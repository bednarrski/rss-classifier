<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-01-17T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.02275"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.04211"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.06568"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.09206"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.05566"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.05643"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.05644"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.05707"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.05757"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.08722"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.06879"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.04342"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.05453"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.05504"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.05574"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.05589"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.05772"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.05787"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.03663"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.06678"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.02082"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.00165"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.04817"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11386"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.02412"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.09983"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1706.02275">
<title>Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments. (arXiv:1706.02275v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1706.02275</link>
<description rdf:parseType="Literal">&lt;p&gt;We explore deep reinforcement learning methods for multi-agent domains. We
begin by analyzing the difficulty of traditional algorithms in the multi-agent
case: Q-learning is challenged by an inherent non-stationarity of the
environment, while policy gradient suffers from a variance that increases as
the number of agents grows. We then present an adaptation of actor-critic
methods that considers action policies of other agents and is able to
successfully learn policies that require complex multi-agent coordination.
Additionally, we introduce a training regimen utilizing an ensemble of policies
for each agent that leads to more robust multi-agent policies. We show the
strength of our approach compared to existing methods in cooperative as well as
competitive scenarios, where agent populations are able to discover various
physical and informational coordination strategies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lowe_R/0/1/0/all/0/1&quot;&gt;Ryan Lowe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yi Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tamar_A/0/1/0/all/0/1&quot;&gt;Aviv Tamar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Harb_J/0/1/0/all/0/1&quot;&gt;Jean Harb&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1&quot;&gt;Pieter Abbeel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mordatch_I/0/1/0/all/0/1&quot;&gt;Igor Mordatch&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.04211">
<title>StackSeq2Seq: Dual Encoder Seq2Seq Recurrent Networks. (arXiv:1710.04211v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1710.04211</link>
<description rdf:parseType="Literal">&lt;p&gt;A widely studied non-deterministic polynomial time (NP) hard problem lies in
finding a route between the two nodes of a graph. Often meta-heuristics
algorithms such as $A^{*}$ are employed on graphs with a large number of nodes.
Here, we propose a deep recurrent neural network architecture based on the
Sequence-2-Sequence (Seq2Seq) model, widely used, for instance in text
translation. Particularly, we illustrate that utilising a context vector that
has been learned from two different recurrent networks enables increased
accuracies in learning the shortest route of a graph. Additionally, we show
that one can boost the performance of the Seq2Seq network by smoothing the loss
function using a homotopy continuation of the decoder&apos;s loss function.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bay_A/0/1/0/all/0/1&quot;&gt;Alessandro Bay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sengupta_B/0/1/0/all/0/1&quot;&gt;Biswa Sengupta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.06568">
<title>ES Is More Than Just a Traditional Finite-Difference Approximator. (arXiv:1712.06568v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1712.06568</link>
<description rdf:parseType="Literal">&lt;p&gt;An evolution strategy (ES) variant recently attracted significant attention
due to its surprisingly good performance at optimizing neural networks in
challenging deep reinforcement learning domains. It searches directly in the
parameter space of neural networks by generating perturbations to the current
set of parameters, checking their performance, and moving in the direction of
higher reward. The resemblance of this algorithm to a traditional
finite-difference approximation of the reward gradient in parameter space
naturally leads to the assumption that it is just that. However, this
assumption is incorrect. The aim of this paper is to definitively demonstrate
this point empirically. ES is a gradient approximator, but optimizes for a
different gradient than just reward (especially when the magnitude of candidate
perturbations is high). Instead, it optimizes for the average reward of the
entire population, often also promoting parameters that are robust to
perturbation. This difference can channel ES into significantly different areas
of the search space than gradient descent in parameter space, and also
consequently to networks with significantly different properties. This unique
robustness-seeking property, and its consequences for optimization, are
demonstrated in several domains. They include humanoid locomotion, where
networks from policy gradient-based reinforcement learning are far less robust
to parameter perturbation than ES-based policies that solve the same task.
While the implications of such robustness and robustness-seeking remain open to
further study, the main contribution of this work is to highlight that such
differences indeed exist and deserve attention.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lehman_J/0/1/0/all/0/1&quot;&gt;Joel Lehman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jay Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Clune_J/0/1/0/all/0/1&quot;&gt;Jeff Clune&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stanley_K/0/1/0/all/0/1&quot;&gt;Kenneth O. Stanley&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.09206">
<title>Chaos-guided Input Structuring for Improved Learning in Recurrent Neural Networks. (arXiv:1712.09206v2 [q-bio.NC] UPDATED)</title>
<link>http://arxiv.org/abs/1712.09206</link>
<description rdf:parseType="Literal">&lt;p&gt;Anatomical studies demonstrate that brain reformats input information to
generate reliable responses for performing computations. However, it remains
unclear how neural circuits encode complex spatio-temporal patterns. We show
that neural dynamics are strongly influenced by the phase alignment between the
input and the spontaneous chaotic activity. Input structuring along the
dominant chaotic projections causes the chaotic trajectories to become stable
channels (or attractors), hence, improving the computational capability of a
recurrent network. Using mean field analysis, we derive the impact of input
structuring on the overall stability of attractors formed. Our results indicate
that input alignment determines the extent of intrinsic noise suppression and
hence, alters the attractor state stability, thereby controlling the network&apos;s
inference ability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Panda_P/0/1/0/all/0/1&quot;&gt;Priyadarshini Panda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Roy_K/0/1/0/all/0/1&quot;&gt;Kaushik Roy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.05566">
<title>An Empirical Analysis of Proximal Policy Optimization with Kronecker-factored Natural Gradients. (arXiv:1801.05566v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1801.05566</link>
<description rdf:parseType="Literal">&lt;p&gt;In this technical report, we consider an approach that combines the PPO
objective and K-FAC natural gradient optimization, for which we call PPOKFAC.
We perform a range of empirical analysis on various aspects of the algorithm,
such as sample complexity, training speed, and sensitivity to batch size and
training epochs. We observe that PPOKFAC is able to outperform PPO in terms of
sample complexity and speed in a range of MuJoCo environments, while being
scalable in terms of batch size. In spite of this, it seems that adding more
epochs is not necessarily helpful for sample efficiency, and PPOKFAC seems to
be worse than its A2C counterpart, ACKTR.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1&quot;&gt;Jiaming Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yuhuai Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.05643">
<title>The Case for Automatic Database Administration using Deep Reinforcement Learning. (arXiv:1801.05643v1 [cs.DB])</title>
<link>http://arxiv.org/abs/1801.05643</link>
<description rdf:parseType="Literal">&lt;p&gt;Like any large software system, a full-fledged DBMS offers an overwhelming
amount of configuration knobs. These range from static initialisation
parameters like buffer sizes, degree of concurrency, or level of replication to
complex runtime decisions like creating a secondary index on a particular
column or reorganising the physical layout of the store. To simplify the
configuration, industry grade DBMSs are usually shipped with various advisory
tools, that provide recommendations for given workloads and machines. However,
reality shows that the actual configuration, tuning, and maintenance is usually
still done by a human administrator, relying on intuition and experience.
Recent work on deep reinforcement learning has shown very promising results in
solving problems, that require such a sense of intuition. For instance, it has
been applied very successfully in learning how to play complicated games with
enormous search spaces. Motivated by these achievements, in this work we
explore how deep reinforcement learning can be used to administer a DBMS.
First, we will describe how deep reinforcement learning can be used to
automatically tune an arbitrary software system like a DBMS by defining a
problem environment. Second, we showcase our concept of NoDBA at the concrete
example of index selection and evaluate how well it recommends indexes for
given workloads.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1&quot;&gt;Ankur Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schuhknecht_F/0/1/0/all/0/1&quot;&gt;Felix Martin Schuhknecht&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dittrich_J/0/1/0/all/0/1&quot;&gt;Jens Dittrich&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.05644">
<title>A formal framework for deliberated judgment. (arXiv:1801.05644v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1801.05644</link>
<description rdf:parseType="Literal">&lt;p&gt;While the philosophical literature has extensively studied how decisions
relate to arguments, reasons and justifications, decision theory almost
entirely ignores the latter notions and rather focuses on preference and
belief. In this article, we argue that decision theory can largely benefit from
explicitly taking into account the stance that decision-makers take towards
arguments and counter-arguments. To that end, we elaborate a formal framework
aiming to integrate the role of arguments and argumentation in decision theory
and decision aid. We start from a decision situation, where an individual
requests decision support. In this context, we formally define, as a
commendable basis for decision-aid, this individual&apos;s deliberated judgment,
popularized by Rawls. We explain how models of deliberated judgment can be
validated empirically. We then identify conditions upon which the existence of
a valid model can be taken for granted, and analyze how these conditions can be
relaxed. We then explore the significance of our proposed framework for
decision aiding practice. We argue that our concept of deliberated judgment
owes its normative credentials both to its normative foundations (the idea of
rationality based on arguments) and to its reference to empirical reality (the
stance that real, empirical individuals hold towards arguments and
counter-arguments, on due reflection). We then highlight that our framework
opens promising avenues for future research involving both philosophical and
decision theoretic approaches, as well as empirical implementations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cailloux_O/0/1/0/all/0/1&quot;&gt;Olivier Cailloux&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meinard_Y/0/1/0/all/0/1&quot;&gt;Yves Meinard&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.05707">
<title>A Generalized Dempster--Shafer Evidence Theory. (arXiv:1801.05707v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1801.05707</link>
<description rdf:parseType="Literal">&lt;p&gt;Dempster-Shafer evidence theory has been widely used in various fields of
applications, because of the flexibility and effectiveness in modeling
uncertainties without prior information. Besides, it has been proven that the
quantum theory has powerful capabilities of solving the decision making
problems, especially for modelling human decision and cognition. However, due
to the inconsistency of the expression, the classical Dempster-Shafer evidence
theory modelled by real numbers can not be integrated directly with the quantum
theory modelled by complex numbers. So, how can we establish a bridge of
communications between the classical Dempster-Shafer evidence theory and the
quantum theory? To answer this question, a generalized Dempster-Shafer evidence
theory is proposed in this paper. The main contribution in this study is that,
unlike the existing evidence theory, a mass function in the generalized
Dempster-Shafer evidence theory is modelled by a complex number, called as a
complex mass function. In addition, compared with the classical Dempster&apos;s
combination rule, the condition in terms of the conflict coefficient between
two evidences (K &amp;lt; 1) is released in the generalized Dempster&apos;s combination
rule so that it is more general and applicable than the classical Dempster&apos;s
combination rule. When the complex mass function is degenerated from complex
numbers to real numbers, the generalized Dempster&apos;s combination rule
degenerates to the classical evidence theory under the condition that the
conflict coefficient between two evidences K is less than 1. This generalized
Dempster-Shafer evidence theory provides a promising way to model and handle
more uncertain information. Numerical examples are illustrated to show the
efficiency of the generalized Dempster-Shafer evidence theory.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_F/0/1/0/all/0/1&quot;&gt;Fuyuan Xiao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.05757">
<title>Experience-driven Networking: A Deep Reinforcement Learning based Approach. (arXiv:1801.05757v1 [cs.NI])</title>
<link>http://arxiv.org/abs/1801.05757</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern communication networks have become very complicated and highly
dynamic, which makes them hard to model, predict and control. In this paper, we
develop a novel experience-driven approach that can learn to well control a
communication network from its own experience rather than an accurate
mathematical model, just as a human learns a new skill (such as driving,
swimming, etc). Specifically, we, for the first time, propose to leverage
emerging Deep Reinforcement Learning (DRL) for enabling model-free control in
communication networks; and present a novel and highly effective DRL-based
control framework, DRL-TE, for a fundamental networking problem: Traffic
Engineering (TE). The proposed framework maximizes a widely-used utility
function by jointly learning network environment and its dynamics, and making
decisions under the guidance of powerful Deep Neural Networks (DNNs). We
propose two new techniques, TE-aware exploration and actor-critic-based
prioritized experience replay, to optimize the general DRL framework
particularly for TE. To validate and evaluate the proposed framework, we
implemented it in ns-3, and tested it comprehensively with both representative
and randomly generated network topologies. Extensive packet-level simulation
results show that 1) compared to several widely-used baseline methods, DRL-TE
significantly reduces end-to-end delay and consistently improves the network
utility, while offering better or comparable throughput; 2) DRL-TE is robust to
network changes; and 3) DRL-TE consistently outperforms a state-ofthe-art DRL
method (for continuous control), Deep Deterministic Policy Gradient (DDPG),
which, however, does not offer satisfying performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1&quot;&gt;Zhiyuan Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1&quot;&gt;Jian Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meng_J/0/1/0/all/0/1&quot;&gt;Jingsong Meng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Weiyi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yanzhi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Chi Harold Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1&quot;&gt;Dejun Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.08722">
<title>Unifying DAGs and UGs. (arXiv:1708.08722v5 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1708.08722</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a new class of graphical models that generalizes
Lauritzen-Wermuth-Frydenberg chain graphs by relaxing the semi-directed
acyclity constraint so that only directed cycles are forbidden. Moreover, up to
two edges are allowed between any pair of nodes. Specifically, we present
local, pairwise and global Markov properties for the new graphical models and
prove their equivalence. We also present an equivalent factorization property.
Finally, we develop an exact algorithm for learning the new models from data
via answer set programming, and we report preliminary results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pena_J/0/1/0/all/0/1&quot;&gt;Jose M. Pe&amp;#xf1;a&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.06879">
<title>Graph Embedding with Rich Information through Heterogeneous Network. (arXiv:1710.06879v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1710.06879</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph embedding has attracted increasing attention due to its critical
application in social network analysis. Most existing algorithms for graph
embedding only rely on the typology information and fail to use the copious
information in nodes as well as edges. As a result, their performance for many
tasks may not be satisfactory. In this paper, we proposed a novel and general
framework of representation learning for graph with rich text information
through constructing a bipartite heterogeneous network. Specially, we designed
a biased random walk to explore the constructed heterogeneous network with the
notion of flexible neighborhood. The efficacy of our method is demonstrated by
extensive comparison experiments with several baselines on various datasets. It
improves the Micro-F1 and Macro-F1 of node classification by 10% and 7% on Cora
dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_G/0/1/0/all/0/1&quot;&gt;Guolei Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiangliang Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.04342">
<title>Combining Symbolic and Function Evaluation Expressions In Neural Programs. (arXiv:1801.04342v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1801.04342</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural programming involves training neural networks to learn programs from
data. Previous works have failed to achieve good generalization performance,
especially on programs with high complexity or on large domains. This is
because they mostly rely either on black-box function evaluations that do not
capture the structure of the program, or on detailed execution traces that are
expensive to obtain, and hence the training data has poor coverage of the
domain under consideration. We present a novel framework that utilizes
black-box function evaluations, in conjunction with symbolic expressions that
integrate relationships between the given functions. We employ tree LSTMs to
incorporate the structure of the symbolic expression trees. We use tree
encoding for numbers present in function evaluation data, based on their
decimal representation. We present an evaluation benchmark for this task to
demonstrate our proposed model combines symbolic reasoning and function
evaluation in a fruitful manner, obtaining high accuracies in our experiments.
Our framework generalizes significantly better to expressions of higher depth
and is able to fill partial equations with valid completions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arabshahi_F/0/1/0/all/0/1&quot;&gt;Forough Arabshahi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1&quot;&gt;Sameer Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1&quot;&gt;Animashree Anandkumar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.05453">
<title>Beyond Word Importance: Contextual Decomposition to Extract Interactions from LSTMs. (arXiv:1801.05453v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1801.05453</link>
<description rdf:parseType="Literal">&lt;p&gt;The driving force behind the recent success of LSTMs has been their ability
to learn complex and non-linear relationships. Consequently, our inability to
describe these relationships has led to LSTMs being characterized as black
boxes. To this end, we introduce contextual decomposition (CD), an
interpretation algorithm for analysing individual predictions made by standard
LSTMs, without any changes to the underlying model. By decomposing the output
of a LSTM, CD captures the contributions of combinations of words or variables
to the final prediction of an LSTM. On the task of sentiment analysis with the
Yelp and SST data sets, we show that CD is able to reliably identify words and
phrases of contrasting sentiment, and how they are combined to yield the LSTM&apos;s
final prediction. Using the phrase-level labels in SST, we also demonstrate
that CD is able to successfully extract positive and negative negations from an
LSTM, something which has not previously been done.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Murdoch_W/0/1/0/all/0/1&quot;&gt;W. James Murdoch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1&quot;&gt;Peter J. Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1&quot;&gt;Bin Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.05504">
<title>Automatic Classification of Music Genre using Masked Conditional Neural Networks. (arXiv:1801.05504v1 [cs.SD])</title>
<link>http://arxiv.org/abs/1801.05504</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural network based architectures used for sound recognition are usually
adapted from other application domains such as image recognition, which may not
harness the time-frequency representation of a signal. The ConditionaL Neural
Networks (CLNN) and its extension the Masked ConditionaL Neural Networks
(MCLNN) are designed for multidimensional temporal signal recognition. The CLNN
is trained over a window of frames to preserve the inter-frame relation, and
the MCLNN enforces a systematic sparseness over the network&apos;s links that mimics
a filterbank-like behavior. The masking operation induces the network to learn
in frequency bands, which decreases the network susceptibility to
frequency-shifts in time-frequency representations. Additionally, the mask
allows an exploration of a range of feature combinations concurrently analogous
to the manual handcrafting of the optimum collection of features for a
recognition task. MCLNN have achieved competitive performance on the Ballroom
music dataset compared to several hand-crafted attempts and outperformed models
based on state-of-the-art Convolutional Neural Networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Medhat_F/0/1/0/all/0/1&quot;&gt;Fady Medhat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chesmore_D/0/1/0/all/0/1&quot;&gt;David Chesmore&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Robinson_J/0/1/0/all/0/1&quot;&gt;John Robinson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.05574">
<title>Brenier approach for optimal transportation between a quasi-discrete measure and a discrete measure. (arXiv:1801.05574v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1801.05574</link>
<description rdf:parseType="Literal">&lt;p&gt;Correctly estimating the discrepancy between two data distributions has
always been an important task in Machine Learning. Recently, Cuturi proposed
the Sinkhorn distance which makes use of an approximate Optimal Transport cost
between two distributions as a distance to describe distribution discrepancy.
Although it has been successfully adopted in various machine learning
applications (e.g. in Natural Language Processing and Computer Vision) since
then, the Sinkhorn distance also suffers from two unnegligible limitations. The
first one is that the Sinkhorn distance only gives an approximation of the real
Wasserstein distance, the second one is the `divide by zero&apos; problem which
often occurs during matrix scaling when setting the entropy regularization
coefficient to a small value. In this paper, we introduce a new Brenier
approach for calculating a more accurate Wasserstein distance between two
discrete distributions, this approach successfully avoids the two limitations
shown above for Sinkhorn distance and gives an alternative way for estimating
distribution discrepancy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1&quot;&gt;Ying Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Liming Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saidi_A/0/1/0/all/0/1&quot;&gt;Alexandre Saidi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_X/0/1/0/all/0/1&quot;&gt;Xianfeng Gu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.05589">
<title>On the Proximal Gradient Algorithm with Alternated Inertia. (arXiv:1801.05589v1 [math.OC])</title>
<link>http://arxiv.org/abs/1801.05589</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we investigate the attractive properties of the proximal
gradient algorithm with inertia. Notably, we show that using alternated inertia
yields monotonically decreasing functional values, which contrasts with usual
accelerated proximal gradient methods. We also provide convergence rates for
the algorithm with alternated inertia based on local geometric properties of
the objective function. The results are put into perspective by discussions on
several extensions and illustrations on common regularized problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Iutzeler_F/0/1/0/all/0/1&quot;&gt;Franck Iutzeler&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Malick_J/0/1/0/all/0/1&quot;&gt;Jerome Malick&lt;/a&gt; (1) ((1) DAO)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.05772">
<title>Ranking Data with Continuous Labels through Oriented Recursive Partitions. (arXiv:1801.05772v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1801.05772</link>
<description rdf:parseType="Literal">&lt;p&gt;We formulate a supervised learning problem, referred to as continuous
ranking, where a continuous real-valued label Y is assigned to an observable
r.v. X taking its values in a feature space $\mathcal{X}$ and the goal is to
order all possible observations x in $\mathcal{X}$ by means of a scoring
function $s:\mathcal{X}\rightarrow \mathbb{R}$ so that s(X) and Y tend to
increase or decrease together with highest probability. This problem
generalizes bi/multi-partite ranking to a certain extent and the task of
finding optimal scoring functions s(x) can be naturally cast as optimization of
a dedicated functional criterion, called the IROC curve here, or as
maximization of the Kendall ${\tau}$ related to the pair (s(X), Y ). From the
theoretical side, we describe the optimal elements of this problem and provide
statistical guarantees for empirical Kendall ${\tau}$ maximization under
appropriate conditions for the class of scoring function candidates. We also
propose a recursive statistical learning algorithm tailored to empirical IROC
curve optimization and producing a piecewise constant scoring function that is
fully described by an oriented binary tree. Preliminary numerical experiments
highlight the difference in nature between regression and continuous ranking
and provide strong empirical evidence of the performance of empirical
optimizers of the criteria proposed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Clemencon_S/0/1/0/all/0/1&quot;&gt;Stephan Cl&amp;#xe9;men&amp;#xe7;on&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Achab_M/0/1/0/all/0/1&quot;&gt;Mastane Achab&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.05787">
<title>Faster gaze prediction with dense networks and Fisher pruning. (arXiv:1801.05787v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1801.05787</link>
<description rdf:parseType="Literal">&lt;p&gt;Predicting human fixations from images has recently seen large improvements
by leveraging deep representations which were pretrained for object
recognition. However, as we show in this paper, these networks are highly
overparameterized for the task of fixation prediction. We first present a
simple yet principled greedy pruning method which we call Fisher pruning.
Through a combination of knowledge distillation and Fisher pruning, we obtain
much more runtime-efficient architectures for saliency prediction, achieving a
10x speedup for the same AUC performance as a state of the art network on the
CAT2000 dataset. Speeding up single-image gaze prediction is important for many
real-world applications, but it is also a crucial step in the development of
video saliency models, where the amount of data to be processed is
substantially larger.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Theis_L/0/1/0/all/0/1&quot;&gt;Lucas Theis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Korshunova_I/0/1/0/all/0/1&quot;&gt;Iryna Korshunova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tejani_A/0/1/0/all/0/1&quot;&gt;Alykhan Tejani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huszar_F/0/1/0/all/0/1&quot;&gt;Ferenc Husz&amp;#xe1;r&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.03663">
<title>Underdamped Langevin MCMC: A non-asymptotic analysis. (arXiv:1707.03663v6 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1707.03663</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the underdamped Langevin diffusion when the log of the target
distribution is smooth and strongly concave. We present a MCMC algorithm based
on its discretization and show that it achieves $\varepsilon$ error (in
2-Wasserstein distance) in $\mathcal{O}(\sqrt{d}/\varepsilon)$ steps. This is a
significant improvement over the best known rate for overdamped Langevin MCMC,
which is $\mathcal{O}(d/\varepsilon^2)$ steps under the same
smoothness/concavity assumptions.
&lt;/p&gt;
&lt;p&gt;The underdamped Langevin MCMC scheme can be viewed as a version of
Hamiltonian Monte Carlo (HMC) which has been observed to outperform overdamped
Langevin MCMC methods in a number of application areas. We provide quantitative
rates that support this empirical wisdom.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cheng_X/0/1/0/all/0/1&quot;&gt;Xiang Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chatterji_N/0/1/0/all/0/1&quot;&gt;Niladri S. Chatterji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bartlett_P/0/1/0/all/0/1&quot;&gt;Peter L. Bartlett&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jordan_M/0/1/0/all/0/1&quot;&gt;Michael I. Jordan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.06678">
<title>Learning Combinations of Sigmoids Through Gradient Estimation. (arXiv:1708.06678v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1708.06678</link>
<description rdf:parseType="Literal">&lt;p&gt;We develop a new approach to learn the parameters of regression models with
hidden variables. In a nutshell, we estimate the gradient of the regression
function at a set of random points, and cluster the estimated gradients. The
centers of the clusters are used as estimates for the parameters of hidden
units. We justify this approach by studying a toy model, whereby the regression
function is a linear combination of sigmoids. We prove that indeed the
estimated gradients concentrate around the parameter vectors of the hidden
units, and provide non-asymptotic bounds on the number of required samples. To
the best of our knowledge, no comparable guarantees have been proven for linear
combinations of sigmoids.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ioannidis_S/0/1/0/all/0/1&quot;&gt;Stratis Ioannidis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Montanari_A/0/1/0/all/0/1&quot;&gt;Andrea Montanari&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.02082">
<title>A deep generative model for gene expression profiles from single-cell RNA sequencing. (arXiv:1709.02082v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1709.02082</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a probabilistic model for interpreting gene expression levels that
are observed through single-cell RNA sequencing. In the model, each cell has a
low-dimensional latent representation. Additional latent variables account for
technical effects that may erroneously set some observations of gene expression
levels to zero. Conditional distributions are specified by neural networks,
giving the proposed model enough flexibility to fit the data well. We use
variational inference and stochastic optimization to approximate the posterior
distribution. The inference procedure scales to over one million cells, whereas
competing algorithms do not. Even for smaller datasets, for several tasks, the
proposed procedure outperforms state-of-the-art methods like ZIFA and
ZINB-WaVE. We also extend our framework to account for batch effects and other
confounding factors, and propose a Bayesian hypothesis test for differential
expression that outperforms DESeq2.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lopez_R/0/1/0/all/0/1&quot;&gt;Romain Lopez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Regier_J/0/1/0/all/0/1&quot;&gt;Jeffrey Regier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cole_M/0/1/0/all/0/1&quot;&gt;Michael Cole&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1&quot;&gt;Michael Jordan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yosef_N/0/1/0/all/0/1&quot;&gt;Nir Yosef&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.00165">
<title>Deep Neural Networks as Gaussian Processes. (arXiv:1711.00165v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.00165</link>
<description rdf:parseType="Literal">&lt;p&gt;A deep fully-connected neural network with an i.i.d. prior over its
parameters is equivalent to a Gaussian process (GP) in the limit of infinite
network width. This correspondence enables exact Bayesian inference for neural
networks on regression tasks by means of straightforward matrix computations.
For single hidden-layer networks, the covariance function of this GP has long
been known. Recently, kernel functions for multi-layer random neural networks
have been developed, but only outside of a Bayesian framework. As such,
previous work has not identified the correspondence between using these kernels
as the covariance function for a GP and performing fully Bayesian prediction
with a deep neural network. In this work, we derive this correspondence and
develop a computationally efficient pipeline to compute the covariance
functions. We then use the resulting GP to perform Bayesian inference for deep
neural networks on MNIST and CIFAR-10. We find that the GP-based predictions
are competitive and can outperform neural networks trained with stochastic
gradient descent. We observe that the trained neural network accuracy
approaches that of the corresponding GP-based computation with increasing layer
width, and that the GP uncertainty is strongly correlated with prediction
error. We connect our observations to the recent development of signal
propagation in random neural networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jaehoon Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bahri_Y/0/1/0/all/0/1&quot;&gt;Yasaman Bahri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Novak_R/0/1/0/all/0/1&quot;&gt;Roman Novak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schoenholz_S/0/1/0/all/0/1&quot;&gt;Samuel S. Schoenholz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pennington_J/0/1/0/all/0/1&quot;&gt;Jeffrey Pennington&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sohl_Dickstein_J/0/1/0/all/0/1&quot;&gt;Jascha Sohl-Dickstein&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.04817">
<title>Sparse quadratic classification rules via linear dimension reduction. (arXiv:1711.04817v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.04817</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of high-dimensional classification between the two
groups with unequal covariance matrices. Rather than estimating the full
quadratic discriminant rule, we propose to perform simultaneous variable
selection and linear dimension reduction on original data, with the subsequent
application of quadratic discriminant analysis on the reduced space. In
contrast to quadratic discriminant analysis, the proposed framework doesn&apos;t
require estimation of precision matrices and scales linearly with the number of
measurements, making it especially attractive for the use on high-dimensional
datasets. We support the methodology with theoretical guarantees on variable
selection consistency, and empirical comparison with competing approaches. We
apply the method to gene expression data of breast cancer patients, and confirm
the crucial importance of ESR1 gene in differentiating estrogen receptor
status.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gaynanova_I/0/1/0/all/0/1&quot;&gt;Irina Gaynanova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_T/0/1/0/all/0/1&quot;&gt;Tianying Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11386">
<title>MR image reconstruction using deep density priors. (arXiv:1711.11386v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1711.11386</link>
<description rdf:parseType="Literal">&lt;p&gt;Purpose: MR image reconstruction exploits regularization to compensate for
missing k-space data. In this work, we propose to learn the probability
distribution of MR image patches with neural networks and use this distribution
as prior information constraining images during reconstruction, effectively
employing it as regularization.
&lt;/p&gt;
&lt;p&gt;Methods: We use variational autoencoders (VAE) to learn the distribution of
MR image patches, which models the high-dimensional distribution by a latent
parameter model of lower dimensions in a non-linear fashion. The proposed
algorithm uses the learned prior in a Maximum-A-Posteriori estimation
formulation. We evaluate the proposed reconstruction method with T1 weighted
images and also apply our method on images with white matter lesions.
&lt;/p&gt;
&lt;p&gt;Results: Visual evaluation of the samples showed that the VAE algorithm can
approximate the distribution of MR patches well. The proposed reconstruction
algorithm using the VAE prior produced high quality reconstructions. The
algorithm achieved normalized RMSE, CNR and CN values of 2.77\%, 0.43, 0.11;
4.29\%, 0.43, 0.11, 6.36\%, 0.47, 0.11 and 10.00\%, 0.42, 0.10 for
undersampling ratios of 2, 3, 4 and 5, respectively, where it outperformed most
of the alternative methods. In the experiments on images with white matter
lesions, the method faithfully reconstructed the lesions.
&lt;/p&gt;
&lt;p&gt;Conclusion: We introduced a novel method for MR reconstruction, which takes a
new perspective on regularization by using priors learned by neural networks.
Results suggest the method compares favorably against the other evaluated
methods and can reconstruct lesions as well.
&lt;/p&gt;
&lt;p&gt;Keywords: Reconstruction, MRI, prior probability, MAP estimation, machine
learning, variational inference, deep learning
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tezcan_K/0/1/0/all/0/1&quot;&gt;Kerem C. Tezcan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baumgartner_C/0/1/0/all/0/1&quot;&gt;Christian F. Baumgartner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Konukoglu_E/0/1/0/all/0/1&quot;&gt;Ender Konukoglu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.02412">
<title>Estimating the error variance in a high-dimensional linear model. (arXiv:1712.02412v2 [stat.ME] UPDATED)</title>
<link>http://arxiv.org/abs/1712.02412</link>
<description rdf:parseType="Literal">&lt;p&gt;The lasso has been studied extensively as a tool for estimating the
coefficient vector in the high-dimensional linear model; however, considerably
less is known about estimating the error variance. Indeed, most well-known
theoretical properties of the lasso, including recent advances in selective
inference with the lasso, are established under the assumption that the
underlying error variance is known. Yet the error variance in practice is, of
course, unknown. In this paper, we propose the natural lasso estimator for the
error variance, which maximizes a penalized likelihood objective. A key aspect
of the natural lasso is that the likelihood is expressed in terms of the
natural parameterization of the multiparameter exponential family of a Gaussian
with unknown mean and variance. The result is a remarkably simple estimator
with provably good performance in terms of mean squared error. These
theoretical results do not require placing any assumptions on the design matrix
or the true regression coefficients. We also propose a companion estimator,
called the organic lasso, which theoretically does not require tuning of the
regularization parameter. Both estimators do well compared to preexisting
methods, especially in settings where successful recovery of the true support
of the coefficient vector is hard.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yu_G/0/1/0/all/0/1&quot;&gt;Guo Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bien_J/0/1/0/all/0/1&quot;&gt;Jacob Bien&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.09983">
<title>Random Feature-based Online Multi-kernel Learning in Environments with Unknown Dynamics. (arXiv:1712.09983v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1712.09983</link>
<description rdf:parseType="Literal">&lt;p&gt;Kernel-based methods exhibit well-documented performance in various nonlinear
learning tasks. Most of them rely on a preselected kernel, whose prudent choice
presumes task-specific prior information. Especially when the latter is not
available, multi-kernel learning has gained popularity thanks to its
flexibility in choosing kernels from a prescribed kernel dictionary. Leveraging
the random feature approximation and its recent orthogonality-promoting
variant, the present contribution develops a scalable multi-kernel learning
scheme (termed Raker) to obtain the sought nonlinear learning function `on the
fly,&apos; first for static environments. To further boost performance in dynamic
environments, an adaptive multi-kernel learning scheme (termed AdaRaker) is
developed using weighted combinations of advices from hierarchical ensembles of
experts. The weights account not only for each kernel&apos;s contribution to the
learning, but also for the unknown dynamics. Performance is analyzed in terms
of both static and dynamic regrets. AdaRaker is uniquely capable of tracking
nonlinear learning functions in environments with unknown dynamics, with
analytic performance guarantees. Tests with synthetic and real datasets are
carried out to showcase the effectiveness of the novel algorithms, and their
performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shen_Y/0/1/0/all/0/1&quot;&gt;Yanning Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_T/0/1/0/all/0/1&quot;&gt;Tianyi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Giannakis_G/0/1/0/all/0/1&quot;&gt;Georgios B. Giannakis&lt;/a&gt;</dc:creator>
</item></rdf:RDF>