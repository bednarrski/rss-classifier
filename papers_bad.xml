<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-02-18T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05825"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05892"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05943"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05991"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.05970"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.05284"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05786"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05818"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05835"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05889"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05929"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05998"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06052"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06068"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.05262"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.03331"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.06294"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04987"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05733"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05757"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05811"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05814"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05821"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05822"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05841"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05872"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05910"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05968"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05980"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05983"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06009"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06014"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06037"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1606.00451"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1610.06462"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1704.09011"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.01383"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.07164"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.07827"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.06598"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.00047"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03001"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04956"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05074"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05688"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1802.05825">
<title>A Comparison of Constraint Handling Techniques for Dynamic Constrained Optimization Problems. (arXiv:1802.05825v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1802.05825</link>
<description rdf:parseType="Literal">&lt;p&gt;Dynamic constrained optimization problems (DCOPs) have gained researchers
attention in recent years because a vast majority of real world problems change
over time. There are studies about the effect of constrained handling
techniques in static optimization problems. However, there lacks any
substantial study in the behavior of the most popular constraint handling
techniques when dealing with DCOPs. In this paper we study the four most
popular used constraint handling techniques and apply a simple Differential
Evolution (DE) algorithm coupled with a change detection mechanism to observe
the behavior of these techniques. These behaviors were analyzed using a common
benchmark to determine which techniques are suitable for the most prevalent
types of DCOPs. For the purpose of analysis, common measures in static
environments were adapted to suit dynamic environments. While an overall
superior technique could not be determined, certain techniques outperformed
others in different aspects like rate of optimization or reliability of
solutions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ameca_Alducin_M/0/1/0/all/0/1&quot;&gt;Maria-Yaneli Ameca-Alducin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hasani_Shoreh_M/0/1/0/all/0/1&quot;&gt;Maryam Hasani-Shoreh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blaikie_W/0/1/0/all/0/1&quot;&gt;Wilson Blaikie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Neumann_F/0/1/0/all/0/1&quot;&gt;Frank Neumann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mezura_Montes_E/0/1/0/all/0/1&quot;&gt;Efren Mezura-Montes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05892">
<title>Neuroscientific User Models: The Source of Uncertain User Feedback and Potentials for Improving Web Personalisation. (arXiv:1802.05892v1 [cs.HC])</title>
<link>http://arxiv.org/abs/1802.05892</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we consider the neuroscientific theory of the Bayesian brain in
the light of adaptive web systems and content personalisation. In particular,
we elaborate on neural mechanisms of human decision-making and the origin of
lacking reliability of user feedback, often denoted as noise or human
uncertainty. To this end, we first introduce an adaptive model of cognitive
agency in which populations of neurons provide an estimation for states of the
world. Subsequently, we present various so-called decoder functions with which
neuronal activity can be translated into quantitative decisions. The interplay
of the underlying cognition model and the chosen decoder function leads to
different model-based properties of decision processes. The goal of this paper
is to promote novel user models and exploit them to naturally associate users
to different clusters on the basis of their individual neural characteristics
and thinking patterns. These user models might be able to turn the variability
of user behaviour into additional information for improving web personalisation
and its experience.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jasberg_K/0/1/0/all/0/1&quot;&gt;Kevin Jasberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sizov_S/0/1/0/all/0/1&quot;&gt;Sergej Sizov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05943">
<title>Cloud No Longer a Silver Bullet, Edge to the Rescue. (arXiv:1802.05943v1 [cs.NI])</title>
<link>http://arxiv.org/abs/1802.05943</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper takes the position that, while cognitive computing today relies
heavily on the cloud, we will soon see a paradigm shift where cognitive
computing primarily happens on network edges. The shift toward edge devices is
fundamentally propelled both by technological constraints in data centers and
wireless network infrastructures, as well as practical considerations such as
privacy and safety. The remainder of this paper lays out our view of how these
constraints will impact future cognitive computing. Bringing cognitive
computing to edge devices opens up several new opportunities and challenges,
some of which demand new solutions and some of which require us to revisit
entrenched techniques in light of new technologies. We close the paper with a
call to action for future research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1&quot;&gt;Yuhao Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_G/0/1/0/all/0/1&quot;&gt;Gu-Yeon Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brooks_D/0/1/0/all/0/1&quot;&gt;David Brooks&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05991">
<title>The N-Tuple Bandit Evolutionary Algorithm for Game Agent Optimisation. (arXiv:1802.05991v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1802.05991</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper describes the N-Tuple Bandit Evolutionary Algorithm (NTBEA), an
optimisation algorithm developed for noisy and expensive discrete
(combinatorial) optimisation problems. The algorithm is applied to two
game-based hyper-parameter optimisation problems. The N-Tuple system directly
models the statistics, approximating the fitness and number of evaluations of
each modelled combination of parameters. The model is simple, efficient and
informative. Results show that the NTBEA significantly outperforms grid search
and an estimation of distribution algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lucas_S/0/1/0/all/0/1&quot;&gt;Simon M Lucas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jialin Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perez_Liebana_D/0/1/0/all/0/1&quot;&gt;Diego Perez-Liebana&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.05970">
<title>Generic Black-Box End-to-End Attack Against State of the Art API Call Based Malware Classifiers. (arXiv:1707.05970v4 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/1707.05970</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we present a black-box attack against API call based machine
learning malware classifiers, focusing on generating adversarial sequences
combining API calls and static features (e.g., printable strings) that will be
misclassified by the classifier without affecting the malware functionality. We
show that this attack is effective against many classifiers due to the
transferability principle between RNN variants, feed forward DNNs, and
traditional machine learning classifiers such as SVM and gradient boosted
decision tree. We also implement GADGET, a software framework to convert any
malware binary to a binary undetected by malware classifiers, using the
proposed attack, without access to the malware source code. Finally, we discuss
the robustness of this attack to existing defense mechanisms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rosenberg_I/0/1/0/all/0/1&quot;&gt;Ishai Rosenberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shabtai_A/0/1/0/all/0/1&quot;&gt;Asaf Shabtai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rokach_L/0/1/0/all/0/1&quot;&gt;Lior Rokach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elovici_Y/0/1/0/all/0/1&quot;&gt;Yuval Elovici&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.05284">
<title>Adaptation to criticality through organizational invariance in embodied agents. (arXiv:1712.05284v2 [nlin.AO] UPDATED)</title>
<link>http://arxiv.org/abs/1712.05284</link>
<description rdf:parseType="Literal">&lt;p&gt;Many biological and cognitive systems do not operate deep within one or other
regime of activity. Instead, they are poised at critical points located at
transitions of their parameter space. The pervasiveness of criticality suggests
that there may be general principles inducing this behaviour, yet there is no
well-founded theory for understanding how criticality is found at a wide span
of levels and contexts. In this paper we present a general adaptive mechanism
that maintains an internal organizational structure in order to drive a system
towards critical points while it interacts with different environments. We
implement the mechanism in artificial embodied agents controlled by a neural
network maintaining a correlation structure randomly sampled from an Ising
model at critical temperature. Agents are evaluated in two classical
reinforcement learning scenarios: the Mountain Car and the Acrobot double
pendulum. In both cases the neural controller appears to reach a point of
criticality, which coincides with a transition point between two regimes of the
agent&apos;s behaviour. These results suggest that adaptation to criticality could
be used as a general adaptive mechanism in some circumstances, providing an
alternative explanation for the pervasive presence of criticality in biological
and cognitive systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/nlin/1/au:+Aguilera_M/0/1/0/all/0/1&quot;&gt;Miguel Aguilera&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/nlin/1/au:+Bedia_M/0/1/0/all/0/1&quot;&gt;Manuel G. Bedia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05786">
<title>Truth Validation with Evidence. (arXiv:1802.05786v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.05786</link>
<description rdf:parseType="Literal">&lt;p&gt;In the modern era, abundant information is easily accessible from various
sources, however only a few of these sources are reliable as they mostly
contain unverified contents. We develop a system to validate the truthfulness
of a given statement together with underlying evidence. The proposed system
provides supporting evidence when the statement is tagged as false. Our work
relies on an inference method on a knowledge graph (KG) to identify the
truthfulness of statements. In order to extract the evidence of falseness, the
proposed algorithm takes into account combined knowledge from KG and
ontologies. The system shows very good results as it provides valid and concise
evidence. The quality of KG plays a role in the performance of the inference
method which explicitly affects the performance of our evidence-extracting
algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wongchaisuwat_P/0/1/0/all/0/1&quot;&gt;Papis Wongchaisuwat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klabjan_D/0/1/0/all/0/1&quot;&gt;Diego Klabjan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05818">
<title>Disentangling Aspect and Opinion Words in Target-based Sentiment Analysis using Lifelong Learning. (arXiv:1802.05818v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1802.05818</link>
<description rdf:parseType="Literal">&lt;p&gt;Given a target name, which can be a product aspect or entity, identifying its
aspect words and opinion words in a given corpus is a fine-grained task in
target-based sentiment analysis (TSA). This task is challenging, especially
when we have no labeled data and we want to perform it for any given domain. To
address it, we propose a general two-stage approach. Stage one extracts/groups
the target-related words (call t-words) for a given target. This is relatively
easy as we can apply an existing semantics-based learning technique. Stage two
separates the aspect and opinion words from the grouped t-words, which is
challenging because we often do not have enough word-level aspect and opinion
labels. In this work, we formulate this problem in a PU learning setting and
incorporate the idea of lifelong learning to solve it. Experimental results
show the effectiveness of our approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Shuai Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1&quot;&gt;Mianwei Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mazumder_S/0/1/0/all/0/1&quot;&gt;Sahisnu Mazumder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1&quot;&gt;Bing Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1&quot;&gt;Yi Chang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05835">
<title>An Anytime Algorithm for Task and Motion MDPs. (arXiv:1802.05835v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.05835</link>
<description rdf:parseType="Literal">&lt;p&gt;Integrated task and motion planning has emerged as a challenging problem in
sequential decision making, where a robot needs to compute high-level strategy
and low-level motion plans for solving complex tasks. While high-level
strategies require decision making over longer time-horizons and scales, their
feasibility depends on low-level constraints based upon the geometries and
continuous dynamics of the environment. The hybrid nature of this problem makes
it difficult to scale; most existing approaches focus on deterministic, fully
observable scenarios. We present a new approach where the high-level decision
problem occurs in a stochastic setting and can be modeled as a Markov decision
process. In contrast to prior efforts, we show that complete MDP policies, or
contingent behaviors, can be computed effectively in an anytime fashion. Our
algorithm continuously improves the quality of the solution and is guaranteed
to be probabilistically complete. We evaluate the performance of our approach
on a challenging, realistic test problem: autonomous aircraft inspection. Our
results show that we can effectively compute consistent task and motion
policies for the most likely execution-time outcomes using only a fraction of
the computation required to develop the complete task and motion policy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srivastava_S/0/1/0/all/0/1&quot;&gt;Siddharth Srivastava&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Desai_N/0/1/0/all/0/1&quot;&gt;Nishant Desai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Freedman_R/0/1/0/all/0/1&quot;&gt;Richard Freedman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zilberstein_S/0/1/0/all/0/1&quot;&gt;Shlomo Zilberstein&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05889">
<title>Combining Linear Non-Gaussian Acyclic Model with Logistic Regression Model for Estimating Causal Structure from Mixed Continuous and Discrete Data. (arXiv:1802.05889v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.05889</link>
<description rdf:parseType="Literal">&lt;p&gt;Estimating causal models from observational data is a crucial task in data
analysis. For continuous-valued data, Shimizu et al. have proposed a linear
acyclic non-Gaussian model to understand the data generating process, and have
shown that their model is identifiable when the number of data is sufficiently
large. However, situations in which continuous and discrete variables coexist
in the same problem are common in practice. Most existing causal discovery
methods either ignore the discrete data and apply a continuous-valued algorithm
or discretize all the continuous data and then apply a discrete Bayesian
network approach. These methods possibly loss important information when we
ignore discrete data or introduce the approximation error due to
discretization. In this paper, we define a novel hybrid causal model which
consists of both continuous and discrete variables. The model assumes: (1) the
value of a continuous variable is a linear function of its parent variables
plus a non-Gaussian noise, and (2) each discrete variable is a logistic
variable whose distribution parameters depend on the values of its parent
variables. In addition, we derive the BIC scoring function for model selection.
The new discovery algorithm can learn causal structures from mixed continuous
and discrete data without discretization. We empirically demonstrate the power
of our method through thorough simulations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shimizu_S/0/1/0/all/0/1&quot;&gt;Shohei Shimizu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05929">
<title>Measuring Human-perceived Similarity in Heterogeneous Collections. (arXiv:1802.05929v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.05929</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a technique for estimating the similarity between objects such as
movies or foods whose proper representation depends on human perception. Our
technique combines a modest number of human similarity assessments to infer a
pairwise similarity function between the objects. This similarity function
captures some human notion of similarity which may be difficult or impossible
to automatically extract, such as which movie from a collection would be a
better substitute when the desired one is unavailable. In contrast to prior
techniques, our method does not assume that all similarity questions on the
collection can be answered or that all users perceive similarity in the same
way. When combined with a user model, we find how each assessor&apos;s tastes vary,
affecting their perception of similarity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anderton_J/0/1/0/all/0/1&quot;&gt;Jesse Anderton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Metrikov_P/0/1/0/all/0/1&quot;&gt;Pavel Metrikov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pavlu_V/0/1/0/all/0/1&quot;&gt;Virgil Pavlu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aslam_J/0/1/0/all/0/1&quot;&gt;Javed Aslam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05998">
<title>Abductive reasoning as the basis to reproduce expert criteria in ECG Atrial Fibrillation identification. (arXiv:1802.05998v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.05998</link>
<description rdf:parseType="Literal">&lt;p&gt;Objective: This work aims at providing a new method for the automatic
detection of atrial fibrillation, other arrhythmia and noise on short single
lead ECG signals, emphasizing the importance of the interpretability of the
classification results.
&lt;/p&gt;
&lt;p&gt;Approach: A morphological and rhythm description of the cardiac behavior is
obtained by a knowledge-based interpretation of the signal using the
\textit{Construe} abductive framework. Then, a set of meaningful features are
extracted for each individual heartbeat and as a summary of the full record.
The feature distributions were used to elucidate the expert criteria underlying
the labeling of the 2017 Physionet/CinC Challenge dataset, enabling a manual
partial relabeling to improve the consistency of the classification rules.
Finally, state-of-the-art machine learning methods are combined to provide an
answer on the basis of the feature values.
&lt;/p&gt;
&lt;p&gt;Main results: The proposal tied for the first place in the official stage of
the Challenge, with a combined $F_1$ score of 0.83, and was even improved in
the follow-up stage to 0.85 with a significant simplification of the model.
&lt;/p&gt;
&lt;p&gt;Significance: This approach demonstrates the potential of \textit{Construe}
to provide robust and valuable descriptions of temporal data even with
significant amounts of noise and artifacts. Also, we discuss the importance of
a consistent classification criteria in manually labeled training datasets, and
the fundamental advantages of knowledge-based approaches to formalize and
validate that criteria.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Teijeiro_T/0/1/0/all/0/1&quot;&gt;Tom&amp;#xe1;s Teijeiro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garcia_C/0/1/0/all/0/1&quot;&gt;Constantino A. Garc&amp;#xed;a&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Castro_D/0/1/0/all/0/1&quot;&gt;Daniel Castro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Felix_P/0/1/0/all/0/1&quot;&gt;Paulo F&amp;#xe9;lix&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06052">
<title>Online Continuous Submodular Maximization. (arXiv:1802.06052v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.06052</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we consider an online optimization process, where the
objective functions are not convex (nor concave) but instead belong to a broad
class of continuous submodular functions. We first propose a variant of the
Frank-Wolfe algorithm that has access to the full gradient of the objective
functions. We show that it achieves a regret bound of $O(\sqrt{T})$ (where $T$
is the horizon of the online optimization problem) against a
$(1-1/e)$-approximation to the best feasible solution in hindsight. However, in
many scenarios, only an unbiased estimate of the gradients are available. For
such settings, we then propose an online stochastic gradient ascent algorithm
that also achieves a regret bound of $O(\sqrt{T})$ regret, albeit against a
weaker $1/2$-approximation to the best feasible solution in hindsight. We also
generalize our results to $\gamma$-weakly submodular functions and prove the
same sublinear regret bounds. Finally, we demonstrate the efficiency of our
algorithms on a few problem instances, including non-convex/non-concave
quadratic programs, multilinear extensions of submodular set functions, and
D-optimal design.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Lin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hassani_H/0/1/0/all/0/1&quot;&gt;Hamed Hassani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Karbasi_A/0/1/0/all/0/1&quot;&gt;Amin Karbasi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06068">
<title>Artificial intelligence and pediatrics: A synthetic mini review. (arXiv:1802.06068v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.06068</link>
<description rdf:parseType="Literal">&lt;p&gt;The use of artificial intelligence intelligencein medicine can be traced back
to 1968 when Paycha published his paper Le diagnostic a l&apos;aide d&apos;intelligences
artificielle, presentation de la premiere machine diagnostri. Few years later
Shortliffe et al. presented an expert system named Mycin which was able to
identify bacteria causing severe blood infections and to recommend antibiotics.
Despite the fact that Mycin outperformed members of the Stanford medical school
in the reliability of diagnosis it was never used in practice due to a legal
issue who do you sue if it gives a wrong diagnosis?. However only in 2016 when
the artificial intelligence software built into the IBM Watson AI platform
correctly diagnosed and proposed an effective treatment for a 60-year-old
womans rare form of leukemia the AI use in medicine become really popular.On of
first papers presenting the use of AI in paediatrics was published in 1984. The
paper introduced a computer-assisted medical decision making system called
SHELP.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kokol_P/0/1/0/all/0/1&quot;&gt;Peter Kokol&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zavrsnik_J/0/1/0/all/0/1&quot;&gt;Jernej Zavr&amp;#x161;nik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vosner_H/0/1/0/all/0/1&quot;&gt;Helena Bla&amp;#x17e;un Vo&amp;#x161;ner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.05262">
<title>Supervising Unsupervised Learning. (arXiv:1709.05262v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1709.05262</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a framework to leverage knowledge acquired from a repository of
(heterogeneous) supervised datasets to new unsupervised datasets. Our
perspective avoids the subjectivity inherent in unsupervised learning by
reducing it to supervised learning, and provides a principled way to evaluate
unsupervised algorithms. We demonstrate the versatility of our framework via
simple agnostic bounds on unsupervised problems. In the context of clustering,
our approach helps choose the number of clusters and the clustering algorithm,
remove the outliers, and provably circumvent the Kleinberg&apos;s impossibility
result. Experimental results across hundreds of problems demonstrate improved
performance on unsupervised data with simple algorithms, despite the fact that
our problems come from heterogeneous domains. Additionally, our framework lets
us leverage deep networks to learn common features from many such small
datasets, and perform zero shot learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garg_V/0/1/0/all/0/1&quot;&gt;Vikas K. Garg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kalai_A/0/1/0/all/0/1&quot;&gt;Adam Kalai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.03331">
<title>Heuristic Optimization for Automated Distribution System Planning in Network Integration Studies. (arXiv:1711.03331v2 [cs.CE] UPDATED)</title>
<link>http://arxiv.org/abs/1711.03331</link>
<description rdf:parseType="Literal">&lt;p&gt;Network integration studies try to assess the impact of future developments,
such as the increase of Renewable Energy Sources or the introduction of Smart
Grid Technologies, on large-scale network areas. Goals can be to support
strategic alignment in the regulatory framework or to adapt the network
planning principles of Distribution System Operators. This study outlines an
approach for the automated distribution system planning that can calculate
network reconfiguration, reinforcement and extension plans in a fully automated
fashion. This allows the estimation of the expected cost in massive
probabilistic simulations of large numbers of real networks and constitutes a
core component of a framework for large-scale network integration studies.
Exemplary case study results are presented that were performed in cooperation
with different major distribution system operators. The case studies cover the
estimation of expected network reinforcement costs, technical and economical
assessment of smart grid technologies and structural network optimisation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scheidler_A/0/1/0/all/0/1&quot;&gt;Alexander Scheidler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thurner_L/0/1/0/all/0/1&quot;&gt;Leon Thurner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Braun_M/0/1/0/all/0/1&quot;&gt;Martin Braun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.06294">
<title>Multi-Task Pharmacovigilance Mining from Social Media Posts. (arXiv:1801.06294v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1801.06294</link>
<description rdf:parseType="Literal">&lt;p&gt;Social media has grown to be a crucial information source for
pharmacovigilance studies where an increasing number of people post adverse
reactions to medical drugs that are previously unreported. Aiming to
effectively monitor various aspects of Adverse Drug Reactions (ADRs) from
diversely expressed social medical posts, we propose a multi-task neural
network framework that learns several tasks associated with ADR monitoring with
different levels of supervisions collectively. Besides being able to correctly
classify ADR posts and accurately extract ADR mentions from online posts, the
proposed framework is also able to further understand reasons for which the
drug is being taken, known as &apos;indication&apos;, from the given social media post. A
coverage-based attention mechanism is adopted in our framework to help the
model properly identify &apos;phrasal&apos; ADRs and Indications that are attentive to
multiple words in a post. Our framework is applicable in situations where
limited parallel data for different pharmacovigilance tasks are available.We
evaluate the proposed framework on real-world Twitter datasets, where the
proposed model outperforms the state-of-the-art alternatives of each individual
task consistently.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chowdhury_S/0/1/0/all/0/1&quot;&gt;Shaika Chowdhury&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chenwei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1&quot;&gt;Philip S. Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04987">
<title>PlayeRank: Multi-dimensional and role-aware rating of soccer player performance. (arXiv:1802.04987v2 [stat.AP] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04987</link>
<description rdf:parseType="Literal">&lt;p&gt;The problem of rating the performance of soccer players is attracting the
interest of many companies, websites, and the scientific community, thanks to
the availability of massive data capturing all the events generated during a
game (e.g., tackles, passes, shots, etc.). Existing approaches fail to fully
exploit the richness of the available data and lack of a proper validation. In
this paper, we design and implement PlayeRank, a data-driven framework that
offers a principled multi-dimensional and role-aware evaluation of the
performance of soccer players. We validate the framework through an
experimental analysis advised by soccer experts, based on a massive dataset of
millions of events pertaining four seasons of the five prominent European
leagues. Experiments show that PlayeRank is robust in agreeing with the
experts&apos; evaluation of players, significantly improving the state of the art.
We also explore an application of PlayeRank --- i.e. searching players --- by
introducing a special form of spatial query on the soccer field. This shows its
flexibility and efficiency, which makes it worth to be used in the design of a
scalable platform for soccer analytics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pappalardo_L/0/1/0/all/0/1&quot;&gt;Luca Pappalardo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cintia_P/0/1/0/all/0/1&quot;&gt;Paolo Cintia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ferragina_P/0/1/0/all/0/1&quot;&gt;Paolo Ferragina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Massucco_E/0/1/0/all/0/1&quot;&gt;Emanuele Massucco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pedreschi_D/0/1/0/all/0/1&quot;&gt;Dino Pedreschi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Giannotti_F/0/1/0/all/0/1&quot;&gt;Fosca Giannotti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05733">
<title>Fair Clustering Through Fairlets. (arXiv:1802.05733v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.05733</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the question of fair clustering under the {\em disparate impact}
doctrine, where each protected class must have approximately equal
representation in every cluster. We formulate the fair clustering problem under
both the $k$-center and the $k$-median objectives, and show that even with two
protected classes the problem is challenging, as the optimum solution can
violate common conventions---for instance a point may no longer be assigned to
its nearest cluster center! En route we introduce the concept of fairlets,
which are minimal sets that satisfy fair representation while approximately
preserving the clustering objective. We show that any fair clustering problem
can be decomposed into first finding good fairlets, and then using existing
machinery for traditional clustering algorithms. While finding good fairlets
can be NP-hard, we proceed to obtain efficient approximation algorithms based
on minimum cost flow. We empirically quantify the value of fair clustering on
real-world datasets with sensitive attributes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chierichetti_F/0/1/0/all/0/1&quot;&gt;Flavio Chierichetti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_R/0/1/0/all/0/1&quot;&gt;Ravi Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lattanzi_S/0/1/0/all/0/1&quot;&gt;Silvio Lattanzi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vassilvitskii_S/0/1/0/all/0/1&quot;&gt;Sergei Vassilvitskii&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05757">
<title>Stochastic Wasserstein Barycenters. (arXiv:1802.05757v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.05757</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a stochastic algorithm to compute the barycenter of a set of
probability distributions under the Wasserstein metric from optimal transport.
Unlike previous approaches, our method extends to continuous input
distributions and allows the support of the barycenter to be adjusted in each
iteration. We tackle the problem without regularization, allowing us to recover
a sharp output whose support is contained within the support of the true
barycenter. We give examples where our algorithm recovers a more meaningful
barycenter than previous work. Our method is versatile and can be extended to
applications such as generating super samples from a given distribution and
recovering blue noise approximations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Claici_S/0/1/0/all/0/1&quot;&gt;Sebastian Claici&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chien_E/0/1/0/all/0/1&quot;&gt;Edward Chien&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Solomon_J/0/1/0/all/0/1&quot;&gt;Justin Solomon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05811">
<title>Distributed Stochastic Optimization via Adaptive Stochastic Gradient Descent. (arXiv:1802.05811v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.05811</link>
<description rdf:parseType="Literal">&lt;p&gt;Stochastic convex optimization algorithms are the most popular way to train
machine learning models on large-scale data. Scaling up the training process of
these models is crucial in many applications, but the most popular algorithm,
Stochastic Gradient Descent (SGD), is a serial algorithm that is surprisingly
hard to parallelize. In this paper, we propose an efficient distributed
stochastic optimization method based on adaptive step sizes and variance
reduction techniques. We achieve a linear speedup in the number of machines,
small memory footprint, and only a small number of synchronization rounds --
logarithmic in dataset size -- in which the computation nodes communicate with
each other. Critically, our approach is a general reduction than parallelizes
any serial SGD algorithm, allowing us to leverage the significant progress that
has been made in designing adaptive SGD algorithms. We conclude by implementing
our algorithm in the Spark distributed framework and exhibit dramatic
performance gains on large-scale logistic regression problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cutkosky_A/0/1/0/all/0/1&quot;&gt;Ashok Cutkosky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Busa_Fekete_R/0/1/0/all/0/1&quot;&gt;Robert Busa-Fekete&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05814">
<title>Variational Autoencoders for Collaborative Filtering. (arXiv:1802.05814v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.05814</link>
<description rdf:parseType="Literal">&lt;p&gt;We extend variational autoencoders (VAEs) to collaborative filtering for
implicit feedback. This non-linear probabilistic model enables us to go beyond
the limited modeling capacity of linear factor models which still largely
dominate collaborative filtering research.We introduce a generative model with
multinomial likelihood and use Bayesian inference for parameter estimation.
Despite widespread use in language modeling and economics, the multinomial
likelihood receives less attention in the recommender systems literature. We
introduce a different regularization parameter for the learning objective,
which proves to be crucial for achieving competitive performance. Remarkably,
there is an efficient way to tune the parameter using annealing. The resulting
model and learning algorithm has information-theoretic connections to maximum
entropy discrimination and the information bottleneck principle. Empirically,
we show that the proposed approach significantly outperforms several
state-of-the-art baselines, including two recently-proposed neural network
approaches, on several real-world datasets. We also provide extended
experiments comparing the multinomial likelihood with other commonly used
likelihood functions in the latent factor collaborative filtering literature
and show favorable results. Finally, we identify the pros and cons of employing
a principled Bayesian inference approach and characterize settings where it
provides the most significant improvements.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liang_D/0/1/0/all/0/1&quot;&gt;Dawen Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Krishnan_R/0/1/0/all/0/1&quot;&gt;Rahul G. Krishnan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hoffman_M/0/1/0/all/0/1&quot;&gt;Matthew D. Hoffman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jebara_T/0/1/0/all/0/1&quot;&gt;Tony Jebara&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05821">
<title>Learning Latent Features with Pairwise Penalties in Matrix Completion. (arXiv:1802.05821v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.05821</link>
<description rdf:parseType="Literal">&lt;p&gt;Low-rank matrix completion (MC) has achieved great success in many real-world
data applications. A latent feature model formulation is usually employed and,
to improve prediction performance, the similarities between latent variables
can be exploited by pairwise learning, e.g., the graph regularized matrix
factorization (GRMF) method. However, existing GRMF approaches often use a
squared L2 norm to measure the pairwise difference, which may be overly
influenced by dissimilar pairs and lead to inferior prediction. To fully
empower pairwise learning for matrix completion, we propose a general
optimization framework that allows a rich class of (non-)convex pairwise
penalty functions. A new and efficient algorithm is further developed to
uniformly solve the optimization problem, with a theoretical convergence
guarantee. In an important situation where the latent variables form a small
number of subgroups, its statistical guarantee is also fully characterized. In
particular, we theoretically characterize the complexity-regularized maximum
likelihood estimator, as a special case of our framework. It has a better error
bound when compared to the standard trace-norm regularized matrix completion.
We conduct extensive experiments on both synthetic and real datasets to
demonstrate the superior performance of this general framework.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ji_K/0/1/0/all/0/1&quot;&gt;Kaiyi Ji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tan_J/0/1/0/all/0/1&quot;&gt;Jian Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chi_Y/0/1/0/all/0/1&quot;&gt;Yuejie Chi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xu_J/0/1/0/all/0/1&quot;&gt;Jinfeng Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05822">
<title>Auto-Encoding Total Correlation Explanation. (arXiv:1802.05822v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.05822</link>
<description rdf:parseType="Literal">&lt;p&gt;Advances in unsupervised learning enable reconstruction and generation of
samples from complex distributions, but this success is marred by the
inscrutability of the representations learned. We propose an
information-theoretic approach to characterizing disentanglement and dependence
in representation learning using multivariate mutual information, also called
total correlation. The principle of total Cor-relation Ex-planation (CorEx) has
motivated successful unsupervised learning applications across a variety of
domains, but under some restrictive assumptions. Here we relax those
restrictions by introducing a flexible variational lower bound to CorEx.
Surprisingly, we find that this lower bound is equivalent to the one in
variational autoencoders (VAE) under certain conditions. This
information-theoretic view of VAE deepens our understanding of hierarchical VAE
and motivates a new algorithm, AnchorVAE, that makes latent codes more
interpretable through information maximization and enables generation of richer
and more realistic samples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1&quot;&gt;Shuyang Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brekelmans_R/0/1/0/all/0/1&quot;&gt;Rob Brekelmans&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Steeg_G/0/1/0/all/0/1&quot;&gt;Greg Ver Steeg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Galstyan_A/0/1/0/all/0/1&quot;&gt;Aram Galstyan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05841">
<title>Rapid Bayesian optimisation for synthesis of short polymer fiber materials. (arXiv:1802.05841v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.05841</link>
<description rdf:parseType="Literal">&lt;p&gt;The discovery of processes for the synthesis of new materials involves many
decisions about process design, operation, and material properties.
Experimentation is crucial but as complexity increases, exploration of
variables can become impractical using traditional combinatorial approaches. We
describe an iterative method which uses machine learning to optimise process
development, incorporating multiple qualitative and quantitative objectives. We
demonstrate the method with a novel fluid processing platform for synthesis of
short polymer fibers, and show how the synthesis process can be efficiently
directed to achieve material and process objectives.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Cheng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Leal_D/0/1/0/all/0/1&quot;&gt;David Rubin de Celis Leal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rana_S/0/1/0/all/0/1&quot;&gt;Santu Rana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gupta_S/0/1/0/all/0/1&quot;&gt;Sunil Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sutti_A/0/1/0/all/0/1&quot;&gt;Alessandra Sutti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Greenhill_S/0/1/0/all/0/1&quot;&gt;Stewart Greenhill&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Slezak_T/0/1/0/all/0/1&quot;&gt;Teo Slezak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Height_M/0/1/0/all/0/1&quot;&gt;Murray Height&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Venkatesh_S/0/1/0/all/0/1&quot;&gt;Svetha Venkatesh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05872">
<title>Online Machine Learning in Big Data Streams. (arXiv:1802.05872v1 [cs.DC])</title>
<link>http://arxiv.org/abs/1802.05872</link>
<description rdf:parseType="Literal">&lt;p&gt;The area of online machine learning in big data streams covers algorithms
that are (1) distributed and (2) work from data streams with only a limited
possibility to store past data. The first requirement mostly concerns software
architectures and efficient algorithms. The second one also imposes nontrivial
theoretical restrictions on the modeling methods: In the data stream model,
older data is no longer available to revise earlier suboptimal modeling
decisions as the fresh data arrives.
&lt;/p&gt;
&lt;p&gt;In this article, we provide an overview of distributed software architectures
and libraries as well as machine learning models for online learning. We
highlight the most important ideas for classification, regression,
recommendation, and unsupervised modeling from streaming data, and we show how
they are implemented in various distributed data stream processing systems.
&lt;/p&gt;
&lt;p&gt;This article is a reference material and not a survey. We do not attempt to
be comprehensive in describing all existing methods and solutions; rather, we
give pointers to the most important resources in the field. All related
sub-fields, online algorithms, online learning, and distributed data processing
are hugely dominant in current research and development with conceptually new
research results and software components emerging at the time of writing. In
this article, we refer to several survey results, both for distributed data
processing and for online machine learning. Compared to past surveys, our
article is different because we discuss recommender systems in extended detail.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Benczur_A/0/1/0/all/0/1&quot;&gt;Andr&amp;#xe1;s A. Bencz&amp;#xfa;r&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kocsis_L/0/1/0/all/0/1&quot;&gt;Levente Kocsis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Palovics_R/0/1/0/all/0/1&quot;&gt;R&amp;#xf3;bert P&amp;#xe1;lovics&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05910">
<title>Pattern Localization in Time Series through Signal-To-Model Alignment in Latent Space. (arXiv:1802.05910v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.05910</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we study the problem of locating a predefined sequence of
patterns in a time series. In particular, the studied scenario assumes a
theoretical model is available that contains the expected locations of the
patterns. This problem is found in several contexts, and it is commonly solved
by first synthesizing a time series from the model, and then aligning it to the
true time series through dynamic time warping. We propose a technique that
increases the similarity of both time series before aligning them, by mapping
them into a latent correlation space. The mapping is learned from the data
through a machine-learning setup. Experiments on data from non-destructive
testing demonstrate that the proposed approach shows significant improvements
over the state of the art.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vaerenbergh_S/0/1/0/all/0/1&quot;&gt;Steven Van Vaerenbergh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Santamaria_I/0/1/0/all/0/1&quot;&gt;Ignacio Santamaria&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elvira_V/0/1/0/all/0/1&quot;&gt;Victor Elvira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salvatori_M/0/1/0/all/0/1&quot;&gt;Matteo Salvatori&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05968">
<title>Information Theory: A Tutorial Introduction. (arXiv:1802.05968v1 [cs.IT])</title>
<link>http://arxiv.org/abs/1802.05968</link>
<description rdf:parseType="Literal">&lt;p&gt;Shannon&apos;s mathematical theory of communication defines fundamental limits on
how much information can be transmitted between the different components of any
man-made or biological system. This paper is an informal but rigorous
introduction to the main ideas implicit in Shannon&apos;s theory. An annotated
reading list is provided for further reading.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stone_J/0/1/0/all/0/1&quot;&gt;James V Stone&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05980">
<title>WHInter: A Working set algorithm for High-dimensional sparse second order Interaction models. (arXiv:1802.05980v1 [q-bio.QM])</title>
<link>http://arxiv.org/abs/1802.05980</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning sparse linear models with two-way interactions is desirable in many
application domains such as genomics. l1-regularised linear models are popular
to estimate sparse models, yet standard implementations fail to address
specifically the quadratic explosion of candidate two-way interactions in high
dimensions, and typically do not scale to genetic data with hundreds of
thousands of features. Here we present WHInter, a working set algorithm to
solve large l1-regularised problems with two-way interactions for binary design
matrices. The novelty of WHInter stems from a new bound to efficiently identify
working sets while avoiding to scan all features, and on fast computations
inspired from solutions to the maximum inner product search problem. We apply
WHInter to simulated and real genetic data and show that it is more scalable
and two orders of magnitude faster than the state of the art.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Morvan_M/0/1/0/all/0/1&quot;&gt;Marine Le Morvan&lt;/a&gt; (CBIO), &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Vert_J/0/1/0/all/0/1&quot;&gt;Jean-Philippe Vert&lt;/a&gt; (CBIO, DMA)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05983">
<title>Disentangling by Factorising. (arXiv:1802.05983v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.05983</link>
<description rdf:parseType="Literal">&lt;p&gt;We define and address the problem of unsupervised learning of disentangled
representations on data generated from independent factors of variation. We
propose FactorVAE, a method that disentangles by encouraging the distribution
of representations to be factorial and hence independent across the dimensions.
We show that it improves upon $\beta$-VAE by providing a better trade-off
between disentanglement and reconstruction quality. Moreover, we highlight the
problems of a commonly used disentanglement metric and introduce a new metric
that does not suffer from them.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kim_H/0/1/0/all/0/1&quot;&gt;Hyunjik Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mnih_A/0/1/0/all/0/1&quot;&gt;Andriy Mnih&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06009">
<title>Dropout Model Evaluation in MOOCs. (arXiv:1802.06009v1 [stat.AP])</title>
<link>http://arxiv.org/abs/1802.06009</link>
<description rdf:parseType="Literal">&lt;p&gt;The field of learning analytics needs to adopt a more rigorous approach for
predictive model evaluation that matches the complex practice of
model-building. In this work, we present a procedure to statistically test
hypotheses about model performance which goes beyond the state-of-the-practice
in the community to analyze both algorithms and feature extraction methods from
raw data. We apply this method to a series of algorithms and feature sets
derived from a large sample of Massive Open Online Courses (MOOCs). While a
complete comparison of all potential modeling approaches is beyond the scope of
this paper, we show that this approach reveals a large gap in dropout
prediction performance between forum-, assignment-, and clickstream-based
feature extraction methods, where the latter is significantly better than the
former two, which are in turn indistinguishable from one another. This work has
methodological implications for evaluating predictive or AI-based models of
student success, and practical implications for the design and targeting of
at-risk student models and interventions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gardner_J/0/1/0/all/0/1&quot;&gt;Josh Gardner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Brooks_C/0/1/0/all/0/1&quot;&gt;Christopher Brooks&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06014">
<title>Orthogonality-Promoting Distance Metric Learning: Convex Relaxation and Theoretical Analysis. (arXiv:1802.06014v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.06014</link>
<description rdf:parseType="Literal">&lt;p&gt;Distance metric learning (DML), which learns a distance metric from labeled
&quot;similar&quot; and &quot;dissimilar&quot; data pairs, is widely utilized. Recently, several
works investigate orthogonality-promoting regularization (OPR), which
encourages the projection vectors in DML to be close to being orthogonal, to
achieve three effects: (1) high balancedness -- achieving comparable
performance on both frequent and infrequent classes; (2) high compactness --
using a small number of projection vectors to achieve a &quot;good&quot; metric; (3) good
generalizability -- alleviating overfitting to training data. While showing
promising results, these approaches suffer three problems. First, they involve
solving non-convex optimization problems where achieving the global optimal is
NP-hard. Second, it lacks a theoretical understanding why OPR can lead to
balancedness. Third, the current generalization error analysis of OPR is not
directly on the regularizer. In this paper, we address these three issues by
(1) seeking convex relaxations of the original nonconvex problems so that the
global optimal is guaranteed to be achievable; (2) providing a formal analysis
on OPR&apos;s capability of promoting balancedness; (3) providing a theoretical
analysis that directly reveals the relationship between OPR and generalization
performance. Experiments on various datasets demonstrate that our convex
methods are more effective in promoting balancedness, compactness, and
generalization, and are computationally more efficient, compared with the
nonconvex methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_P/0/1/0/all/0/1&quot;&gt;Pengtao Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1&quot;&gt;Wei Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1&quot;&gt;Yichen Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1&quot;&gt;Eric P. Xing&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06037">
<title>Policy Evaluation and Optimization with Continuous Treatments. (arXiv:1802.06037v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.06037</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the problem of policy evaluation and learning from batched
contextual bandit data when treatments are continuous, going beyond previous
work on discrete treatments. Previous work for discrete treatment/action spaces
focuses on inverse probability weighting (IPW) and doubly robust (DR) methods
that use a rejection sampling approach for evaluation and the equivalent
weighted classification problem for learning. In the continuous setting, this
reduction fails as we would almost surely reject all observations. To tackle
the case of continuous treatments, we extend the IPW and DR approaches to the
continuous setting using a kernel function that leverages treatment proximity
to attenuate discrete rejection. Our policy estimator is consistent and we
characterize the optimal bandwidth. The resulting continuous policy optimizer
(CPO) approach using our estimator achieves convergent regret and approaches
the best-in-class policy for learnable policy classes. We demonstrate that the
estimator performs well and, in particular, outperforms a discretization-based
benchmark. We further study the performance of our policy optimizer in a case
study on personalized dosing based on a dataset of Warfarin patients, their
covariates, and final therapeutic doses. Our learned policy outperforms
benchmarks and nears the oracle-best linear policy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kallus_N/0/1/0/all/0/1&quot;&gt;Nathan Kallus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhou_A/0/1/0/all/0/1&quot;&gt;Angela Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1606.00451">
<title>Graph-Guided Banding of the Covariance Matrix. (arXiv:1606.00451v2 [stat.ME] UPDATED)</title>
<link>http://arxiv.org/abs/1606.00451</link>
<description rdf:parseType="Literal">&lt;p&gt;Regularization has become a primary tool for developing reliable estimators
of the covariance matrix in high-dimensional settings. To curb the curse of
dimensionality, numerous methods assume that the population covariance (or
inverse covariance) matrix is sparse, while making no particular structural
assumptions on the desired pattern of sparsity. A highly-related, yet
complementary, literature studies the specific setting in which the measured
variables have a known ordering, in which case a banded population matrix is
often assumed. While the banded approach is conceptually and computationally
easier than asking for &quot;patternless sparsity,&quot; it is only applicable in very
specific situations (such as when data are measured over time or
one-dimensional space). This work proposes a generalization of the notion of
bandedness that greatly expands the range of problems in which banded
estimators apply.
&lt;/p&gt;
&lt;p&gt;We develop convex regularizers occupying the broad middle ground between the
former approach of &quot;patternless sparsity&quot; and the latter reliance on having a
known ordering. Our framework defines bandedness with respect to a known graph
on the measured variables. Such a graph is available in diverse situations, and
we provide a theoretical, computational, and applied treatment of two new
estimators. An R package, called ggb, implements these new methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bien_J/0/1/0/all/0/1&quot;&gt;Jacob Bien&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1610.06462">
<title>Gaussian process modeling in approximate Bayesian computation to estimate horizontal gene transfer in bacteria. (arXiv:1610.06462v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1610.06462</link>
<description rdf:parseType="Literal">&lt;p&gt;Approximate Bayesian computation (ABC) can be used for model fitting when the
likelihood function is intractable but simulating from the model is feasible.
However, even a single evaluation of a complex model may take several hours,
limiting the number of model evaluations available. Modelling the discrepancy
between the simulated and observed data using a Gaussian process (GP) can be
used to reduce the number of model evaluations required by ABC, but the
sensitivity of this approach to a specific GP formulation has not yet been
thoroughly investigated. We begin with a comprehensive empirical evaluation of
using GPs in ABC, including various transformations of the discrepancies and
two novel GP formulations. Our results indicate the choice of GP may
significantly affect the accuracy of the estimated posterior distribution.
Selection of an appropriate GP model is thus important. We formulate expected
utility to measure the accuracy of classifying discrepancies below or above the
ABC threshold, and show that it can be used to automate the GP model selection
step. Finally, based on the understanding gained with toy examples, we fit a
population genetic model for bacteria, providing insight into horizontal gene
transfer events within the population and from external origins.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jarvenpaa_M/0/1/0/all/0/1&quot;&gt;Marko J&amp;#xe4;rvenp&amp;#xe4;&amp;#xe4;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gutmann_M/0/1/0/all/0/1&quot;&gt;Michael Gutmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vehtari_A/0/1/0/all/0/1&quot;&gt;Aki Vehtari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Marttinen_P/0/1/0/all/0/1&quot;&gt;Pekka Marttinen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1704.09011">
<title>Mostly Exploration-Free Algorithms for Contextual Bandits. (arXiv:1704.09011v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1704.09011</link>
<description rdf:parseType="Literal">&lt;p&gt;The contextual bandit literature has traditionally focused on algorithms that
address the exploration-exploitation tradeoff. In particular, greedy algorithms
that exploit current estimates without any exploration may be sub-optimal in
general. However, exploration-free greedy algorithms are desirable in practical
settings where exploration may be costly or unethical (e.g., clinical trials).
Surprisingly, we find that a simple greedy algorithm can be rate-optimal if
there is sufficient randomness in the observed contexts. We prove that this is
always the case for a two-armed bandit under a general class of context
distributions that satisfy a condition we term covariate diversity.
Furthermore, even absent this condition, we show that a greedy algorithm can be
rate-optimal with nonzero probability. Thus, standard bandit algorithms may
unnecessarily explore. Motivated by these results, we introduce Greedy-First, a
new algorithm that uses only observed contexts and rewards to determine whether
to follow a greedy algorithm or to explore. We prove that this algorithm is
rate-optimal without any additional assumptions on the context distribution or
the number of arms. Extensive simulations demonstrate that Greedy-First
successfully reduces experimentation and outperforms existing
(exploration-based) contextual bandit algorithms such as Thompson sampling or
UCB.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bastani_H/0/1/0/all/0/1&quot;&gt;Hamsa Bastani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bayati_M/0/1/0/all/0/1&quot;&gt;Mohsen Bayati&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Khosravi_K/0/1/0/all/0/1&quot;&gt;Khashayar Khosravi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.01383">
<title>Variance-Reduced Stochastic Learning under Random Reshuffling. (arXiv:1708.01383v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1708.01383</link>
<description rdf:parseType="Literal">&lt;p&gt;Several useful variance-reduced stochastic gradient algorithms, such as SVRG,
SAGA, Finito, and SAG, have been proposed to minimize empirical risks with
linear convergence properties to the exact minimizer. The existing convergence
results assume uniform data sampling with replacement. However, it has been
observed in related works that random reshuffling can deliver superior
performance over uniform sampling and, yet, no formal proofs or guarantees of
exact convergence exist for variance-reduced algorithms under random
reshuffling. This paper makes two contributions. First, it resolves this open
issue and provides the first theoretical guarantee of linear convergence under
random reshuffling for SAGA; the argument is also adaptable to other
variance-reduced algorithms. Second, under random reshuffling, the paper
proposes a new amortized variance-reduced gradient (AVRG) algorithm with
constant storage requirements compared to SAGA and with balanced gradient
computations compared to SVRG. AVRG is also shown analytically to converge
linearly.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ying_B/0/1/0/all/0/1&quot;&gt;Bicheng Ying&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_K/0/1/0/all/0/1&quot;&gt;Kun Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sayed_A/0/1/0/all/0/1&quot;&gt;Ali H. Sayed&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.07164">
<title>Newton-Type Methods for Non-Convex Optimization Under Inexact Hessian Information. (arXiv:1708.07164v3 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/1708.07164</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider variants of trust-region and cubic regularization methods for
non-convex optimization, in which the Hessian matrix is approximated. Under
mild conditions on the inexact Hessian, and using approximate solution of the
corresponding sub-problems, we provide iteration complexity to achieve $
\epsilon $-approximate second-order optimality which have shown to be tight.
Our Hessian approximation conditions constitute a major relaxation over the
existing ones in the literature. Consequently, we are able to show that such
mild conditions allow for the construction of the approximate Hessian through
various random sampling methods. In this light, we consider the canonical
problem of finite-sum minimization, provide appropriate uniform and non-uniform
sub-sampling strategies to construct such Hessian approximations, and obtain
optimal iteration complexity for the corresponding sub-sampled trust-region and
cubic regularization methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Xu_P/0/1/0/all/0/1&quot;&gt;Peng Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Roosta_Khorasani_F/0/1/0/all/0/1&quot;&gt;Farbod Roosta-Khorasani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Mahoney_M/0/1/0/all/0/1&quot;&gt;Michael W. Mahoney&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.07827">
<title>Second-Order Optimization for Non-Convex Machine Learning: An Empirical Study. (arXiv:1708.07827v2 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/1708.07827</link>
<description rdf:parseType="Literal">&lt;p&gt;While first-order optimization methods such as stochastic gradient descent
(SGD) are popular in machine learning (ML), they come with well-known
deficiencies, including relatively-slow convergence, sensitivity to the
settings of hyper-parameters such as learning rate, stagnation at high training
errors, and difficulty in escaping flat regions and saddle points. These issues
are particularly acute in highly non-convex settings such as those arising in
neural networks. Motivated by this, there has been recent interest in
second-order methods that aim to alleviate these shortcomings by capturing
curvature information. In this paper, we report detailed empirical evaluations
of a class of Newton-type methods, namely sub-sampled variants of trust region
(TR) and adaptive regularization with cubics (ARC) algorithms, for non-convex
ML problems. In doing so, we demonstrate that these methods not only can be
computationally competitive with hand-tuned SGD with momentum, obtaining
comparable or better generalization performance, but also they are highly
robust to hyper-parameter settings. Further, in contrast to SGD with momentum,
we show that the manner in which these Newton-type methods employ curvature
information allows them to seamlessly escape flat regions and saddle points.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Xu_P/0/1/0/all/0/1&quot;&gt;Peng Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Roosta_Khorasani_F/0/1/0/all/0/1&quot;&gt;Farbod Roosta-Khorasani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Mahoney_M/0/1/0/all/0/1&quot;&gt;Michael W. Mahoney&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.06598">
<title>How Wrong Am I? - Studying Adversarial Examples and their Impact on Uncertainty in Gaussian Process Machine Learning Models. (arXiv:1711.06598v3 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/1711.06598</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning models are vulnerable to Adversarial Examples: minor
perturbations to input samples intended to deliberately cause
misclassification. Current defenses against adversarial examples, especially
for Deep Neural Networks (DNN), are primarily derived from empirical
developments, and their security guarantees are often only justified
retroactively. Many defenses therefore rely on hidden assumptions that are
subsequently subverted by increasingly elaborate attacks. This is not
surprising: deep learning notoriously lacks a comprehensive mathematical
framework to provide meaningful guarantees.
&lt;/p&gt;
&lt;p&gt;In this paper, we leverage Gaussian Processes to investigate adversarial
examples in the framework of Bayesian inference. Across different models and
datasets, we find deviating levels of uncertainty reflect the perturbation
introduced to benign samples by state-of-the-art attacks, including novel
white-box attacks on Gaussian Processes. Our experiments demonstrate that even
unoptimized uncertainty thresholds already reject adversarial examples in many
scenarios.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grosse_K/0/1/0/all/0/1&quot;&gt;Kathrin Grosse&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pfaff_D/0/1/0/all/0/1&quot;&gt;David Pfaff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smith_M/0/1/0/all/0/1&quot;&gt;Michael Thomas Smith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Backes_M/0/1/0/all/0/1&quot;&gt;Michael Backes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.00047">
<title>Matrix completion with deterministic pattern - a geometric perspective. (arXiv:1802.00047v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.00047</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the matrix completion problem with a deterministic pattern of
observed entries and aim to find conditions such that there will be (at least
locally) unique solution to the non-convex Minimum Rank Matrix Completion
(MRMC) formulation. We answer the question from a somewhat different point of
view and to give a geometric perspective. We give a sufficient and &quot;almost
necessary&quot; condition (which we call the well-posedness condition) for the local
uniqueness of MRMC solutions and illustrate with some special cases where such
condition can be verified. We also consider the convex relaxation and nuclear
norm minimization formulations. Then we argue that the low-rank approximation
approaches are more stable than MRMC and further propose a sequential
statistical testing procedure to determine the rank of the matrix from observed
entries. Finally, numerical examples verified the validity of our theory.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shapiro_A/0/1/0/all/0/1&quot;&gt;Alexander Shapiro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1&quot;&gt;Yao Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1&quot;&gt;Rui Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03001">
<title>Statistical Learnability of Generalized Additive Models based on Total Variation Regularization. (arXiv:1802.03001v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.03001</link>
<description rdf:parseType="Literal">&lt;p&gt;A generalized additive model (GAM, Hastie and Tibshirani (1987)) is a
nonparametric model by the sum of univariate functions with respect to each
explanatory variable, i.e., $f({\mathbf x}) = \sum f_j(x_j)$, where
$x_j\in\mathbb{R}$ is $j$-th component of a sample ${\mathbf x}\in
\mathbb{R}^p$. In this paper, we introduce the total variation (TV) of a
function as a measure of the complexity of functions in $L^1_{\rm
c}(\mathbb{R})$-space. Our analysis shows that a GAM based on TV-regularization
exhibits a Rademacher complexity of $O(\sqrt{\frac{\log p}{m}})$, which is
tight in terms of both $m$ and $p$ in the agnostic case of the classification
problem. In result, we obtain generalization error bounds for finite samples
according to work by Bartlett and Mandelson (2002).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Matsushima_S/0/1/0/all/0/1&quot;&gt;Shin Matsushima&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04956">
<title>D2KE: From Distance to Kernel and Embedding. (arXiv:1802.04956v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04956</link>
<description rdf:parseType="Literal">&lt;p&gt;For many machine learning problem settings, particularly with structured
inputs such as sequences or sets of objects, a distance measure between inputs
can be specified more naturally than a feature representation. However, most
standard machine models are designed for inputs with a vector feature
representation. In this work, we consider the estimation of a function
$f:\mathcal{X} \rightarrow \R$ based solely on a dissimilarity measure
$d:\mathcal{X}\times\mathcal{X} \rightarrow \R$ between inputs. In particular,
we propose a general framework to derive a family of \emph{positive definite
kernels} from a given dissimilarity measure, which subsumes the widely-used
\emph{representative-set method} as a special case, and relates to the
well-known \emph{distance substitution kernel} in a limiting case. We show that
functions in the corresponding Reproducing Kernel Hilbert Space (RKHS) are
Lipschitz-continuous w.r.t. the given distance metric. We provide a tractable
algorithm to estimate a function from this RKHS, and show that it enjoys better
generalizability than Nearest-Neighbor estimates. Our approach draws from the
literature of Random Features, but instead of deriving feature maps from an
existing kernel, we construct novel kernels from a random feature map, that we
specify given the distance measure. We conduct classification experiments with
such disparate domains as strings, time series, and sets of vectors, where our
proposed framework compares favorably to existing distance-based learning
methods such as $k$-nearest-neighbors, distance-substitution kernels,
pseudo-Euclidean embedding, and the representative-set method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wu_L/0/1/0/all/0/1&quot;&gt;Lingfei Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yen_I/0/1/0/all/0/1&quot;&gt;Ian En-Hsu Yen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xu_F/0/1/0/all/0/1&quot;&gt;Fangli Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ravikumar_P/0/1/0/all/0/1&quot;&gt;Pradeep Ravikumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Witbrock_M/0/1/0/all/0/1&quot;&gt;Michael Witbrock&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05074">
<title>L4: Practical loss-based stepsize adaptation for deep learning. (arXiv:1802.05074v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.05074</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a stepsize adaptation scheme for stochastic gradient descent. It
operates directly with the loss function and rescales the gradient in order to
make fixed predicted progress on the loss. We demonstrate its capabilities by
strongly improving the performance of Adam and Momentum optimizers. The
enhanced optimizers with default hyperparameters consistently outperform their
constant stepsize counterparts, even the best ones, without a measurable
increase in computational cost. The performance is validated on multiple
architectures including ResNets and the Differential Neural Computer. A
prototype implementation as a TensorFlow optimizer is released.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rolinek_M/0/1/0/all/0/1&quot;&gt;Michal Rolinek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martius_G/0/1/0/all/0/1&quot;&gt;Georg Martius&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05688">
<title>Simulation assisted machine learning. (arXiv:1802.05688v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.05688</link>
<description rdf:parseType="Literal">&lt;p&gt;Predicting how a proposed cancer treatment will affect a given tumor can be
cast as a machine learning problem, but the complexity of biological systems,
the number of potentially relevant genomic and clinical features, and the lack
of very large scale patient data repositories make this a unique challenge.
&quot;Pure data&quot; approaches to this problem are underpowered to detect
combinatorially complex interactions and are bound to uncover false
correlations despite statistical precautions taken (1). To investigate this
setting, we propose a method to integrate simulations, a strong form of prior
knowledge, into machine learning, a combination which to date has been largely
unexplored. The results of multiple simulations (under various uncertainty
scenarios) are used to compute similarity measures between every pair of
samples: sample pairs are given a high similarity score if they behave
similarly under a wide range of simulation parameters. These similarity values,
rather than the original high dimensional feature data, are used to train
kernelized machine learning algorithms such as support vector machines, thus
handling the curse-of-dimensionality that typically affects genomic machine
learning. Using four synthetic datasets of complex systems--three biological
models and one network flow optimization model--we demonstrate that when the
number of training samples is small compared to the number of features, the
simulation kernel approach dominates over no-prior-knowledge methods. In
addition to biology and medicine, this approach should be applicable to other
disciplines, such as weather forecasting, financial markets, and agricultural
management, where predictive models are sought and informative yet approximate
simulations are available. The Python SimKern software, the models (in MATLAB,
Octave, and R), and the datasets are made freely available at
https://github.com/davidcraft/SimKern.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Deist_T/0/1/0/all/0/1&quot;&gt;Timo Deist&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Patti_A/0/1/0/all/0/1&quot;&gt;Andrew Patti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhaoqi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Krane_D/0/1/0/all/0/1&quot;&gt;David Krane&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sorenson_T/0/1/0/all/0/1&quot;&gt;Taylor Sorenson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Craft_D/0/1/0/all/0/1&quot;&gt;David Craft&lt;/a&gt;</dc:creator>
</item></rdf:RDF>