<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-02-22T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1701.07879"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.10119"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.10704"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.07810"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.07814"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.07833"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.07842"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.07846"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08138"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08183"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08201"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1604.05636"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.07654"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.00740"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.01788"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.07284"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.07444"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.07756"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.07773"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.07796"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.07834"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.07889"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.07917"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.07927"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.07928"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.07935"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.07954"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.07971"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08009"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08012"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08021"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08061"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08089"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08139"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08163"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08167"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08242"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1703.01610"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1704.01665"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.04293"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.07606"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.06491"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.06878"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.06315"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.07283"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.01796"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.08824"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.04695"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03569"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04852"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.07481"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1701.07879">
<title>A Radically New Theory of how the Brain Represents and Computes with Probabilities. (arXiv:1701.07879v4 [q-bio.NC] UPDATED)</title>
<link>http://arxiv.org/abs/1701.07879</link>
<description rdf:parseType="Literal">&lt;p&gt;The brain is believed to implement probabilistic reasoning and to represent
information via population, or distributed, coding. Most previous
population-based probabilistic (PPC) theories share several basic properties:
1) continuous-valued neurons; 2) fully(densely)-distributed codes, i.e.,
all(most) units participate in every code; 3) graded synapses; 4) rate coding;
5) units have innate unimodal tuning functions (TFs); 6) intrinsically noisy
units; and 7) noise/correlation is considered harmful. We present a radically
different theory that assumes: 1) binary units; 2) only a small subset of
units, i.e., a sparse distributed representation (SDR) (cell assembly),
comprises any individual code; 3) binary synapses; 4) signaling formally
requires only single (i.e., first) spikes; 5) units initially have completely
flat TFs (all weights zero); 6) units are far less intrinsically noisy than
traditionally thought; rather 7) noise is a resource generated/used to cause
similar inputs to map to similar codes, controlling a tradeoff between storage
capacity and embedding the input space statistics in the pattern of
intersections over stored codes, epiphenomenally determining correlation
patterns across neurons. The theory, Sparsey, was introduced 20+ years ago as a
canonical cortical circuit/algorithm model achieving efficient sequence
learning/recognition, but not elaborated as an alternative to PPC theories.
Here, we show that: a) the active SDR simultaneously represents both the most
similar/likely input and the entire (coarsely-ranked) similarity
likelihood/distribution over all stored inputs (hypotheses); and b) given an
input, the SDR code selection algorithm, which underlies both learning and
inference, updates both the most likely hypothesis and the entire likelihood
distribution (cf. belief update) with a number of steps that remains constant
as the number of stored items increases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Rinkus_G/0/1/0/all/0/1&quot;&gt;Gerard Rinkus&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.10119">
<title>Kernel Implicit Variational Inference. (arXiv:1705.10119v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1705.10119</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent progress in variational inference has paid much attention to the
flexibility of variational posteriors. One promising direction is to use
implicit distributions, i.e., distributions without tractable densities as the
variational posterior. However, existing methods on implicit posteriors still
face challenges of noisy estimation and computational infeasibility when
applied to models with high-dimensional latent variables. In this paper, we
present a new approach named Kernel Implicit Variational Inference that
addresses these challenges. As far as we know, for the first time implicit
variational inference is successfully applied to Bayesian neural networks,
which shows promising results on both regression and classification tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shi_J/0/1/0/all/0/1&quot;&gt;Jiaxin Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sun_S/0/1/0/all/0/1&quot;&gt;Shengyang Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhu_J/0/1/0/all/0/1&quot;&gt;Jun Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.10704">
<title>Training Probabilistic Spiking Neural Networks with First-to-spike Decoding. (arXiv:1710.10704v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1710.10704</link>
<description rdf:parseType="Literal">&lt;p&gt;Third-generation neural networks, or Spiking Neural Networks (SNNs), aim at
harnessing the energy efficiency of spike-domain processing by building on
computing elements that operate on, and exchange, spikes. In this paper, the
problem of training a two-layer SNN is studied for the purpose of
classification, under a Generalized Linear Model (GLM) probabilistic neural
model that was previously considered within the computational neuroscience
literature. Conventional classification rules for SNNs operate offline based on
the number of output spikes at each output neuron. In contrast, a novel
training method is proposed here for a first-to-spike decoding rule, whereby
the SNN can perform an early classification decision once spike firing is
detected at an output neuron. Numerical results bring insights into the optimal
parameter selection for the GLM neuron and on the accuracy-complexity trade-off
performance of conventional and first-to-spike decoding.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bagheri_A/0/1/0/all/0/1&quot;&gt;Alireza Bagheri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Simeone_O/0/1/0/all/0/1&quot;&gt;Osvaldo Simeone&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rajendran_B/0/1/0/all/0/1&quot;&gt;Bipin Rajendran&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.07810">
<title>Manipulating and Measuring Model Interpretability. (arXiv:1802.07810v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.07810</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite a growing body of research focused on creating interpretable machine
learning methods, there have been few empirical studies verifying whether
interpretable methods achieve their intended effects on end users. We present a
framework for assessing the effects of model interpretability on users via
pre-registered experiments in which participants are shown functionally
identical models that vary in factors thought to influence interpretability.
Using this framework, we ran a sequence of large-scale randomized experiments,
varying two putative drivers of interpretability: the number of features and
the model transparency (clear or black-box). We measured how these factors
impact trust in model predictions, the ability to simulate a model, and the
ability to detect a model&apos;s mistakes. We found that participants who were shown
a clear model with a small number of features were better able to simulate the
model&apos;s predictions. However, we found no difference in multiple measures of
trust and found that clear models did not improve the ability to correct
mistakes. These findings suggest that interpretability research could benefit
from more emphasis on empirically verifying that interpretable models achieve
all their intended effects.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poursabzi_Sangdeh_F/0/1/0/all/0/1&quot;&gt;Forough Poursabzi-Sangdeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goldstein_D/0/1/0/all/0/1&quot;&gt;Daniel G. Goldstein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hofman_J/0/1/0/all/0/1&quot;&gt;Jake M. Hofman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vaughan_J/0/1/0/all/0/1&quot;&gt;Jennifer Wortman Vaughan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wallach_H/0/1/0/all/0/1&quot;&gt;Hanna Wallach&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.07814">
<title>Learning to Explain: An Information-Theoretic Perspective on Model Interpretation. (arXiv:1802.07814v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.07814</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce instancewise feature selection as a methodology for model
interpretation. Our method is based on learning a function to extract a subset
of features that are most informative for each given example. This feature
selector is trained to maximize the mutual information between selected
features and the response variable, where the conditional distribution of the
response variable given the input is the model to be explained. We develop an
efficient variational approximation to the mutual information, and show that
the resulting method compares favorably to other model explanation methods on a
variety of synthetic and real data sets using both quantitative metrics and
human evaluation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jianbo Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1&quot;&gt;Le Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wainwright_M/0/1/0/all/0/1&quot;&gt;Martin J. Wainwright&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1&quot;&gt;Michael I. Jordan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.07833">
<title>Variational Inference for Policy Gradient. (arXiv:1802.07833v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.07833</link>
<description rdf:parseType="Literal">&lt;p&gt;Inspired by the seminal work on Stein Variational Inference and Stein
Variational Policy Gradient, we derived a method to generate samples from the
posterior variational parameter distribution by \textit{explicitly} minimizing
the KL divergence to match the target distribution in an amortize fashion.
Consequently, we applied this varational inference technique into vanilla
policy gradient, TRPO and PPO with Bayesian Neural Network parameterizations
for reinforcement learning problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1&quot;&gt;Tianbing Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.07842">
<title>Convergent Actor-Critic Algorithms Under Off-Policy Training and Function Approximation. (arXiv:1802.07842v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.07842</link>
<description rdf:parseType="Literal">&lt;p&gt;We present the first class of policy-gradient algorithms that work with both
state-value and policy function-approximation, and are guaranteed to converge
under off-policy training. Our solution targets problems in reinforcement
learning where the action representation adds to the-curse-of-dimensionality;
that is, with continuous or large action sets, thus making it infeasible to
estimate state-action value functions (Q functions). Using state-value
functions helps to lift the curse and as a result naturally turn our
policy-gradient solution into classical Actor-Critic architecture whose Actor
uses state-value function for the update. Our algorithms, Gradient Actor-Critic
and Emphatic Actor-Critic, are derived based on the exact gradient of averaged
state-value function objective and thus are guaranteed to converge to its
optimal solution, while maintaining all the desirable properties of classical
Actor-Critic methods with no additional hyper-parameters. To our knowledge,
this is the first time that convergent off-policy learning methods have been
extended to classical Actor-Critic methods with function approximation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maei_H/0/1/0/all/0/1&quot;&gt;Hamid Reza Maei&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.07846">
<title>Cross-Modality Synthesis from CT to PET using FCN and GAN Networks for Improved Automated Lesion Detection. (arXiv:1802.07846v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1802.07846</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work we present a novel system for generation of virtual PET images
using CT scans. We combine a fully convolutional network (FCN) with a
conditional generative adversarial network (GAN) to generate simulated PET data
from given input CT data. The synthesized PET can be used for false-positive
reduction in lesion detection solutions. Clinically, such solutions may enable
lesion detection and drug treatment evaluation in a CT-only environment, thus
reducing the need for the more expensive and radioactive PET/CT scan. Our
dataset includes 60 PET/CT scans from Sheba Medical center. We used 23 scans
for training and 37 for testing. Different schemes to achieve the synthesized
output were qualitatively compared. Quantitative evaluation was conducted using
an existing lesion detection software, combining the synthesized PET as a false
positive reduction layer for the detection of malignant lesions in the liver.
Current results look promising showing a 28% reduction in the average false
positive per case from 2.9 to 2.1. The suggested solution is comprehensive and
can be expanded to additional body organs, and different modalities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ben_Cohen_A/0/1/0/all/0/1&quot;&gt;Avi Ben-Cohen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klang_E/0/1/0/all/0/1&quot;&gt;Eyal Klang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raskin_S/0/1/0/all/0/1&quot;&gt;Stephen P. Raskin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soffer_S/0/1/0/all/0/1&quot;&gt;Shelly Soffer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ben_Haim_S/0/1/0/all/0/1&quot;&gt;Simona Ben-Haim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Konen_E/0/1/0/all/0/1&quot;&gt;Eli Konen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amitai_M/0/1/0/all/0/1&quot;&gt;Michal Marianne Amitai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Greenspan_H/0/1/0/all/0/1&quot;&gt;Hayit Greenspan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08138">
<title>Reliable Intersection Control in Non-cooperative Environments. (arXiv:1802.08138v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.08138</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a reliable intersection control mechanism for strategic autonomous
and connected vehicles (agents) in non-cooperative environments. Each agent has
access to his/her earliest possible and desired passing times, and reports a
passing time to the intersection manager, who allocates the intersection
temporally to the agents in a First-Come-First-Serve basis. However, the agents
might have conflicting interests and can take actions strategically. To this
end, we analyze the strategic behaviors of the agents and formulate Nash
equilibria for all possible scenarios. Furthermore, among all Nash equilibria
we identify a socially optimal equilibrium that leads to a fair intersection
allocation, and correspondingly we describe a strategy-proof intersection
mechanism, which achieves reliable intersection control such that the strategic
agents do not have any incentive to misreport their passing times
strategically.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sayin_M/0/1/0/all/0/1&quot;&gt;Muhammed O. Sayin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1&quot;&gt;Chung-Wei Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shiraishi_S/0/1/0/all/0/1&quot;&gt;Shinichi Shiraishi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Basar_T/0/1/0/all/0/1&quot;&gt;Tamer Ba&amp;#x15f;ar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08183">
<title>Projection-Free Online Optimization with Stochastic Gradient: From Convexity to Submodularity. (arXiv:1802.08183v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.08183</link>
<description rdf:parseType="Literal">&lt;p&gt;Online optimization has been a successful framework for solving large-scale
problems under computational constraints and partial information. Current
methods for online convex optimization require either a projection or exact
gradient computation at each step, both of which can be prohibitively expensive
for large-scale applications. At the same time, there is a growing trend of
non-convex optimization in machine learning community and a need for online
methods. Continuous submodular functions, which exhibit a natural diminishing
returns condition, have recently been proposed as a broad class of non-convex
functions which may be efficiently optimized. Although online methods have been
introduced, they suffer from similar problems. In this work, we propose
Meta-Frank-Wolfe, the first online projectionfree algorithm that uses
stochastic gradient estimates. The algorithm relies on a careful sampling of
gradients in each round and achieves the optimal $O(\sqrt{T})$ adversarial
regret bounds for convex and continuous submodular optimization. We also
propose One-Shot Frank-Wolfe, a simpler algorithm which requires only a single
stochastic gradient estimate in each round and achieves a $O(T^{2/3})$
stochastic regret bound for convex and continuous submodular optimization. We
apply our methods to develop a novel &quot;lifting&quot; framework for the online
discrete submodular maximization and also see that they outperform current
state of the art techniques on an extensive set of experiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Lin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Harshaw_C/0/1/0/all/0/1&quot;&gt;Christopher Harshaw&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hassani_H/0/1/0/all/0/1&quot;&gt;Hamed Hassani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Karbasi_A/0/1/0/all/0/1&quot;&gt;Amin Karbasi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08201">
<title>A Polynomial Time Subsumption Algorithm for Nominal Safe $\mathcal{ELO}_\bot$ under Rational Closure. (arXiv:1802.08201v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.08201</link>
<description rdf:parseType="Literal">&lt;p&gt;Description Logics (DLs) under Rational Closure (RC) is a well-known
framework for non-monotonic reasoning in DLs. In this paper, we address the
concept subsumption decision problem under RC for nominal safe
$\mathcal{ELO}_\bot$, a notable and practically important DL representative of
the OWL 2 profile OWL 2 EL.
&lt;/p&gt;
&lt;p&gt;Our contribution here is to define a polynomial time subsumption procedure
for nominal safe $\mathcal{ELO}_\bot$ under RC that relies entirely on a series
of classical, monotonic $\mathcal{EL}_\bot$ subsumption tests. Therefore, any
existing classical monotonic $\mathcal{EL}_\bot$ reasoner can be used as a
black box to implement our method. We then also adapt the method to one of the
known extensions of RC for DLs, namely Defeasible Inheritance-based DLs without
losing the computational tractability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Casini_G/0/1/0/all/0/1&quot;&gt;Giovanni Casini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Straccia_U/0/1/0/all/0/1&quot;&gt;Umberto Straccia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meyer_T/0/1/0/all/0/1&quot;&gt;Thomas Meyer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1604.05636">
<title>Pattern-Based Approach to the Workflow Satisfiability Problem with User-Independent Constraints. (arXiv:1604.05636v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1604.05636</link>
<description rdf:parseType="Literal">&lt;p&gt;The fixed parameter tractable (FPT) approach is a powerful tool in tackling
computationally hard problems. In this paper, we link FPT results to classic
artificial intelligence (AI) techniques to show how they complement each other.
Specifically, we consider the workflow satisfiability problem (WSP) which asks
whether there exists an assignment of authorised users to the steps in a
workflow specification, subject to certain constraints on the assignment. It
was shown by Cohen et al. (JAIR 2014) that WSP restricted to the class of
user-independent constraints (UI), covering many practical cases, admits FPT
algorithms, i.e. can be solved in time exponential only in the number of steps
$k$ and polynomial in the number of users $n$. Since usually $k \ll n$ in WSP,
such FPT algorithms are of great practical interest as they significantly
extend the size of the problem that can be routinely solved.
&lt;/p&gt;
&lt;p&gt;We give a new view of the FPT nature of the WSP with UI constraints, showing
that it decomposes the problem into two levels. Exploiting this two-level
split, we develop a new FPT algorithm that is by many orders of magnitude
faster than the previous state-of-the-art WSP algorithm; and it also has only
polynomial space complexity whereas the old algorithm takes memory exponential
in $k$, which limits its application.
&lt;/p&gt;
&lt;p&gt;We also provide a new pseudo-boolean (PB) formulation of the WSP with UI
constraints which exploits this new decomposition of the problem into two
levels. Our experiments show that efficiency of solving this new PB formulation
of the problem by a general purpose PB solver can be close to the bespoke FPT
algorithm, which raises the potential of using general purpose solvers to
tackle FPT problems efficiently.
&lt;/p&gt;
&lt;p&gt;We also study the computational performance of various algorithms to
complement the overly-pessimistic worst-case analysis that is usually done in
FPT studies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karapetyan_D/0/1/0/all/0/1&quot;&gt;Daniel Karapetyan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parkes_A/0/1/0/all/0/1&quot;&gt;Andrew J. Parkes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gutin_G/0/1/0/all/0/1&quot;&gt;Gregory Gutin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gagarin_A/0/1/0/all/0/1&quot;&gt;Andrei Gagarin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.07654">
<title>Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence Learning. (arXiv:1710.07654v3 [cs.SD] UPDATED)</title>
<link>http://arxiv.org/abs/1710.07654</link>
<description rdf:parseType="Literal">&lt;p&gt;We present Deep Voice 3, a fully-convolutional attention-based neural
text-to-speech (TTS) system. Deep Voice 3 matches state-of-the-art neural
speech synthesis systems in naturalness while training ten times faster. We
scale Deep Voice 3 to data set sizes unprecedented for TTS, training on more
than eight hundred hours of audio from over two thousand speakers. In addition,
we identify common error modes of attention-based speech synthesis networks,
demonstrate how to mitigate them, and compare several different waveform
synthesis methods. We also describe how to scale inference to ten million
queries per day on one single-GPU server.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ping_W/0/1/0/all/0/1&quot;&gt;Wei Ping&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_K/0/1/0/all/0/1&quot;&gt;Kainan Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gibiansky_A/0/1/0/all/0/1&quot;&gt;Andrew Gibiansky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arik_S/0/1/0/all/0/1&quot;&gt;Sercan O. Arik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kannan_A/0/1/0/all/0/1&quot;&gt;Ajay Kannan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Narang_S/0/1/0/all/0/1&quot;&gt;Sharan Narang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raiman_J/0/1/0/all/0/1&quot;&gt;Jonathan Raiman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miller_J/0/1/0/all/0/1&quot;&gt;John Miller&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.00740">
<title>Learning to Represent Programs with Graphs. (arXiv:1711.00740v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1711.00740</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning tasks on source code (i.e., formal languages) have been considered
recently, but most work has tried to transfer natural language methods and does
not capitalize on the unique opportunities offered by code&apos;s known syntax. For
example, long-range dependencies induced by using the same variable or function
in distant locations are often not considered. We propose to use graphs to
represent both the syntactic and semantic structure of code and use graph-based
deep learning methods to learn to reason over program structures.
&lt;/p&gt;
&lt;p&gt;In this work, we present how to construct graphs from source code and how to
scale Gated Graph Neural Networks training to such large graphs. We evaluate
our method on two tasks: VarNaming, in which a network attempts to predict the
name of a variable given its usage, and VarMisuse, in which the network learns
to reason about selecting the correct variable that should be used at a given
program location. Our comparison to methods that use less structured program
representations shows the advantages of modeling known structure, and suggests
that our models learn to infer meaningful names and to solve the VarMisuse task
in many cases. Additionally, our testing showed that VarMisuse identifies a
number of bugs in mature open-source projects.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Allamanis_M/0/1/0/all/0/1&quot;&gt;Miltiadis Allamanis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brockschmidt_M/0/1/0/all/0/1&quot;&gt;Marc Brockschmidt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khademi_M/0/1/0/all/0/1&quot;&gt;Mahmoud Khademi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.01788">
<title>A Reliability Theory of Truth. (arXiv:1801.01788v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1801.01788</link>
<description rdf:parseType="Literal">&lt;p&gt;Our approach is basically a coherence approach, but we avoid the well-known
pitfalls of coherence theories of truth. Consistency is replaced by
reliability, which expresses support and attack, and, in principle, every
theory (or agent, message) counts. At the same time, we do not require a
priviledged access to &quot;reality&quot;. A centerpiece of our approach is that we
attribute reliability also to agents, messages, etc., so an unreliable source
of information will be less important in future. Our ideas can also be extended
to value systems, and even actions, e.g., of animals.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schlechta_K/0/1/0/all/0/1&quot;&gt;Karl Schlechta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.07284">
<title>Logic Programming Applications: What Are the Abstractions and Implementations?. (arXiv:1802.07284v1 [cs.PL] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1802.07284</link>
<description rdf:parseType="Literal">&lt;p&gt;This article presents an overview of applications of logic programming,
classifying them based on the abstractions and implementations of logic
languages that support the applications. The three key abstractions are join,
recursion, and constraint. Their essential implementations are for-loops, fixed
points, and backtracking, respectively. The corresponding kinds of applications
are database queries, inductive analysis, and combinatorial search,
respectively. We also discuss language extensions and programming paradigms,
summarize example application problems by application areas, and touch on
example systems that support variants of the abstractions with different
implementations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yanhong A. Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.07444">
<title>Scaling-up Split-Merge MCMC with Locality Sensitive Sampling (LSS). (arXiv:1802.07444v1 [cs.LG] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1802.07444</link>
<description rdf:parseType="Literal">&lt;p&gt;Split-Merge MCMC (Monte Carlo Markov Chain) is one of the essential and
popular variants of MCMC for problems when an MCMC state consists of an unknown
number of components or clusters. It is well known that state-of-the-art
methods for split-merge MCMC do not scale well. Strategies for rapid mixing
requires smart and informative proposals to reduce the rejection rate. However,
all known smart proposals involve cost at least linear in the size of the data
$ \ge O(N)$, to suggest informative transitions. Thus, the cost of each
iteration is prohibitive for massive scale datasets. It is further known that
uninformative but computationally efficient proposals, such as random
split-merge, leads to extremely slow convergence. This tradeoff between mixing
time and per update cost seems hard to get around. In this paper, we get around
this tradeoff by utilizing simple similarity information, such as cosine
similarity, between the entity vectors to design a proposal distribution. Such
information is readily available in almost all applications. We show that the
recent use of locality sensitive hashing for efficient adaptive sampling can be
leveraged to obtain a computationally efficient pseudo-marginal MCMC. The new
split-merge MCMC has constant time update, just like random split-merge, and at
the same time the proposal is informative and needs significantly fewer
iterations than random split-merge. Overall, we obtain a sweet tradeoff between
convergence and per update cost. As a direct consequence, our proposal, named
LSHSM, is around 10x faster than the state-of-the-art sampling methods on both
synthetic datasets and two large real datasets KDDCUP and PubMed with several
millions of entities and thousands of cluster centers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_C/0/1/0/all/0/1&quot;&gt;Chen Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shrivastava_A/0/1/0/all/0/1&quot;&gt;Anshumali Shrivastava&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.07756">
<title>Determining the best classifier for predicting the value of a boolean field on a blood donor database. (arXiv:1802.07756v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.07756</link>
<description rdf:parseType="Literal">&lt;p&gt;Motivation: Thanks to digitization, we often have access to large databases,
consisting of various fields of information, ranging from numbers to texts and
even boolean values. Such databases lend themselves especially well to machine
learning, classification and big data analysis tasks. We are able to train
classifiers, using already existing data and use them for predicting the values
of a certain field, given that we have information regarding the other fields.
Most specifically, in this study, we look at the Electronic Health Records
(EHRs) that are compiled by hospitals. These EHRs are convenient means of
accessing data of individual patients, but there processing as a whole still
remains a task. However, EHRs that are composed of coherent, well-tabulated
structures lend themselves quite well to the application to machine language,
via the usage of classifiers. In this study, we look at a Blood Transfusion
Service Center Data Set (Data taken from the Blood Transfusion Service Center
in Hsin-Chu City in Taiwan). We used scikit-learn machine learning in python.
From Support Vector Machines(SVM), we use Support Vector Classification(SVC),
from the linear model we import Perceptron. We also used the
K.neighborsclassifier and the decision tree classifiers. We segmented the
database into the 2 parts. Using the first, we trained the classifiers and the
next part was used to verify if the classifier prediction matched that of the
actual values.
&lt;/p&gt;
&lt;p&gt;Contact: ritabratamaiti@hiretrex.com
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Maiti_R/0/1/0/all/0/1&quot;&gt;Ritabrata Maiti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.07773">
<title>Counting Motifs with Graph Sampling. (arXiv:1802.07773v1 [math.ST])</title>
<link>http://arxiv.org/abs/1802.07773</link>
<description rdf:parseType="Literal">&lt;p&gt;Applied researchers often construct a network from a random sample of nodes
in order to infer properties of the parent network. Two of the most widely used
sampling schemes are subgraph sampling, where we sample each vertex
independently with probability $p$ and observe the subgraph induced by the
sampled vertices, and neighborhood sampling, where we additionally observe the
edges between the sampled vertices and their neighbors.
&lt;/p&gt;
&lt;p&gt;In this paper, we study the problem of estimating the number of motifs as
induced subgraphs under both models from a statistical perspective. We show
that: for any connected $h$ on $k$ vertices, to estimate $s=\mathsf{s}(h,G)$,
the number of copies of $h$ in the parent graph $G$ of maximum degree $d$, with
a multiplicative error of $\epsilon$, (a) For subgraph sampling, the optimal
sampling ratio $p$ is $\Theta_{k}(\max\{ (s\epsilon^2)^{-\frac{1}{k}}, \;
\frac{d^{k-1}}{s\epsilon^{2}} \})$, achieved by Horvitz-Thompson type of
estimators. (b) For neighborhood sampling, we propose a family of estimators,
encompassing and outperforming the Horvitz-Thompson estimator and achieving the
sampling ratio $O_{k}(\min\{ (\frac{d}{s\epsilon^2})^{\frac{1}{k-1}}, \;
\sqrt{\frac{d^{k-2}}{s\epsilon^2}}\})$. This is shown to be optimal for all
motifs with at most $4$ vertices and cliques of all sizes.
&lt;/p&gt;
&lt;p&gt;The matching minimax lower bounds are established using certain algebraic
properties of subgraph counts. These results quantify how much more informative
neighborhood sampling is than subgraph sampling, as empirically verified by
experiments on both synthetic and real-world data. We also address the issue of
adaptation to the unknown maximum degree, and study specific problems for
parent graphs with additional structures, e.g., trees or planar graphs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Klusowski_J/0/1/0/all/0/1&quot;&gt;Jason M. Klusowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yihong Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.07796">
<title>Continuous Relaxation of MAP Inference: A Nonconvex Perspective. (arXiv:1802.07796v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1802.07796</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we study a nonconvex continuous relaxation of MAP inference in
discrete Markov random fields (MRFs). We show that for arbitrary MRFs, this
relaxation is tight, and a discrete stationary point of it can be easily
reached by a simple block coordinate descent algorithm. In addition, we study
the resolution of this relaxation using popular gradient methods, and further
propose a more effective solution using a multilinear decomposition framework
based on the alternating direction method of multipliers (ADMM). Experiments on
many real-world problems demonstrate that the proposed ADMM significantly
outperforms other nonconvex relaxation based methods, and compares favorably
with state of the art MRF optimization algorithms in different settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Le_Huu_D/0/1/0/all/0/1&quot;&gt;D. Khu&amp;#xea; L&amp;#xea;-Huu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paragios_N/0/1/0/all/0/1&quot;&gt;Nikos Paragios&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.07834">
<title>Learning to Gather without Communication. (arXiv:1802.07834v1 [q-bio.PE])</title>
<link>http://arxiv.org/abs/1802.07834</link>
<description rdf:parseType="Literal">&lt;p&gt;A standard belief on emerging collective behavior is that it emerges from
simple individual rules. Most of the mathematical research on such collective
behavior starts from imperative individual rules, like always go to the center.
But how could an (optimal) individual rule emerge during a short period within
the group lifetime, especially if communication is not available. We argue that
such rules can actually emerge in a group in a short span of time via
collective (multi-agent) reinforcement learning, i.e learning via rewards and
punishments. We consider the gathering problem: several agents (social animals,
swarming robots...) must gather around a same position, which is not determined
in advance. They must do so without communication on their planned decision,
just by looking at the position of other agents. We present the first
experimental evidence that a gathering behavior can be learned without
communication in a partially observable environment. The learned behavior has
the same properties as a self-stabilizing distributed algorithm, as processes
can gather from any initial state (and thus tolerate any transient failure).
Besides, we show that it is possible to tolerate the brutal loss of up to 90\%
of agents without significant impact on the behavior.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Mhamdi_E/0/1/0/all/0/1&quot;&gt;El Mahdi El Mhamdi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Guerraoui_R/0/1/0/all/0/1&quot;&gt;Rachid Guerraoui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Maurer_A/0/1/0/all/0/1&quot;&gt;Alexandre Maurer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Tempez_V/0/1/0/all/0/1&quot;&gt;Vladislav Tempez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.07889">
<title>Entropy Rate Estimation for Markov Chains with Large State Space. (arXiv:1802.07889v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.07889</link>
<description rdf:parseType="Literal">&lt;p&gt;Estimating the entropy based on data is one of the prototypical problems in
distribution property testing and estimation. For estimating the Shannon
entropy of a distribution on $S$ elements with independent samples,
[Paninski2004] showed that the sample complexity is sublinear in $S$, and
[Valiant--Valiant2011] showed that consistent estimation of Shannon entropy is
possible if and only if the sample size $n$ far exceeds $\frac{S}{\log S}$. In
this paper we consider the problem of estimating the entropy rate of a
stationary reversible Markov chain with $S$ states from a sample path of $n$
observations. We show that:
&lt;/p&gt;
&lt;p&gt;(1) As long as the Markov chain mixes not too slowly, i.e., the relaxation
time is at most $O(\frac{S}{\ln^3 S})$, consistent estimation is achievable
when $n \gg \frac{S^2}{\log S}$.
&lt;/p&gt;
&lt;p&gt;(2) As long as the Markov chain has some slight dependency, i.e., the
relaxation time is at least $1+\Omega(\frac{\ln^2 S}{\sqrt{S}})$, consistent
estimation is impossible when $n \lesssim \frac{S^2}{\log S}$.
&lt;/p&gt;
&lt;p&gt;Under both assumptions, the optimal estimation accuracy is shown to be
$\Theta(\frac{S^2}{n \log S})$. In comparison, the empirical entropy rate
requires at least $\Omega(S^2)$ samples to be consistent, even when the Markov
chain is memoryless. In addition to synthetic experiments, we also apply the
estimators that achieve the optimal sample complexity to estimate the entropy
rate of the English language in the Penn Treebank and the Google One Billion
Words corpora, which provides a natural benchmark for language modeling and
relates it directly to the widely used perplexity measure.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1&quot;&gt;Yanjun Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiao_J/0/1/0/all/0/1&quot;&gt;Jiantao Jiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1&quot;&gt;Chuan-Zheng Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weissman_T/0/1/0/all/0/1&quot;&gt;Tsachy Weissman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yihong Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1&quot;&gt;Tiancheng Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.07917">
<title>Regional Multi-Armed Bandits. (arXiv:1802.07917v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.07917</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider a variant of the classic multi-armed bandit problem where the
expected reward of each arm is a function of an unknown parameter. The arms are
divided into different groups, each of which has a common parameter. Therefore,
when the player selects an arm at each time slot, information of other arms in
the same group is also revealed. This regional bandit model naturally bridges
the non-informative bandit setting where the player can only learn the chosen
arm, and the global bandit model where sampling one arms reveals information of
all arms. We propose an efficient algorithm, UCB-g, that solves the regional
bandit problem by combining the Upper Confidence Bound (UCB) and greedy
principles. Both parameter-dependent and parameter-free regret upper bounds are
derived. We also establish a matching lower bound, which proves the
order-optimality of UCB-g. Moreover, we propose SW-UCB-g, which is an extension
of UCB-g for a non-stationary environment where the parameters slowly vary over
time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhiyang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_R/0/1/0/all/0/1&quot;&gt;Ruida Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1&quot;&gt;Cong Shen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.07927">
<title>The Hidden Vulnerability of Distributed Learning in Byzantium. (arXiv:1802.07927v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.07927</link>
<description rdf:parseType="Literal">&lt;p&gt;While machine learning is going through an era of celebrated success,
concerns have been raised about the vulnerability of its backbone: stochastic
gradient descent (SGD). Recent approaches have been proposed to ensure the
robustness of distributed SGD against adversarial (Byzantine) workers sending
poisoned gradients during the training phase. Some of these approaches have
been proven Byzantine-resilient: they ensure the convergence of SGD despite the
presence of a minority of adversarial workers.
&lt;/p&gt;
&lt;p&gt;We show in this paper that convergence is not enough. In high dimension $d
\gg 1$, an adver\-sary can build on the loss function&apos;s non--convexity to make
SGD converge to ineffective models. More precisely, we bring to light that
existing Byzantine--resilient schemes leave a margin of poisoning of
$\Omega\left(f(d)\right)$, where $f(d)$ increases at least like $\sqrt[p]{d~}$.
Based on this leeway, we build a simple attack, and experimentally show its
strong to utmost effectivity on CIFAR--10 and MNIST.
&lt;/p&gt;
&lt;p&gt;We introduce Bulyan, and prove it significantly reduces the attackers leeway
to a narrow $O( \frac{1}{\sqrt{d~}})$ bound. We empirically show that Bulyan
does not suffer the fragility of existing aggregation rules and, at a
reasonable cost in terms of required batch size, achieves convergence as if
only non--Byzantine gradients had been used to update the model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mhamdi_E/0/1/0/all/0/1&quot;&gt;El Mahdi El Mhamdi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Guerraoui_R/0/1/0/all/0/1&quot;&gt;Rachid Guerraoui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rouault_S/0/1/0/all/0/1&quot;&gt;S&amp;#xe9;bastien Rouault&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.07928">
<title>Asynchronous Byzantine Machine Learning. (arXiv:1802.07928v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.07928</link>
<description rdf:parseType="Literal">&lt;p&gt;Asynchronous distributed machine learning solutions have proven very
effective so far, but always assuming perfectly functioning workers. In
practice, some of the workers can however exhibit Byzantine behavior, caused by
hardware failures, software bugs, corrupt data, or even malicious attacks. We
introduce \emph{Kardam}, the first distributed asynchronous stochastic gradient
descent (SGD) algorithm that copes with Byzantine workers. Kardam consists of
two complementary components: a filtering and a dampening component. The first
is scalar-based and ensures resilience against $\frac{1}{3}$ Byzantine workers.
Essentially, this filter leverages the Lipschitzness of cost functions and acts
as a self-stabilizer against Byzantine workers that would attempt to corrupt
the progress of SGD. The dampening component bounds the convergence rate by
adjusting to stale information through a generic gradient weighting scheme. We
prove that Kardam guarantees almost sure convergence in the presence of
asynchrony and Byzantine behavior, and we derive its convergence rate. We
evaluate Kardam on the CIFAR-100 and EMNIST datasets and measure its overhead
with respect to non Byzantine-resilient solutions. We empirically show that
Kardam does not introduce additional noise to the learning procedure but does
induce a slowdown (the cost of Byzantine resilience) that we both theoretically
and empirically show to be less than $f/n$, where $f$ is the number of
Byzantine failures tolerated and $n$ the total number of workers.
Interestingly, we also empirically observe that the dampening component is
interesting in its own right for it enables to build an SGD algorithm that
outperforms alternative staleness-aware asynchronous competitors in
environments with honest workers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Damaskinos_G/0/1/0/all/0/1&quot;&gt;Georgios Damaskinos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mhamdi_E/0/1/0/all/0/1&quot;&gt;El Mahdi El Mhamdi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Guerraoui_R/0/1/0/all/0/1&quot;&gt;Rachid Guerraoui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Patra_R/0/1/0/all/0/1&quot;&gt;Rhicheek Patra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Taziki_M/0/1/0/all/0/1&quot;&gt;Mahsa Taziki&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.07935">
<title>Asynchronous stochastic approximations with asymptotically biased errors and deep multi-agent learning. (arXiv:1802.07935v1 [math.OC])</title>
<link>http://arxiv.org/abs/1802.07935</link>
<description rdf:parseType="Literal">&lt;p&gt;Asynchronous stochastic approximations are an important class of model-free
algorithms that are readily applicable to multi-agent reinforcement learning
(RL) and distributed control applications. When the system size is large, the
aforementioned algorithms are used in conjunction with function approximations.
In this paper, we present a complete analysis, including stability (almost sure
boundedness) and convergence, of asynchronous stochastic approximations with
asymptotically bounded biased errors, under easily verifiable sufficient
conditions. As an application, we analyze the Policy Gradient algorithms and
the more general Value Iteration based algorithms with noise. These are popular
reinforcement learning algorithms due to their simplicity and effectiveness.
Specifically, we analyze the asynchronous approximate counterpart of policy
gradient (A2PG) and value iteration (A2VI) schemes. It is shown that the
stability of these algorithms remains unaffected when the approximation errors
are guaranteed to be asymptotically bounded, although possibly biased.
Regarding convergence of A2VI, it is shown to converge to a fixed point of the
perturbed Bellman operator when balanced step-sizes are used. Further, a
relationship between these fixed points and the approximation errors is
established. A similar analysis for A2PG is also presented.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ramaswamy_A/0/1/0/all/0/1&quot;&gt;Arunselvan Ramaswamy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Bhatnagar_S/0/1/0/all/0/1&quot;&gt;Shalabh Bhatnagar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Quevedo_D/0/1/0/all/0/1&quot;&gt;Daniel E. Quevedo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.07954">
<title>The State of the Art in Integrating Machine Learning into Visual Analytics. (arXiv:1802.07954v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.07954</link>
<description rdf:parseType="Literal">&lt;p&gt;Visual analytics systems combine machine learning or other analytic
techniques with interactive data visualization to promote sensemaking and
analytical reasoning. It is through such techniques that people can make sense
of large, complex data. While progress has been made, the tactful combination
of machine learning and data visualization is still under-explored. This
state-of-the-art report presents a summary of the progress that has been made
by highlighting and synthesizing select research advances. Further, it presents
opportunities and challenges to enhance the synergy between machine learning
and visual analytics for impactful future research directions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Endert_A/0/1/0/all/0/1&quot;&gt;A. Endert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ribarsky_W/0/1/0/all/0/1&quot;&gt;W. Ribarsky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Turkay_C/0/1/0/all/0/1&quot;&gt;C. Turkay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wong_W/0/1/0/all/0/1&quot;&gt;W Wong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nabney_I/0/1/0/all/0/1&quot;&gt;I. Nabney&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Blanco_I/0/1/0/all/0/1&quot;&gt;I D&amp;#xed;az Blanco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rossi_F/0/1/0/all/0/1&quot;&gt;Fabrice Rossi&lt;/a&gt; (SAMM)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.07971">
<title>Robustness of classifiers to uniform $\ell\_p$ and Gaussian noise. (arXiv:1802.07971v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.07971</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the robustness of classifiers to various kinds of random noise
models. In particular, we consider noise drawn uniformly from the $\ell\_p$
ball for $p \in [1, \infty]$ and Gaussian noise with an arbitrary covariance
matrix. We characterize this robustness to random noise in terms of the
distance to the decision boundary of the classifier. This analysis applies to
linear classifiers as well as classifiers with locally approximately flat
decision boundaries, a condition which is satisfied by state-of-the-art deep
neural networks. The predicted robustness is verified experimentally.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Franceschi_J/0/1/0/all/0/1&quot;&gt;Jean-Yves Franceschi&lt;/a&gt; (LIP), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fawzi_A/0/1/0/all/0/1&quot;&gt;Alhussein Fawzi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fawzi_O/0/1/0/all/0/1&quot;&gt;Omar Fawzi&lt;/a&gt; (LIP)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08009">
<title>Iterate averaging as regularization for stochastic gradient descent. (arXiv:1802.08009v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.08009</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose and analyze a variant of the classic Polyak-Ruppert averaging
scheme, broadly used in stochastic gradient methods. Rather than a uniform
average of the iterates, we consider a weighted average, with weights decaying
in a geometric fashion. In the context of linear least squares regression, we
show that this averaging scheme has a the same regularizing effect, and indeed
is asymptotically equivalent, to ridge regression. In particular, we derive
finite-sample bounds for the proposed approach that match the best known
results for regularized stochastic gradient methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Neu_G/0/1/0/all/0/1&quot;&gt;Gergely Neu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rosasco_L/0/1/0/all/0/1&quot;&gt;Lorenzo Rosasco&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08012">
<title>Learning Topic Models by Neighborhood Aggregation. (arXiv:1802.08012v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.08012</link>
<description rdf:parseType="Literal">&lt;p&gt;Topic models are one of the most frequently used models in machine learning
due to its high interpretability and modular structure. However extending the
model to include supervisory signal, incorporate pre-trained word embedding
vectors and add nonlinear output function to the model is not an easy task
because one has to resort to highly intricate approximate inference procedure.
In this paper, we show that topic models could be viewed as performing a
neighborhood aggregation algorithm where the messages are passed through a
network defined over words. Under the network view of topic models, nodes
corresponds to words in a document and edges correspond to either a
relationship describing co-occurring words in a document or a relationship
describing same word in the corpus. The network view allows us to extend the
model to include supervisory signals, incorporate pre-trained word embedding
vectors and add nonlinear output function to the model in a simple manner.
Moreover, we describe a simple way to train the model that is well suited in a
semi-supervised setting where we only have supervisory signals for some portion
of the corpus and the goal is to improve prediction performance in the held-out
data. Through careful experiments we show that our approach outperforms
state-of-the-art supervised Latent Dirichlet Allocation implementation in both
held-out document classification tasks and topic coherence.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hisano_R/0/1/0/all/0/1&quot;&gt;Ryohei Hisano&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08021">
<title>SparCML: High-Performance Sparse Communication for Machine Learning. (arXiv:1802.08021v1 [cs.DC])</title>
<link>http://arxiv.org/abs/1802.08021</link>
<description rdf:parseType="Literal">&lt;p&gt;One of the main drivers behind the rapid recent advances in machine learning
has been the availability of efficient system support. This comes both through
hardware acceleration, but also in the form of efficient software frameworks
and programming models. Despite significant progress, scaling compute-intensive
machine learning workloads to a large number of compute nodes is still a
challenging task, with significant latency and bandwidth demands. In this
paper, we address this challenge, by proposing SPARCML, a general, scalable
communication layer for machine learning applications. SPARCML is built on the
observation that many distributed machine learning algorithms either have
naturally sparse communication patters, or have updates which can be sparsified
in a structured way for improved performance, without any convergence or
accuracy loss. To exploit this insight, we design and implement a set of
communication efficient protocols for sparse input data, in conjunction with
efficient machine learning algorithms which can leverage these primitives. Our
communication protocols generalize standard collective operations, by allowing
processes to contribute sparse input data vectors, of heterogeneous sizes. We
call these operations sparse-input collectives, and present efficient practical
algorithms with strong theoretical bounds on their running time and
communication cost. Our generic communication layer is enriched with additional
features, such support for non-blocking (asynchronous) operations, and support
for low-precision data representations. We validate our algorithmic results
experimentally on a range of large-scale machine learning applications and
target architectures, showing that we can leverage sparsity for order-
of-magnitude runtime savings, compared to state-of-the art methods and
frameworks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Renggli_C/0/1/0/all/0/1&quot;&gt;C&amp;#xe8;dric Renggli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alistarh_D/0/1/0/all/0/1&quot;&gt;Dan Alistarh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoefler_T/0/1/0/all/0/1&quot;&gt;Torsten Hoefler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08061">
<title>Algorithmic Collusion in Cournot Duopoly Market: Evidence from Experimental Economics. (arXiv:1802.08061v1 [econ.EM])</title>
<link>http://arxiv.org/abs/1802.08061</link>
<description rdf:parseType="Literal">&lt;p&gt;Algorithmic collusion is an emerging concept in current artificial
intelligence age. Whether algorithmic collusion is a creditable threat remains
as an argument. In this paper, we propose an algorithm which can extort its
human rival to collude in a Cournot duopoly competing market. In experiments,
we show that, the algorithm can successfully extorted its human rival and gets
higher profit in long run, meanwhile the human rival will fully collude with
the algorithm. As a result, the social welfare declines rapidly and stably.
Both in theory and in experiment, our work confirms that, algorithmic collusion
can be a creditable threat. In application, we hope, the frameworks, the
algorithm design as well as the experiment environment illustrated in this
work, can be an incubator or a test bed for researchers and policymakers to
handle the emerging algorithmic collusion.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Zhou_N/0/1/0/all/0/1&quot;&gt;Nan Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Li Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Shijian Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhijian Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08089">
<title>Sampling as optimization in the space of measures: The Langevin dynamics as a composite optimization problem. (arXiv:1802.08089v1 [math.OC])</title>
<link>http://arxiv.org/abs/1802.08089</link>
<description rdf:parseType="Literal">&lt;p&gt;We study sampling as optimization in the space of measures. We focus on
gradient flow-based optimization with the Langevin dynamics as a case study. We
investigate the source of the bias of the unadjusted Langevin algorithm (ULA)
in discrete time, and consider how to remove or reduce the bias. We point out
the difficulty is that the heat flow is exactly solvable, but neither its
forward nor backward method is implementable in general, except for Gaussian
data. We propose the symmetrized Langevin algorithm (SLA), which should have a
smaller bias than ULA, at the price of implementing a proximal gradient step in
space. We show SLA is in fact consistent for Gaussian target measure, whereas
ULA is not. We also illustrate various algorithms explicitly for Gaussian
target measure, including gradient descent, proximal gradient, and
Forward-Backward, and show they are all consistent.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Wibisono_A/0/1/0/all/0/1&quot;&gt;Andre Wibisono&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08139">
<title>Path-Specific Counterfactual Fairness. (arXiv:1802.08139v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.08139</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of learning fair decision systems in complex
scenarios in which a sensitive attribute might affect the decision along both
fair and unfair pathways. We introduce a causal approach to disregard effects
along unfair pathways that simplifies and generalizes previous literature. Our
method corrects observations adversely affected by the sensitive attribute, and
uses these to form a decision. This avoids disregarding fair information, and
does not require an often intractable computation of the path-specific effect.
We leverage recent developments in deep learning and approximate inference to
achieve a solution that is widely applicable to complex, non-linear scenarios.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chiappa_S/0/1/0/all/0/1&quot;&gt;Silvia Chiappa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gillam_T/0/1/0/all/0/1&quot;&gt;Thomas P. S. Gillam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08163">
<title>An Analysis of Categorical Distributional Reinforcement Learning. (arXiv:1802.08163v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.08163</link>
<description rdf:parseType="Literal">&lt;p&gt;Distributional approaches to value-based reinforcement learning model the
entire distribution of returns, rather than just their expected values, and
have recently been shown to yield state-of-the-art empirical performance. This
was demonstrated by the recently proposed C51 algorithm, based on categorical
distributional reinforcement learning (CDRL) [Bellemare et al., 2017]. However,
the theoretical properties of CDRL algorithms are not yet well understood. In
this paper, we introduce a framework to analyse CDRL algorithms, establish the
importance of the projected distributional Bellman operator in distributional
RL, draw fundamental connections between CDRL and the Cram\&apos;er distance, and
give a proof of convergence for sample-based categorical distributional
reinforcement learning algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rowland_M/0/1/0/all/0/1&quot;&gt;Mark Rowland&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bellemare_M/0/1/0/all/0/1&quot;&gt;Marc G. Bellemare&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dabney_W/0/1/0/all/0/1&quot;&gt;Will Dabney&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Munos_R/0/1/0/all/0/1&quot;&gt;R&amp;#xe9;mi Munos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Teh_Y/0/1/0/all/0/1&quot;&gt;Yee Whye Teh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08167">
<title>Learning Causally-Generated Stationary Time Series. (arXiv:1802.08167v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.08167</link>
<description rdf:parseType="Literal">&lt;p&gt;We present the Causal Gaussian Process Convolution Model (CGPCM), a doubly
nonparametric model for causal, spectrally complex dynamical phenomena. The
CGPCM is a generative model in which white noise is passed through a causal,
nonparametric-window moving-average filter, a construction that we show to be
equivalent to a Gaussian process with a nonparametric kernel that is biased
towards causally-generated signals. We develop enhanced variational inference
and learning schemes for the CGPCM and its previous acausal variant, the GPCM
(Tobar et al., 2015b), that significantly improve statistical accuracy. These
modelling and inferential contributions are demonstrated on a range of
synthetic and real-world signals.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bruinsma_W/0/1/0/all/0/1&quot;&gt;Wessel Bruinsma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Turner_R/0/1/0/all/0/1&quot;&gt;Richard E. Turner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08242">
<title>Structured low-rank matrix completion for forecasting in time series analysis. (arXiv:1802.08242v1 [stat.ME])</title>
<link>http://arxiv.org/abs/1802.08242</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we consider the low-rank matrix completion problem with
specific application to forecasting in time series analysis. Briefly, the
low-rank matrix completion problem is the problem of imputing missing values of
a matrix under a rank constraint. We consider a matrix completion problem for
Hankel matrices and a convex relaxation based on the nuclear norm. Based on new
theoretical results and a number of numerical and real examples, we investigate
the cases when the proposed approach can work. Our results highlight the
importance of choosing a proper weighting scheme for the known observations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gillard_J/0/1/0/all/0/1&quot;&gt;Jonathan Gillard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Usevich_K/0/1/0/all/0/1&quot;&gt;Konstantin Usevich&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1703.01610">
<title>Improving Regret Bounds for Combinatorial Semi-Bandits with Probabilistically Triggered Arms and Its Applications. (arXiv:1703.01610v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1703.01610</link>
<description rdf:parseType="Literal">&lt;p&gt;We study combinatorial multi-armed bandit with probabilistically triggered
arms (CMAB-T) and semi-bandit feedback. We resolve a serious issue in the prior
CMAB-T studies where the regret bounds contain a possibly exponentially large
factor of $1/p^*$, where $p^*$ is the minimum positive probability that an arm
is triggered by any action. We address this issue by introducing a triggering
probability modulated (TPM) bounded smoothness condition into the general
CMAB-T framework, and show that many applications such as influence
maximization bandit and combinatorial cascading bandit satisfy this TPM
condition. As a result, we completely remove the factor of $1/p^*$ from the
regret bounds, achieving significantly better regret bounds for influence
maximization and cascading bandits than before. Finally, we provide lower bound
results showing that the factor $1/p^*$ is unavoidable for general CMAB-T
problems, suggesting that the TPM condition is crucial in removing this factor.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1&quot;&gt;Qinshi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Wei Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1704.01665">
<title>Learning Combinatorial Optimization Algorithms over Graphs. (arXiv:1704.01665v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1704.01665</link>
<description rdf:parseType="Literal">&lt;p&gt;The design of good heuristics or approximation algorithms for NP-hard
combinatorial optimization problems often requires significant specialized
knowledge and trial-and-error. Can we automate this challenging, tedious
process, and learn the algorithms instead? In many real-world applications, it
is typically the case that the same optimization problem is solved again and
again on a regular basis, maintaining the same problem structure but differing
in the data. This provides an opportunity for learning heuristic algorithms
that exploit the structure of such recurring problems. In this paper, we
propose a unique combination of reinforcement learning and graph embedding to
address this challenge. The learned greedy policy behaves like a meta-algorithm
that incrementally constructs a solution, and the action is determined by the
output of a graph embedding network capturing the current state of the
solution. We show that our framework can be applied to a diverse range of
optimization problems over graphs, and learns effective algorithms for the
Minimum Vertex Cover, Maximum Cut and Traveling Salesman problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_H/0/1/0/all/0/1&quot;&gt;Hanjun Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khalil_E/0/1/0/all/0/1&quot;&gt;Elias B. Khalil&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yuyu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dilkina_B/0/1/0/all/0/1&quot;&gt;Bistra Dilkina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1&quot;&gt;Le Song&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.04293">
<title>Bayesian Approaches to Distribution Regression. (arXiv:1705.04293v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1705.04293</link>
<description rdf:parseType="Literal">&lt;p&gt;Distribution regression has recently attracted much interest as a generic
solution to the problem of supervised learning where labels are available at
the group level, rather than at the individual level. Current approaches,
however, do not propagate the uncertainty in observations due to sampling
variability in the groups. This effectively assumes that small and large groups
are estimated equally well, and should have equal weight in the final
regression. We account for this uncertainty with a Bayesian distribution
regression formalism, improving the robustness and performance of the model
when group sizes vary. We frame our models in a neural network style, allowing
for simple MAP inference using backpropagation to learn the parameters, as well
as MCMC-based inference which can fully propagate uncertainty. We demonstrate
our approach on illustrative toy datasets, as well as on a challenging problem
of predicting age from images.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Law_H/0/1/0/all/0/1&quot;&gt;Ho Chung Leon Law&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sutherland_D/0/1/0/all/0/1&quot;&gt;Dougal J. Sutherland&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sejdinovic_D/0/1/0/all/0/1&quot;&gt;Dino Sejdinovic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Flaxman_S/0/1/0/all/0/1&quot;&gt;Seth Flaxman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.07606">
<title>Guide Actor-Critic for Continuous Control. (arXiv:1705.07606v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1705.07606</link>
<description rdf:parseType="Literal">&lt;p&gt;Actor-critic methods solve reinforcement learning problems by updating a
parameterized policy known as an actor in a direction that increases an
estimate of the expected return known as a critic. However, existing
actor-critic methods only use values or gradients of the critic to update the
policy parameter. In this paper, we propose a novel actor-critic method called
the guide actor-critic (GAC). GAC firstly learns a guide actor that locally
maximizes the critic and then it updates the policy parameter based on the
guide actor by supervised learning. Our main theoretical contributions are two
folds. First, we show that GAC updates the guide actor by performing
second-order optimization in the action space where the curvature matrix is
based on the Hessians of the critic. Second, we show that the deterministic
policy gradient method is a special case of GAC when the Hessians are ignored.
Through experiments, we show that our method is a promising reinforcement
learning method for continuous controls.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tangkaratt_V/0/1/0/all/0/1&quot;&gt;Voot Tangkaratt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Abdolmaleki_A/0/1/0/all/0/1&quot;&gt;Abbas Abdolmaleki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sugiyama_M/0/1/0/all/0/1&quot;&gt;Masashi Sugiyama&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.06491">
<title>Data-Efficient Reinforcement Learning with Probabilistic Model Predictive Control. (arXiv:1706.06491v2 [cs.SY] UPDATED)</title>
<link>http://arxiv.org/abs/1706.06491</link>
<description rdf:parseType="Literal">&lt;p&gt;Trial-and-error based reinforcement learning (RL) has seen rapid advancements
in recent times, especially with the advent of deep neural networks. However,
the majority of autonomous RL algorithms require a large number of interactions
with the environment. A large number of interactions may be impractical in many
real-world applications, such as robotics, and many practical systems have to
obey limitations in the form of state space or control constraints. To reduce
the number of system interactions while simultaneously handling constraints, we
propose a model-based RL framework based on probabilistic Model Predictive
Control (MPC). In particular, we propose to learn a probabilistic transition
model using Gaussian Processes (GPs) to incorporate model uncertainty into
long-term predictions, thereby, reducing the impact of model errors. We then
use MPC to find a control sequence that minimises the expected long-term cost.
We provide theoretical guarantees for first-order optimality in the GP-based
transition models with deterministic approximate inference for long-term
planning. We demonstrate that our approach does not only achieve
state-of-the-art data efficiency, but also is a principled way for RL in
constrained environments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kamthe_S/0/1/0/all/0/1&quot;&gt;Sanket Kamthe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deisenroth_M/0/1/0/all/0/1&quot;&gt;Marc Peter Deisenroth&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.06878">
<title>An Unsupervised Method for Estimating the Global Horizontal Irradiance from Photovoltaic Power Measurements. (arXiv:1706.06878v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1706.06878</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we present a method to determine the global horizontal
irradiance (GHI) from the power measurements of one or more PV systems, located
in the same neighborhood. The method is completely unsupervised and is based on
a physical model of a PV plant. The precise assessment of solar irradiance is
pivotal for the forecast of the electric power generated by photovoltaic (PV)
plants. However, on-ground measurements are expensive and are generally not
performed for small and medium-sized PV plants. Satellite-based services
represent a valid alternative to on site measurements, but their space-time
resolution is limited. Results from two case studies located in Switzerland are
presented. The performance of the proposed method at assessing GHI is compared
with that of free and commercial satellite services. Our results show that the
presented method is generally better than satellite-based services, especially
at high temporal resolutions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nespoli_L/0/1/0/all/0/1&quot;&gt;Lorenzo Nespoli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Medici_V/0/1/0/all/0/1&quot;&gt;Vasco Medici&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.06315">
<title>FLAME: A Fast Large-scale Almost Matching Exactly Approach to Causal Inference. (arXiv:1707.06315v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1707.06315</link>
<description rdf:parseType="Literal">&lt;p&gt;A classical problem in causal inference is that of matching, where treatment
units need to be matched to control units. Some of the main challenges in
developing matching methods arise from the tension among (i) inclusion of as
many covariates as possible in defining the matched groups, (ii) having matched
groups with enough treated and control units for a valid estimate of Average
Treatment Effect (ATE) in each group, and (iii) computing the matched pairs
efficiently for large datasets. In this paper we propose a fast method for
approximate and exact matching in causal analysis called FLAME (Fast
Large-scale Almost Matching Exactly). We define an optimization objective for
match quality, which gives preferences to matching on covariates that can be
useful for predicting the outcome while encouraging as many matches as
possible. FLAME aims to optimize our match quality measure, leveraging
techniques that are natural for query processing in the area of database
management. We provide two implementations of FLAME using SQL queries and
bit-vector techniques.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Roy_S/0/1/0/all/0/1&quot;&gt;Sudeepa Roy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rudin_C/0/1/0/all/0/1&quot;&gt;Cynthia Rudin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Volfovsky_A/0/1/0/all/0/1&quot;&gt;Alexander Volfovsky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_T/0/1/0/all/0/1&quot;&gt;Tianyu Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.07283">
<title>Decomposition of Uncertainty in Bayesian Deep Learning for Efficient and Risk-sensitive Learning. (arXiv:1710.07283v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1710.07283</link>
<description rdf:parseType="Literal">&lt;p&gt;Bayesian neural networks with latent variables (BNNs+LVs) are scalable and
flexible probabilistic models: They account for uncertainty in the estimation
of the network weights and, by making use of latent variables, they can capture
complex noise patterns in the data. In this work, we show how to separate these
two forms of uncertainty for decision-making purposes. This decomposition
allows us to successfully identify informative points for active learning of
functions with heteroskedastic and bimodal noise. We also demonstrate how this
decomposition allows us to define a novel risk-sensitive reinforcement learning
criterion to identify policies that balance expected cost, model-bias and noise
averseness.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Depeweg_S/0/1/0/all/0/1&quot;&gt;Stefan Depeweg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hernandez_Lobato_J/0/1/0/all/0/1&quot;&gt;Jos&amp;#xe9; Miguel Hern&amp;#xe1;ndez-Lobato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Doshi_Velez_F/0/1/0/all/0/1&quot;&gt;Finale Doshi-Velez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Udluft_S/0/1/0/all/0/1&quot;&gt;Steffen Udluft&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.01796">
<title>Independently Interpretable Lasso: A New Regularizer for Sparse Regression with Uncorrelated Variables. (arXiv:1711.01796v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.01796</link>
<description rdf:parseType="Literal">&lt;p&gt;Sparse regularization such as $\ell_1$ regularization is a quite powerful and
widely used strategy for high dimensional learning problems. The effectiveness
of sparse regularization has been supported practically and theoretically by
several studies. However, one of the biggest issues in sparse regularization is
that its performance is quite sensitive to correlations between features.
Ordinary $\ell_1$ regularization can select variables correlated with each
other, which results in deterioration of not only its generalization error but
also interpretability. In this paper, we propose a new regularization method,
&quot;Independently Interpretable Lasso&quot; (IILasso). Our proposed regularizer
suppresses selecting correlated variables, and thus each active variable
independently affects the objective variable in the model. Hence, we can
interpret regression coefficients intuitively and also improve the performance
by avoiding overfitting. We analyze theoretical property of IILasso and show
that the proposed method is much advantageous for its sign recovery and
achieves almost minimax optimal convergence rate. Synthetic and real data
analyses also indicate the effectiveness of IILasso.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Takada_M/0/1/0/all/0/1&quot;&gt;Masaaki Takada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Suzuki_T/0/1/0/all/0/1&quot;&gt;Taiji Suzuki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fujisawa_H/0/1/0/all/0/1&quot;&gt;Hironori Fujisawa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.08824">
<title>The Nearest Neighbor Information Estimator is Adaptively Near Minimax Rate-Optimal. (arXiv:1711.08824v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.08824</link>
<description rdf:parseType="Literal">&lt;p&gt;We analyze the Kozachenko--Leonenko (KL) nearest neighbor estimator for the
differential entropy. We obtain the first uniform upper bound on its
performance over H\&quot;older balls on a torus without assuming any conditions on
how close the density could be from zero. Accompanying a new minimax lower
bound over the H\&quot;older ball, we show that the KL estimator is achieving the
minimax rates up to logarithmic factors without cognizance of the smoothness
parameter $s$ of the H\&quot;older ball for $s\in (0,2]$ and arbitrary dimension
$d$, rendering it the first estimator that provably satisfies this property.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jiao_J/0/1/0/all/0/1&quot;&gt;Jiantao Jiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gao_W/0/1/0/all/0/1&quot;&gt;Weihao Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Han_Y/0/1/0/all/0/1&quot;&gt;Yanjun Han&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.04695">
<title>Sparsity-based Defense against Adversarial Attacks on Linear Classifiers. (arXiv:1801.04695v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1801.04695</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks represent the state of the art in machine learning in a
growing number of fields, including vision, speech and natural language
processing. However, recent work raises important questions about the
robustness of such architectures, by showing that it is possible to induce
classification errors through tiny, almost imperceptible, perturbations.
Vulnerability to such &quot;adversarial attacks&quot;, or &quot;adversarial examples&quot;, has
been conjectured to be due to the excessive linearity of deep networks. In this
paper, we study this phenomenon in the setting of a linear classifier, and show
that it is possible to exploit sparsity in natural data to combat
$\ell_{\infty}$-bounded adversarial perturbations. Specifically, we demonstrate
the efficacy of a sparsifying front end via an ensemble averaged analysis, and
experimental results for the MNIST handwritten digit database. To the best of
our knowledge, this is the first work to show that sparsity provides a
theoretically rigorous framework for defense against adversarial attacks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Marzi_Z/0/1/0/all/0/1&quot;&gt;Zhinus Marzi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gopalakrishnan_S/0/1/0/all/0/1&quot;&gt;Soorya Gopalakrishnan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Madhow_U/0/1/0/all/0/1&quot;&gt;Upamanyu Madhow&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pedarsani_R/0/1/0/all/0/1&quot;&gt;Ramtin Pedarsani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03569">
<title>Riemannian Manifold Kernel for Persistence Diagrams. (arXiv:1802.03569v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.03569</link>
<description rdf:parseType="Literal">&lt;p&gt;Algebraic topology methods have recently played an important role for
statistical analysis with complicated geometric structured data. Among them,
persistent homology is a well-known tool to extract robust topological
features, and outputs as persistence diagrams. Unfortunately, persistence
diagrams are point multi-sets which can not be used in machine learning
algorithms for vector data. To deal with it, an emerged approach is to use
kernel methods. Besides that, geometry for persistence diagrams is also an
important factor. A popular geometry for persistence diagrams is the
Wasserstein metric. However, Wasserstein distance is not negative definite.
Thus, it is limited to build positive definite kernels upon the Wasserstein
distance without approximation. In this work, we explore an alternative
Riemannian manifold geometry, namely the Fisher information metric. By building
upon the geodesic distance on the Riemannian manifold, we propose a positive
definite kernel, namely Riemannian manifold kernel. Then, we analyze
eigensystem of the integral operator induced by the proposed kernel for kernel
machines. Based on that, we conduct generalization error bounds via covering
numbers and Rademacher averages for kernel machines using the Riemannian
manifold kernel. Additionally, we also show some nice properties for the
proposed kernel such as stability, infinite divisibility and comparative time
complexity with other kernels for persistence diagrams in term of computation.
Throughout experiments with many different tasks on various benchmark datasets,
we illustrate that the Riemannian manifold kernel improves performances of
other baseline kernels.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Le_T/0/1/0/all/0/1&quot;&gt;Tam Le&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yamada_M/0/1/0/all/0/1&quot;&gt;Makoto Yamada&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04852">
<title>Persistence Codebooks for Topological Data Analysis. (arXiv:1802.04852v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04852</link>
<description rdf:parseType="Literal">&lt;p&gt;Topological data analysis, such as persistent homology has shown beneficial
properties for machine learning in many tasks. Topological representations,
such as the persistence diagram (PD), however, have a complex structure
(multiset of intervals) which makes it difficult to combine with typical
machine learning workflows. We present novel compact fixed-size vectorial
representations of PDs based on clustering and bag of words encodings that cope
well with the inherent sparsity of PDs. Our novel representations outperform
state-of-the-art approaches from topological data analysis and are
computationally more efficient.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zielinski_B/0/1/0/all/0/1&quot;&gt;Bartosz Zielinski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Juda_M/0/1/0/all/0/1&quot;&gt;Mateusz Juda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zeppelzauer_M/0/1/0/all/0/1&quot;&gt;Matthias Zeppelzauer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.07481">
<title>Dual Extrapolation for Faster Lasso Solvers. (arXiv:1802.07481v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.07481</link>
<description rdf:parseType="Literal">&lt;p&gt;Convex sparsity-inducing regularizations are ubiquitous in high-dimension
machine learning, but their non-differentiability requires the use of iterative
solvers. To accelerate such solvers, state-of-the-art approaches consist in
reducing the size of the optimization problem at hand. In the context of
regression, this can be achieved either by discarding irrelevant features
(screening techniques) or by prioritizing features likely to be included in the
support of the solution (working set techniques). Duality comes into play at
several steps in these techniques. Here, we propose an extrapolation technique
starting from a sequence of iterates in the dual that leads to the construction
of an improved dual point. This enables a tighter control of optimality as used
in stopping criterion, as well as better screening performance of Gap Safe
rules. Finally, we propose a working set strategy based on an aggressive use of
Gap Safe rules and our new dual point construction, which improves
state-of-the-art time performance on Lasso problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Massias_M/0/1/0/all/0/1&quot;&gt;Mathurin Massias&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gramfort_A/0/1/0/all/0/1&quot;&gt;Alexandre Gramfort&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Salmon_J/0/1/0/all/0/1&quot;&gt;Joseph Salmon&lt;/a&gt;</dc:creator>
</item></rdf:RDF>