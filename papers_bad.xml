<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-05-24T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09415"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09545"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09416"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09460"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09476"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09495"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09676"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09697"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09780"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.05077"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.09233"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.05240"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03493"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04742"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.02349"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02205"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09169"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08322"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09360"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09365"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09386"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09388"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09406"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09450"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09464"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09473"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09480"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09505"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09527"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09547"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09567"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09575"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09639"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09654"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09682"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09717"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09719"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09757"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09772"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09781"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09793"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09804"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.03439"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.08415"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.04072"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05283"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08334"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.01682"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.03666"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07179"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07914"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08527"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09108"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1805.09415">
<title>First-Hitting Times Under Additive Drift. (arXiv:1805.09415v1 [math.PR])</title>
<link>http://arxiv.org/abs/1805.09415</link>
<description rdf:parseType="Literal">&lt;p&gt;For the last ten years, almost every theoretical result concerning the
expected run time of a randomized search heuristic used drift theory, making it
the arguably most important tool in this domain. Its success is due to its ease
of use and its powerful result: drift theory allows the user to derive bounds
on the expected first-hitting time of a random process by bounding expected
local changes of the process -- the drift. This is usually far easier than
bounding the expected first-hitting time directly.
&lt;/p&gt;
&lt;p&gt;Due to the widespread use of drift theory, it is of utmost importance to have
the best drift theorems possible. We improve the fundamental additive,
multiplicative, and variable drift theorems by stating them in a form as
general as possible and providing examples of why the restrictions we keep are
still necessary. Our additive drift theorem for upper bounds only requires the
process to be nonnegative, that is, we remove unnecessary restrictions like a
finite, discrete, or bounded search space. As corollaries, the same is true for
our upper bounds in the case of variable and multiplicative drift.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Kotzing_T/0/1/0/all/0/1&quot;&gt;Timo K&amp;#xf6;tzing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Krejca_M/0/1/0/all/0/1&quot;&gt;Martin S. Krejca&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09545">
<title>On the Global Convergence of Gradient Descent for Over-parameterized Models using Optimal Transport. (arXiv:1805.09545v1 [math.OC])</title>
<link>http://arxiv.org/abs/1805.09545</link>
<description rdf:parseType="Literal">&lt;p&gt;Many tasks in machine learning and signal processing can be solved by
minimizing a convex function of a measure. This includes sparse spikes
deconvolution or training a neural network with a single hidden layer. For
these problems, we study a simple minimization method: the unknown measure is
discretized into a mixture of particles and a continuous-time gradient descent
is performed on their weights and positions. This is an idealization of the
usual way to train neural networks with a large hidden layer. We show that,
when initialized correctly and in the many-particle limit, this gradient flow,
although non-convex, converges to global minimizers. The proof involves
Wasserstein gradient flows, a by-product of optimal transport theory. Numerical
experiments show that this asymptotic behavior is already at play for a
reasonable number of particles, even in high dimension.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Chizat_L/0/1/0/all/0/1&quot;&gt;Lenaic Chizat&lt;/a&gt; (SIERRA), &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Bach_F/0/1/0/all/0/1&quot;&gt;Francis Bach&lt;/a&gt; (SIERRA)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09416">
<title>Adaptive Stochastic Gradient Langevin Dynamics: Taming Convergence and Saddle Point Escape Time. (arXiv:1805.09416v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.09416</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a new adaptive stochastic gradient Langevin
dynamics (ASGLD) algorithmic framework and its two specialized versions, namely
adaptive stochastic gradient (ASG) and adaptive gradient Langevin
dynamics(AGLD), for non-convex optimization problems. All proposed algorithms
can escape from saddle points with at most $O(\log d)$ iterations, which is
nearly dimension-free. Further, we show that ASGLD and ASG converge to a local
minimum with at most $O(\log d/\epsilon^4)$ iterations. Also, ASGLD with full
gradients or ASGLD with a slowly linearly increasing batch size converge to a
local minimum with iterations bounded by $O(\log d/\epsilon^2)$, which
outperforms existing first-order methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sang_H/0/1/0/all/0/1&quot;&gt;Hejian Sang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jia Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09460">
<title>Cautious Deep Learning. (arXiv:1805.09460v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.09460</link>
<description rdf:parseType="Literal">&lt;p&gt;Most classifiers operate by selecting the maximum of an estimate of the
conditional distribution $p(y|x)$ where $x$ stands for the features of the
instance to be classified and $y$ denotes its label. This often results in a
hubristic bias: overconfidence in the assignment of a definite label. Usually,
the observations are concentrated on a small volume but the classifier provides
definite predictions for the entire space. We propose constructing conformal
prediction sets [vovk2005algorithmic] which contain a set of labels rather than
a single label. These conformal prediction sets contain the true label with
probability $1-\alpha$. Our construction is based on $p(x|y)$ rather than
$p(y|x)$ which results in a classifier that is very cautious: it outputs the
null set - meaning `I don&apos;t know&apos; --- when the object does not resemble the
training examples. An important property of our approach is that classes can be
added or removed without having to retrain the classifier. We demonstrate the
performance on the ImageNet ILSVRC dataset using high dimensional features
obtained from state of the art convolutional neural networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hechtlinger_Y/0/1/0/all/0/1&quot;&gt;Yotam Hechtlinger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Poczos_B/0/1/0/all/0/1&quot;&gt;Barnab&amp;#xe1;s P&amp;#xf3;czos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wasserman_L/0/1/0/all/0/1&quot;&gt;Larry Wasserman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09476">
<title>Hierarchical Clustering with Structural Constraints. (arXiv:1805.09476v1 [cs.DS])</title>
<link>http://arxiv.org/abs/1805.09476</link>
<description rdf:parseType="Literal">&lt;p&gt;Hierarchical clustering is a popular unsupervised data analysis method. For
many real-world applications, we would like to exploit prior information about
the data that imposes constraints on the clustering hierarchy, and is not
captured by the set of features available to the algorithm. This gives rise to
the problem of &quot;hierarchical clustering with structural constraints&quot;.
Structural constraints pose major challenges for bottom-up approaches like
average/single linkage and even though they can be naturally incorporated into
top-down divisive algorithms, no formal guarantees exist on the quality of
their output. In this paper, we provide provable approximation guarantees for
two simple top-down algorithms, using a recently introduced optimization
viewpoint of hierarchical clustering with pairwise similarity information
[Dasgupta, 2016]. We show how to find good solutions even in the presence of
conflicting prior information, by formulating a &quot;constraint-based
regularization&quot; of the objective. Finally, we explore a variation of this
objective for dissimilarity information [Cohen-Addad et al., 2018] and improve
upon current techniques.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chatziafratis_V/0/1/0/all/0/1&quot;&gt;Vaggos Chatziafratis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niazadeh_R/0/1/0/all/0/1&quot;&gt;Rad Niazadeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Charikar_M/0/1/0/all/0/1&quot;&gt;Moses Charikar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09495">
<title>A Practical Algorithm for Distributed Clustering and Outlier Detection. (arXiv:1805.09495v1 [cs.DC])</title>
<link>http://arxiv.org/abs/1805.09495</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the classic $k$-means/median clustering, which are fundamental
problems in unsupervised learning, in the setting where data are partitioned
across multiple sites, and where we are allowed to discard a small portion of
the data by labeling them as outliers. We propose a simple approach based on
constructing small summary for the original dataset. The proposed method is
time and communication efficient, has good approximation guarantees, and can
identify the global outliers effectively. To the best of our knowledge, this is
the first practical algorithm with theoretical guarantees for distributed
clustering with outliers. Our experiments on both real and synthetic data have
demonstrated the clear superiority of our algorithm against all the baseline
algorithms in almost all metrics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jiecao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Azer_E/0/1/0/all/0/1&quot;&gt;Erfan Sadeqi Azer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1&quot;&gt;Qin Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09676">
<title>Forming IDEAS Interactive Data Exploration &amp; Analysis System. (arXiv:1805.09676v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1805.09676</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern cyber security operations collect an enormous amount of logging and
alerting data. While analysts have the ability to query and compute simple
statistics and plots from their data, current analytical tools are too simple
to admit deep understanding. To detect advanced and novel attacks, analysts
turn to manual investigations. While commonplace, current investigations are
time-consuming, intuition-based, and proving insufficient. Our hypothesis is
that arming the analyst with easy-to-use data science tools will increase their
work efficiency, provide them with the ability to resolve hypotheses with
scientific inquiry of their data, and support their decisions with evidence
over intuition. To this end, we present our work to build IDEAS (Interactive
Data Exploration and Analysis System). We present three real-world use-cases
that drive the system design from the algorithmic capabilities to the user
interface. Finally, a modular and scalable software architecture is discussed
along with plans for our pilot deployment with a security operation command.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bridges_R/0/1/0/all/0/1&quot;&gt;Robert A. Bridges&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vincent_M/0/1/0/all/0/1&quot;&gt;Maria A. Vincent&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huffer_K/0/1/0/all/0/1&quot;&gt;Kelly M. T. Huffer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goodall_J/0/1/0/all/0/1&quot;&gt;John R. Goodall&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jamieson_J/0/1/0/all/0/1&quot;&gt;Jessie D. Jamieson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Burch_Z/0/1/0/all/0/1&quot;&gt;Zachary Burch&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09697">
<title>Learning and Testing Causal Models with Interventions. (arXiv:1805.09697v1 [cs.DS])</title>
<link>http://arxiv.org/abs/1805.09697</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider testing and learning problems on causal Bayesian networks as
defined by Pearl (Pearl, 2009). Given a causal Bayesian network $\mathcal{M}$
on a graph with $n$ discrete variables and bounded in-degree and bounded
`confounded components&apos;, we show that $O(\log n)$ interventions on an unknown
causal Bayesian network $\mathcal{X}$ on the same graph, and
$\tilde{O}(n/\epsilon^2)$ samples per intervention, suffice to efficiently
distinguish whether $\mathcal{X}=\mathcal{M}$ or whether there exists some
intervention under which $\mathcal{X}$ and $\mathcal{M}$ are farther than
$\epsilon$ in total variation distance. We also obtain sample/time/intervention
efficient algorithms for: (i) testing the identity of two unknown causal
Bayesian networks on the same graph; and (ii) learning a causal Bayesian
network on a given graph. Although our algorithms are non-adaptive, we show
that adaptivity does not help in general: $\Omega(\log n)$ interventions are
necessary for testing the identity of two unknown causal Bayesian networks on
the same graph, even adaptively. Our algorithms are enabled by a new
subadditivity inequality for the squared Hellinger distance between two causal
Bayesian networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Acharya_J/0/1/0/all/0/1&quot;&gt;Jayadev Acharya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhattacharyya_A/0/1/0/all/0/1&quot;&gt;Arnab Bhattacharyya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Daskalakis_C/0/1/0/all/0/1&quot;&gt;Constantinos Daskalakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kandasamy_S/0/1/0/all/0/1&quot;&gt;Saravanan Kandasamy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09780">
<title>Mining Procedures from Technical Support Documents. (arXiv:1805.09780v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.09780</link>
<description rdf:parseType="Literal">&lt;p&gt;Guided troubleshooting is an inherent task in the domain of technical support
services. When a customer experiences an issue with the functioning of a
technical service or a product, an expert user helps guide the customer through
a set of steps comprising a troubleshooting procedure. The objective is to
identify the source of the problem through a set of diagnostic steps and
observations, and arrive at a resolution. Procedures containing these set of
diagnostic steps and observations in response to different problems are common
artifacts in the body of technical support documentation. The ability to use
machine learning and linguistics to understand and leverage these procedures
for applications like intelligent chatbots or robotic process automation, is
crucial. Existing research on question answering or intelligent chatbots does
not look within procedures or deep-understand them. In this paper, we outline a
system for mining procedures from technical support documents. We create models
for solving important subproblems like extraction of procedures, identifying
decision points within procedures, identifying blocks of instructions
corresponding to these decision points and mapping instructions within a
decision block. We also release a dataset containing our manual annotations on
publicly available support documents, to promote further research on the
problem.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1&quot;&gt;Abhirut Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khosla_A/0/1/0/all/0/1&quot;&gt;Abhay Khosla&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_G/0/1/0/all/0/1&quot;&gt;Gautam Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dasgupta_G/0/1/0/all/0/1&quot;&gt;Gargi Dasgupta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.05077">
<title>Transforming Cooling Optimization for Green Data Center via Deep Reinforcement Learning. (arXiv:1709.05077v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1709.05077</link>
<description rdf:parseType="Literal">&lt;p&gt;Cooling system plays a key role in modern data center. Developing an optimal
control policy for data center cooling system is a challenging task. The
prevailing approaches often rely on approximated system models that are built
upon the knowledge of mechanical cooling, electrical and thermal management,
which is difficult to design and may lead to sub-optimal or unstable
performances. In this paper we propose to utilize the large amount of
monitoring data in data center to optimize the control policy. To do so, we
cast the cooling control policy design into an energy cost minimization problem
with temperature constraints, and tab it into the emerging deep reinforcement
learning (DRL) framework. Specifically, we propose an end-to-end neural control
algorithm that is based on the actor-critic framework and the deep
deterministic policy gradient (DDPG) technique. To improve the robustness of
the control algorithm, we test various DRL related optimization techniques,
such as recurrent decision making, discounted return, different neural network
architectures, and different stochastic gradient descent algorithms, and adding
additional constraints on the output of the policy network. We evaluate the
proposed algorithms on the EnergyPlus simulation platform and on a real data
trace collected from the National Super Computing Centre (NSCC) of Singapore.
Our results show that the proposed end-to-end cooling control algorithm can
achieve about 10% cooling cost saving on the simulation platform compared with
a canonical two stage optimization algorithm; and it can achieve about 13.6%
cooling energy saving on the NSCC data trace. Furthermore, it shows high
accuracy in predicting the temperature of the racks (with mean absolute error
0.1 degree) and can control the temperature of the data center zone close to
the predefined threshold with variation lower to 0.2 degree.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yuanlong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1&quot;&gt;Yonggang Wen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guan_K/0/1/0/all/0/1&quot;&gt;Kyle Guan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1&quot;&gt;Dacheng Tao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.09233">
<title>Dose Prediction with U-net: A Feasibility Study for Predicting Dose Distributions from Contours using Deep Learning on Prostate IMRT Patients. (arXiv:1709.09233v3 [physics.med-ph] UPDATED)</title>
<link>http://arxiv.org/abs/1709.09233</link>
<description rdf:parseType="Literal">&lt;p&gt;With the advancement of treatment modalities in radiation therapy for cancer
patients, outcomes have improved, but at the cost of increased treatment plan
complexity and planning time. The accurate prediction of dose distributions
would alleviate this issue by guiding clinical plan optimization to save time
and maintain high quality plans. We have modified a convolutional deep network
model, U-net (originally designed for segmentation purposes), for predicting
dose from patient image contours. We show that, as an example, we are able to
accurately predict the dose of intensity-modulated radiation therapy (IMRT) for
prostate cancer patients, where the average dice similarity coefficient is 0.91
when comparing the predicted vs. true isodose volumes between 0% and 100% of
the prescription dose. The average value of the absolute differences in [max,
mean] dose is found to be under 5% of the prescription dose, specifically for
each structure is [1.80%, 1.03%](PTV), [1.94%, 4.22%](Bladder), [1.80%,
0.48%](Body), [3.87%, 1.79%](L Femoral Head), [5.07%, 2.55%](R Femoral Head),
and [1.26%, 1.62%](Rectum) of the prescription dose. We thus managed to map a
desired radiation dose distribution from a patient&apos;s PTV and OAR contours. As
an additional advantage, relatively little data was used in the techniques and
models described in this paper.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Nguyen_D/0/1/0/all/0/1&quot;&gt;Dan Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Long_T/0/1/0/all/0/1&quot;&gt;Troy Long&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Jia_X/0/1/0/all/0/1&quot;&gt;Xun Jia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Lu_W/0/1/0/all/0/1&quot;&gt;Weiguo Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Gu_X/0/1/0/all/0/1&quot;&gt;Xuejun Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Iqbal_Z/0/1/0/all/0/1&quot;&gt;Zohaib Iqbal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Jiang_S/0/1/0/all/0/1&quot;&gt;Steve Jiang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.05240">
<title>Weakly-supervised Semantic Parsing with Abstract Examples. (arXiv:1711.05240v4 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1711.05240</link>
<description rdf:parseType="Literal">&lt;p&gt;Training semantic parsers from weak supervision (denotations) rather than
strong supervision (programs) complicates training in two ways. First, a large
search space of potential programs needs to be explored at training time to
find a correct program. Second, spurious programs that accidentally lead to a
correct denotation add noise to training. In this work we propose that in
closed worlds with clear semantic types, one can substantially alleviate these
problems by utilizing an abstract representation, where tokens in both the
language utterance and program are lifted to an abstract form. We show that
these abstractions can be defined with a handful of lexical rules and that they
result in sharing between different examples that alleviates the difficulties
in training. To test our approach, we develop the first semantic parser for
CNLVR, a challenging visual reasoning dataset, where the search space is large
and overcoming spuriousness is critical, because denotations are either TRUE or
FALSE, and thus random programs are likely to lead to a correct denotation. Our
method substantially improves performance, and reaches 82.5% accuracy, a 14.7%
absolute accuracy improvement compared to the best reported accuracy so far.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goldman_O/0/1/0/all/0/1&quot;&gt;Omer Goldman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Latcinnik_V/0/1/0/all/0/1&quot;&gt;Veronica Latcinnik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Naveh_U/0/1/0/all/0/1&quot;&gt;Udi Naveh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Globerson_A/0/1/0/all/0/1&quot;&gt;Amir Globerson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berant_J/0/1/0/all/0/1&quot;&gt;Jonathan Berant&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03493">
<title>More Robust Doubly Robust Off-policy Evaluation. (arXiv:1802.03493v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1802.03493</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the problem of off-policy evaluation (OPE) in reinforcement learning
(RL), where the goal is to estimate the performance of a policy from the data
generated by another policy(ies). In particular, we focus on the doubly robust
(DR) estimators that consist of an importance sampling (IS) component and a
performance model, and utilize the low (or zero) bias of IS and low variance of
the model at the same time. Although the accuracy of the model has a huge
impact on the overall performance of DR, most of the work on using the DR
estimators in OPE has been focused on improving the IS part, and not much on
how to learn the model. In this paper, we propose alternative DR estimators,
called more robust doubly robust (MRDR), that learn the model parameter by
minimizing the variance of the DR estimator. We first present a formulation for
learning the DR model in RL. We then derive formulas for the variance of the DR
estimator in both contextual bandits and RL, such that their gradients
w.r.t.~the model parameters can be estimated from the samples, and propose
methods to efficiently minimize the variance. We prove that the MRDR estimators
are strongly consistent and asymptotically optimal. Finally, we evaluate MRDR
in bandits and RL benchmark problems, and compare its performance with the
existing methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Farajtabar_M/0/1/0/all/0/1&quot;&gt;Mehrdad Farajtabar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chow_Y/0/1/0/all/0/1&quot;&gt;Yinlam Chow&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghavamzadeh_M/0/1/0/all/0/1&quot;&gt;Mohammad Ghavamzadeh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04742">
<title>Quantifying Uncertainty in Discrete-Continuous and Skewed Data with Bayesian Deep Learning. (arXiv:1802.04742v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04742</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep Learning (DL) methods have been transforming computer vision with
innovative adaptations to other domains including climate change. For DL to
pervade Science and Engineering (S&amp;amp;E) applications where risk management is a
core component, well-characterized uncertainty estimates must accompany
predictions. However, S&amp;amp;E observations and model-simulations often follow
heavily skewed distributions and are not well modeled with DL approaches, since
they usually optimize a Gaussian, or Euclidean, likelihood loss. Recent
developments in Bayesian Deep Learning (BDL), which attempts to capture
uncertainties from noisy observations, aleatoric, and from unknown model
parameters, epistemic, provide us a foundation. Here we present a
discrete-continuous BDL model with Gaussian and lognormal likelihoods for
uncertainty quantification (UQ). We demonstrate the approach by developing UQ
estimates on `DeepSD&apos;, a super-resolution based DL model for Statistical
Downscaling (SD) in climate applied to precipitation, which follows an
extremely skewed distribution. We find that the discrete-continuous models
outperform a basic Gaussian distribution in terms of predictive accuracy and
uncertainty calibration. Furthermore, we find that the lognormal distribution,
which can handle skewed distributions, produces quality uncertainty estimates
at the extremes. Such results may be important across S&amp;amp;E, as well as other
domains such as finance and economics, where extremes are often of significant
interest. Furthermore, to our knowledge, this is the first UQ model in SD where
both aleatoric and epistemic uncertainties are characterized.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vandal_T/0/1/0/all/0/1&quot;&gt;Thomas Vandal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kodra_E/0/1/0/all/0/1&quot;&gt;Evan Kodra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dy_J/0/1/0/all/0/1&quot;&gt;Jennifer Dy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ganguly_S/0/1/0/all/0/1&quot;&gt;Sangram Ganguly&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nemani_R/0/1/0/all/0/1&quot;&gt;Ramakrishna Nemani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ganguly_A/0/1/0/all/0/1&quot;&gt;Auroop R. Ganguly&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.02349">
<title>Billion-scale Commodity Embedding for E-commerce Recommendation in Alibaba. (arXiv:1803.02349v2 [cs.IR] UPDATED)</title>
<link>http://arxiv.org/abs/1803.02349</link>
<description rdf:parseType="Literal">&lt;p&gt;Recommender systems (RSs) have been the most important technology for
increasing the business in Taobao, the largest online consumer-to-consumer
(C2C) platform in China. The billion-scale data in Taobao creates three major
challenges to Taobao&apos;s RS: scalability, sparsity and cold start. In this paper,
we present our technical solutions to address these three challenges. The
methods are based on the graph embedding framework. We first construct an item
graph from users&apos; behavior history. Each item is then represented as a vector
using graph embedding. The item embeddings are employed to compute pairwise
similarities between all items, which are then used in the recommendation
process. To alleviate the sparsity and cold start problems, side information is
incorporated into the embedding framework. We propose two aggregation methods
to integrate the embeddings of items and the corresponding side information.
Experimental results from offline experiments show that methods incorporating
side information are superior to those that do not. Further, we describe the
platform upon which the embedding methods are deployed and the workflow to
process the billion-scale data in Taobao. Using online A/B test, we show that
the online Click-Through-Rate (CTRs) are improved comparing to the previous
recommendation methods widely used in Taobao, further demonstrating the
effectiveness and feasibility of our proposed methods in Taobao&apos;s live
production environment.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jizhe Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_P/0/1/0/all/0/1&quot;&gt;Pipei Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1&quot;&gt;Huan Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhibo Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_B/0/1/0/all/0/1&quot;&gt;Binqiang Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1&quot;&gt;Dik Lun Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02205">
<title>Correlation Heuristics for Constraint Programming. (arXiv:1805.02205v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1805.02205</link>
<description rdf:parseType="Literal">&lt;p&gt;Effective general-purpose search strategies are an important component in
Constraint Programming. We introduce a new idea, namely, using correlations
between variables to guide search. Variable correlations are measured and
maintained by using domain changes during constraint propagation. We propose
two variable heuristics based on the correlation matrix, crbs-sum and crbs-max.
We evaluate our correlation heuristics with well known heuristics, namely,
dom/wdeg, impact-based search and activity-based search. Experiments on a large
set of benchmarks show that our correlation heuristics are competitive with the
other heuristics, and can be the fastest on many series.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1&quot;&gt;Ruiwei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xia_W/0/1/0/all/0/1&quot;&gt;Wei Xia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yap_R/0/1/0/all/0/1&quot;&gt;Roland H. C. Yap&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09169">
<title>A distinct approach to diagnose Dengue Fever with the help of Soft Set Theory. (arXiv:1805.09169v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1805.09169</link>
<description rdf:parseType="Literal">&lt;p&gt;Mathematics has played a substantial role to revolutionize the medical
science. Intelligent systems based on mathematical theories have proved to be
efficient in diagnosing various diseases. In this paper, we used an expert
system based on soft set theory and fuzzy set theory named as a soft expert
system to diagnose tropical disease dengue. The objective to use soft expert
system is to predict the risk level of a patient having dengue fever by using
input variables like age, TLC, SGOT, platelets count and blood pressure. The
proposed method explicitly demonstrates the exact percentage of the risk level
of dengue fever automatically circumventing for all possible (medical)
imprecisions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bukhari_S/0/1/0/all/0/1&quot;&gt;Syeda fariha Bukhari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amjad_M/0/1/0/all/0/1&quot;&gt;Maaz Amjad&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08322">
<title>Teaching Multiple Concepts to Forgetful Learners. (arXiv:1805.08322v1 [cs.AI] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1805.08322</link>
<description rdf:parseType="Literal">&lt;p&gt;How can we help a forgetful learner learn multiple concepts within a limited
time frame? For long-term learning, it is crucial to devise teaching strategies
that leverage the underlying forgetting mechanisms of the learners. In this
paper, we cast the problem of adaptively teaching a forgetful learner as a
novel discrete optimization problem, where we seek to optimize a natural
objective function that characterizes the learner&apos;s expected performance
throughout the teaching session. We then propose a simple greedy teaching
strategy and derive strong performance guarantees based on two intuitive
data-dependent parameters, which characterize the degree of diminishing returns
of teaching each concept. We show that, given some assumptions of the learner&apos;s
memory model, one can efficiently compute the performance bounds. Furthermore,
we identify parameter settings of our memory models where greedy is guaranteed
to achieve high performance. We have deployed our approach in two concrete
applications, namely (1) an educational app for online vocabulary teaching and
(2) an app for teaching novices how to recognize bird species. We demonstrate
the effectiveness of our algorithm using simulations along with user studies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hunziker_A/0/1/0/all/0/1&quot;&gt;Anette Hunziker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yuxin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aodha_O/0/1/0/all/0/1&quot;&gt;Oisin Mac Aodha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rodriguez_M/0/1/0/all/0/1&quot;&gt;Manuel Gomez Rodriguez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krause_A/0/1/0/all/0/1&quot;&gt;Andreas Krause&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perona_P/0/1/0/all/0/1&quot;&gt;Pietro Perona&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yue_Y/0/1/0/all/0/1&quot;&gt;Yisong Yue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singla_A/0/1/0/all/0/1&quot;&gt;Adish Singla&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09360">
<title>Deep Reinforcement Learning of Marked Temporal Point Processes. (arXiv:1805.09360v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.09360</link>
<description rdf:parseType="Literal">&lt;p&gt;In a wide variety of applications, humans interact with a complex environment
by means of asynchronous stochastic discrete events in continuous time. Can we
design online interventions that will help humans achieve certain goals in such
asynchronous setting? In this paper, we address the above problem from the
perspective of deep reinforcement learning of marked temporal point processes,
where both the actions taken by an agent and the feedback it receives from the
environment are asynchronous stochastic discrete events characterized using
marked temporal point processes. In doing so, we define the agent&apos;s policy
using the intensity and mark distribution of the corresponding process and then
derive a flexible policy gradient method, which embeds the agent&apos;s actions and
the feedback it receives into real-valued vectors using deep recurrent neural
networks. Our method does not make any assumptions on the functional form of
the intensity and mark distribution of the feedback and it allows for
arbitrarily complex reward functions. We apply our methodology to two different
applications in personalized teaching and viral marketing and, using data
gathered from Duolingo and Twitter, we show that it may be able to find
interventions to help learners and marketers achieve their goals more
effectively than alternatives.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Upadhyay_U/0/1/0/all/0/1&quot;&gt;Utkarsh Upadhyay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+De_A/0/1/0/all/0/1&quot;&gt;Abir De&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gomez_Rodriguez_M/0/1/0/all/0/1&quot;&gt;Manuel Gomez-Rodriguez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09365">
<title>Learning Contextual Bandits in a Non-stationary Environment. (arXiv:1805.09365v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.09365</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-armed bandit algorithms have become a reference solution for handling
the explore/exploit dilemma in recommender systems, and many other important
real-world problems, such as display advertisement. However, such algorithms
usually assume a stationary reward distribution, which hardly holds in practice
as users&apos; preferences are dynamic. This inevitably costs a recommender system
consistent suboptimal performance. In this paper, we consider the situation
where the underlying distribution of reward remains unchanged over (possibly
short) epochs and shifts at unknown time instants. In accordance, we propose a
contextual bandit algorithm that detects possible changes of environment based
on its reward estimation confidence and updates its arm selection strategy
respectively. Rigorous upper regret bound analysis of the proposed algorithm
demonstrates its learning effectiveness in such a non-trivial environment.
Extensive empirical evaluations on both synthetic and real-world datasets for
recommendation confirm its practical utility in a changing environment.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1&quot;&gt;Qingyun Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iyer_N/0/1/0/all/0/1&quot;&gt;Naveen Iyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Hongning Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09386">
<title>Predictive Local Smoothness for Stochastic Gradient Methods. (arXiv:1805.09386v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.09386</link>
<description rdf:parseType="Literal">&lt;p&gt;Stochastic gradient methods are dominant in nonconvex optimization especially
for deep models but have low asymptotical convergence due to the fixed
smoothness. To address this problem, we propose a simple yet effective method
for improving stochastic gradient methods named predictive local smoothness
(PLS). First, we create a convergence condition to build a learning rate which
varies adaptively with local smoothness. Second, the local smoothness can be
predicted by the latest gradients. Third, we use the adaptive learning rate to
update the stochastic gradients for exploring linear convergence rates. By
applying the PLS method, we implement new variants of three popular algorithms:
PLS-stochastic gradient descent (PLS-SGD), PLS-accelerated SGD (PLS-AccSGD),
and PLS-AMSGrad. Moreover, we provide much simpler proofs to ensure their
linear convergence. Empirical results show that the variants have better
performance gains than the popular algorithms, such as, faster convergence and
alleviating explosion and vanish of gradients.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jun Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Hongfu Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhong_B/0/1/0/all/0/1&quot;&gt;Bineng Zhong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yue Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1&quot;&gt;Yun Fu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09388">
<title>Regret Bounds for Robust Adaptive Control of the Linear Quadratic Regulator. (arXiv:1805.09388v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.09388</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider adaptive control of the Linear Quadratic Regulator (LQR), where
an unknown linear system is controlled subject to quadratic costs. Leveraging
recent developments in the estimation of linear systems and in robust
controller synthesis, we present the first provably polynomial time algorithm
that provides high probability guarantees of sub-linear regret on this problem.
We further study the interplay between regret minimization and parameter
estimation by proving a lower bound on the expected regret in terms of the
exploration schedule used by any algorithm. Finally, we conduct a numerical
study comparing our robust adaptive algorithm to other methods from the
adaptive LQR literature, and demonstrate the flexibility of our proposed method
by extending it to a demand forecasting problem subject to state constraints.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dean_S/0/1/0/all/0/1&quot;&gt;Sarah Dean&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mania_H/0/1/0/all/0/1&quot;&gt;Horia Mania&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Matni_N/0/1/0/all/0/1&quot;&gt;Nikolai Matni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Recht_B/0/1/0/all/0/1&quot;&gt;Benjamin Recht&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tu_S/0/1/0/all/0/1&quot;&gt;Stephen Tu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09406">
<title>Scalable Bayesian Learning for State Space Models using Variational Inference with SMC Samplers. (arXiv:1805.09406v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.09406</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a scalable approach to performing approximate fully Bayesian
inference in generic state space models. The proposed method is an alternative
to particle MCMC that provides full Bayesian inference of both the dynamic
latent states and the static parameters of the model. We build up on recent
advances in computational statistics that combine variational methods with
sequential Monte Carlo sampling and we demonstrate the advantages of performing
full Bayesian inference over the static parameters rather than just performing
variational EM approximations. We illustrate how our approach enables scalable
inference in multivariate stochastic volatility models and self-exciting point
process models that allow for flexible dynamics in the latent intensity
function.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hirt_M/0/1/0/all/0/1&quot;&gt;Marcel Hirt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dellaportas_P/0/1/0/all/0/1&quot;&gt;Petros Dellaportas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09450">
<title>Large Data and Zero Noise Limits of Graph-Based Semi-Supervised Learning Algorithms. (arXiv:1805.09450v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.09450</link>
<description rdf:parseType="Literal">&lt;p&gt;Scalings in which the graph Laplacian approaches a differential operator in
the large graph limit are used to develop understanding of a number of
algorithms for semi-supervised learning; in particular the extension, to this
graph setting, of the probit algorithm, level set and kriging methods, are
studied. Both optimization and Bayesian approaches are considered, based around
a regularizing quadratic form found from an affine transformation of the
Laplacian, raised to a, possibly fractional, exponent. Conditions on the
parameters defining this quadratic form are identified under which well-defined
limiting continuum analogues of the optimization and Bayesian semi-supervised
learning problems may be found, thereby shedding light on the design of
algorithms in the large graph setting. The large graph limits of the
optimization formulations are tackled through $\Gamma$-convergence, using the
recently introduced $TL^p$ metric. The small labelling noise limit of the
Bayesian formulations are also identified, and contrasted with pre-existing
harmonic function approaches to the problem.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dunlop_M/0/1/0/all/0/1&quot;&gt;Matthew M. Dunlop&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Slepcev_D/0/1/0/all/0/1&quot;&gt;Dejan Slep&amp;#x10d;ev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Stuart_A/0/1/0/all/0/1&quot;&gt;Andrew M. Stuart&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Thorpe_M/0/1/0/all/0/1&quot;&gt;Matthew Thorpe&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09464">
<title>Simple and practical algorithms for $\ell_p$-norm low-rank approximation. (arXiv:1805.09464v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.09464</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose practical algorithms for entrywise $\ell_p$-norm low-rank
approximation, for $p = 1$ or $p = \infty$. The proposed framework, which is
non-convex and gradient-based, is easy to implement and typically attains
better approximations, faster, than state of the art.
&lt;/p&gt;
&lt;p&gt;From a theoretical standpoint, we show that the proposed scheme can attain
$(1 + \varepsilon)$-OPT approximations. Our algorithms are not
hyperparameter-free: they achieve the desiderata only assuming algorithm&apos;s
hyperparameters are known a priori---or are at least approximable. I.e., our
theory indicates what problem quantities need to be known, in order to get a
good solution within polynomial time, and does not contradict to recent
inapproximabilty results, as in [46].
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kyrillidis_A/0/1/0/all/0/1&quot;&gt;Anastasios Kyrillidis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09473">
<title>Deploy Large-Scale Deep Neural Networks in Resource Constrained IoT Devices with Local Quantization Region. (arXiv:1805.09473v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.09473</link>
<description rdf:parseType="Literal">&lt;p&gt;Implementing large-scale deep neural networks with high computational
complexity on low-cost IoT devices may inevitably be constrained by limited
computation resource, making the devices hard to respond in real-time. This
disjunction makes the state-of-art deep learning algorithms, i.e. CNN
(Convolutional Neural Networks), incompatible with IoT world. We present a
low-bit (range from 8-bit to 1-bit) scheme with our local quantization region
algorithm. We use models in Caffe model zoo as our example tasks to evaluate
the effect of our low precision data representation scheme. With the available
of local quantization region, we find implementations on top of those schemes
could greatly retain the model accuracy, besides the reduction of computational
complexity. For example, our 8-bit scheme has no drops on top-1 and top-5
accuracy with 2x speedup on Intel Edison IoT platform. Implementations based on
our 4-bit, 2-bit or 1-bit scheme are also applicable to IoT devices with
advances of low computational complexity. For example, the drop on our task is
only 0.7% when using 2-bit scheme, a scheme which could largely save
transistors. Making low-bit scheme usable here opens a new door for further
optimization on commodity IoT controller, i.e. extra speed-up could be achieved
by replacing multiply-accumulate operations with the proposed table look-up
operations. The whole study offers a new approach to relief the challenge of
bring advanced deep learning algorithm to resource constrained low-cost IoT
device.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yi Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1&quot;&gt;Andy Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xiaoming Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ji_J/0/1/0/all/0/1&quot;&gt;Jiang Ji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhenyang Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_Y/0/1/0/all/0/1&quot;&gt;Yan Dai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09480">
<title>Optimal Algorithms for Continuous Non-monotone Submodular and DR-Submodular Maximization. (arXiv:1805.09480v1 [cs.DS])</title>
<link>http://arxiv.org/abs/1805.09480</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we study the fundamental problems of maximizing a continuous
non-monotone submodular function over the hypercube, both with and without
coordinate-wise concavity. This family of optimization problems has several
applications in machine learning, economics, and communication systems. Our
main result is the first $\frac{1}{2}$-approximation algorithm for continuous
submodular function maximization; this approximation factor of $\frac{1}{2}$ is
the best possible for algorithms that only query the objective function at
polynomially many points. For the special case of DR-submodular maximization,
i.e. when the submodular functions is also coordinate wise concave along all
coordinates, we provide a different $\frac{1}{2}$-approximation algorithm that
runs in quasilinear time. Both of these results improve upon prior work [Bian
et al, 2017, Soma and Yoshida, 2017].
&lt;/p&gt;
&lt;p&gt;Our first algorithm uses novel ideas such as reducing the guaranteed
approximation problem to analyzing a zero-sum game for each coordinate, and
incorporates the geometry of this zero-sum game to fix the value at this
coordinate. Our second algorithm exploits coordinate-wise concavity to identify
a monotone equilibrium condition sufficient for getting the required
approximation guarantee, and hunts for the equilibrium point using binary
search. We further run experiments to verify the performance of our proposed
algorithms in related machine learning applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niazadeh_R/0/1/0/all/0/1&quot;&gt;Rad Niazadeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roughgarden_T/0/1/0/all/0/1&quot;&gt;Tim Roughgarden&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Joshua R. Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09505">
<title>Kernel-estimated Nonparametric Overlap-Based Syncytial Clustering. (arXiv:1805.09505v1 [stat.ME])</title>
<link>http://arxiv.org/abs/1805.09505</link>
<description rdf:parseType="Literal">&lt;p&gt;Standard clustering algorithms usually find regular-structured clusters such
as ellipsoidally- or spherically-dispersed groups, but are more challenged with
groups lacking formal structure or definition. Syncytial clustering is the name
that we introduce for methods that merge groups obtained from standard
clustering algorithms in order to reveal complex group structure in the data.
Here, we develop a distribution-free fully-automated syncytial clustering
algorithm that can be used with $k$-means and other algorithms. Our approach
computes the cumulative distribution function of the normed residuals from an
appropriately fit $k$-groups model and calculates the nonparametric overlap
between each pair of groups. Groups with high pairwise overlaps are merged as
long as the generalized overlap decreases. Our methodology is always a top
performer in identifying groups with regular and irregular structures in
several datasets. The approach is also used to identify the distinct kinds of
gamma ray bursts in the Burst and Transient Source Experiment 4Br catalog and
also the distinct kinds of activation in a functional Magnetic Resonance
Imaging study.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Almodovar_Rivera_I/0/1/0/all/0/1&quot;&gt;Israel Almod&amp;#xf3;var-Rivera&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Maitra_R/0/1/0/all/0/1&quot;&gt;Ranjan Maitra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09527">
<title>Stable specification search in structural equation model with latent variables. (arXiv:1805.09527v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.09527</link>
<description rdf:parseType="Literal">&lt;p&gt;In our previous study, we introduced stable specification search for
cross-sectional data (S3C). It is an exploratory causal method that combines
stability selection concept and multi-objective optimization to search for
stable and parsimonious causal structures across the entire range of model
complexities. In this study, we extended S3C to S3C-Latent, to model causal
relations between latent variables. We evaluated S3C-Latent on simulated data
and compared the results to those of PC-MIMBuild, an extension of the PC
algorithm, the state-of-the-art causal discovery method. The comparison showed
that S3C-Latent achieved better performance. We also applied S3C-Latent to
real-world data of children with attention deficit/hyperactivity disorder and
data about measuring mental abilities among pupils. The results are consistent
with those of previous studies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rahmadi_R/0/1/0/all/0/1&quot;&gt;Ridho Rahmadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Groot_P/0/1/0/all/0/1&quot;&gt;Perry Groot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Heskes_T/0/1/0/all/0/1&quot;&gt;Tom Heskes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09547">
<title>Interpretable and Compositional Relation Learning by Joint Training with an Autoencoder. (arXiv:1805.09547v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.09547</link>
<description rdf:parseType="Literal">&lt;p&gt;Embedding models for entities and relations are extremely useful for
recovering missing facts in a knowledge base. Intuitively, a relation can be
modeled by a matrix mapping entity vectors. However, relations reside on low
dimension sub-manifolds in the parameter space of arbitrary matrices---for one
reason, composition of two relations $\boldsymbol{M}_1,\boldsymbol{M}_2$ may
match a third $\boldsymbol{M}_3$ (e.g. composition of relations
currency_of_country and country_of_film usually matches
currency_of_film_budget), which imposes compositional constraints to be
satisfied by the parameters (i.e. $\boldsymbol{M}_1\cdot
\boldsymbol{M}_2\approx \boldsymbol{M}_3$). In this paper we investigate a
dimension reduction technique by training relations jointly with an
autoencoder, which is expected to better capture compositional constraints. We
achieve state-of-the-art on Knowledge Base Completion tasks with strongly
improved Mean Rank, and show that joint training with an autoencoder leads to
interpretable sparse codings of relations, helps discovering compositional
constraints and benefits from compositional training. Our source code is
released at github.com/tianran/glimvec.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Takahashi_R/0/1/0/all/0/1&quot;&gt;Ryo Takahashi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tian_R/0/1/0/all/0/1&quot;&gt;Ran Tian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Inui_K/0/1/0/all/0/1&quot;&gt;Kentaro Inui&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09567">
<title>A Unified Probabilistic Model for Learning Latent Factors and Their Connectivities from High-Dimensional Data. (arXiv:1805.09567v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.09567</link>
<description rdf:parseType="Literal">&lt;p&gt;Connectivity estimation is challenging in the context of high-dimensional
data. A useful preprocessing step is to group variables into clusters, however,
it is not always clear how to do so from the perspective of connectivity
estimation. Another practical challenge is that we may have data from multiple
related classes (e.g., multiple subjects or conditions) and wish to incorporate
constraints on the similarities across classes. We propose a probabilistic
model which simultaneously performs both a grouping of variables (i.e.,
detecting community structure) and estimation of connectivities between the
groups which correspond to latent variables. The model is essentially a factor
analysis model where the factors are allowed to have arbitrary correlations,
while the factor loading matrix is constrained to express a community
structure. The model can be applied on multiple classes so that the
connectivities can be different between the classes, while the community
structure is the same for all classes. We propose an efficient estimation
algorithm based on score matching, and prove the identifiability of the model.
Finally, we present an extension to directed (causal) connectivities over
latent variables. Simulations and experiments on fMRI data validate the
practical utility of the method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Monti_R/0/1/0/all/0/1&quot;&gt;Ricardo Pio Monti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hyvarinen_A/0/1/0/all/0/1&quot;&gt;Aapo Hyv&amp;#xe4;rinen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09575">
<title>Primal-Dual Wasserstein GAN. (arXiv:1805.09575v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.09575</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce Primal-Dual Wasserstein GAN, a new learning algorithm for
building latent variable models of the data distribution based on the primal
and the dual formulations of the optimal transport (OT) problem. We utilize the
primal formulation to learn a flexible inference mechanism and to create an
optimal approximate coupling between the data distribution and the generative
model. In order to learn the generative model, we use the dual formulation and
train the decoder adversarially through a critic network that is regularized by
the approximate coupling obtained from the primal. Unlike previous methods that
violate various properties of the optimal critic, we regularize the norm and
the direction of the gradients of the critic function. Our model shares many of
the desirable properties of auto-encoding models in terms of mode coverage and
latent structure, while avoiding their undesirable averaging properties, e.g.
their inability to capture sharp visual features when modeling real images. We
compare our algorithm with several other generative modeling techniques that
utilize Wasserstein distances on Frechet Inception Distance (FID) and Inception
Scores (IS).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gemici_M/0/1/0/all/0/1&quot;&gt;Mevlana Gemici&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Akata_Z/0/1/0/all/0/1&quot;&gt;Zeynep Akata&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Welling_M/0/1/0/all/0/1&quot;&gt;Max Welling&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09639">
<title>Nonlinear Acceleration of Deep Neural Networks. (arXiv:1805.09639v1 [math.OC])</title>
<link>http://arxiv.org/abs/1805.09639</link>
<description rdf:parseType="Literal">&lt;p&gt;Regularized nonlinear acceleration (RNA) is a generic extrapolation scheme
for optimization methods, with marginal computational overhead. It aims to
improve convergence using only the iterates of simple iterative algorithms.
However, so far its application to optimization was theoretically limited to
gradient descent and other single-step algorithms. Here, we adapt RNA to a much
broader setting including stochastic gradient with momentum and Nesterov&apos;s fast
gradient. We use it to train deep neural networks, and empirically observe that
extrapolated networks are more accurate, especially in the early iterations. A
straightforward application of our algorithm when training ResNet-152 on
ImageNet produces a top-1 test error of 20.88%, improving by 0.8% the reference
classification pipeline. Furthermore, the code runs offline in this case, so it
never negatively affects performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Scieur_D/0/1/0/all/0/1&quot;&gt;Damien Scieur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Oyallon_E/0/1/0/all/0/1&quot;&gt;Edouard Oyallon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+dAspremont_A/0/1/0/all/0/1&quot;&gt;Alexandre d&amp;#x27;Aspremont&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Bach_F/0/1/0/all/0/1&quot;&gt;Francis Bach&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09654">
<title>Multivariate Convolutional Sparse Coding for Electromagnetic Brain Signals. (arXiv:1805.09654v1 [eess.SP])</title>
<link>http://arxiv.org/abs/1805.09654</link>
<description rdf:parseType="Literal">&lt;p&gt;Frequency-specific patterns of neural activity are traditionally interpreted
as sustained rhythmic oscillations, and related to cognitive mechanisms such as
attention, high level visual processing or motor control. While alpha waves
(8--12\,Hz) are known to closely resemble short sinusoids, and thus are
revealed by Fourier analysis or wavelet transforms, there is an evolving debate
that electromagnetic neural signals are composed of more complex waveforms that
cannot be analyzed by linear filters and traditional signal representations. In
this paper, we propose to learn dedicated representations of such recordings
using a multivariate convolutional sparse coding (CSC) algorithm. Applied to
electroencephalography (EEG) or magnetoencephalography (MEG) data, this method
is able to learn not only prototypical temporal waveforms, but also associated
spatial patterns so their origin can be localized in the brain. Our algorithm
is based on alternated minimization and a greedy coordinate descent solver that
leads to state-of-the-art running time on long time series. To demonstrate the
implications of this method, we apply it to MEG data and show that it is able
to recover biological artifacts. More remarkably, our approach also reveals the
presence of non-sinusoidal mu-shaped patterns, along with their topographic
maps related to the somatosensory cortex.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Tour_T/0/1/0/all/0/1&quot;&gt;Tom Dupr&amp;#xe9; La Tour&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Moreau_T/0/1/0/all/0/1&quot;&gt;Thomas Moreau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Jas_M/0/1/0/all/0/1&quot;&gt;Mainak Jas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Gramfort_A/0/1/0/all/0/1&quot;&gt;Alexandre Gramfort&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09682">
<title>Phocas: dimensional Byzantine-resilient stochastic gradient descent. (arXiv:1805.09682v1 [cs.DC])</title>
<link>http://arxiv.org/abs/1805.09682</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a novel robust aggregation rule for distributed synchronous
Stochastic Gradient Descent~(SGD) under a general Byzantine failure model. The
attackers can arbitrarily manipulate the data transferred between the servers
and the workers in the parameter server~(PS) architecture. We prove the
Byzantine resilience of the proposed aggregation rules. Empirical analysis
shows that the proposed techniques outperform current approaches for realistic
use cases and Byzantine attack scenarios.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1&quot;&gt;Cong Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koyejo_O/0/1/0/all/0/1&quot;&gt;Oluwasanmi Koyejo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_I/0/1/0/all/0/1&quot;&gt;Indranil Gupta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09717">
<title>Learning Classifiers with Fenchel-Young Losses: Generalized Entropies, Margins, and Algorithms. (arXiv:1805.09717v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.09717</link>
<description rdf:parseType="Literal">&lt;p&gt;We study in this paper Fenchel-Young losses, a generic way to construct
convex loss functions from a convex regularizer. We provide an in-depth study
of their properties in a broad setting and show that they unify many well-known
loss functions. When constructed from a generalized entropy, which includes
well-known entropies such as Shannon and Tsallis entropies, we show that
Fenchel-Young losses induce a predictive probability distribution and develop
an efficient algorithm to compute that distribution for separable entropies. We
derive conditions for generalized entropies to yield a distribution with sparse
support and losses with a separation margin. Finally, we present both primal
and dual algorithms to learn predictive models with generic Fenchel-Young
losses.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Blondel_M/0/1/0/all/0/1&quot;&gt;Mathieu Blondel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Martins_A/0/1/0/all/0/1&quot;&gt;Andr&amp;#xe9; F. T. Martins&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Niculae_V/0/1/0/all/0/1&quot;&gt;Vlad Niculae&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09719">
<title>Learning convex polytopes with margin. (arXiv:1805.09719v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.09719</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a near-optimal algorithm for properly learning convex polytopes in
the realizable PAC setting from data with a margin. Our first contribution is
to identify distinct generalizations of the notion of {\em margin} from
hyperplanes to polytopes and to understand how they relate geometrically; this
result may be of interest beyond the learning setting. Our novel learning
algorithm constructs a consistent polytope as an intersection of about $t \log
t$ halfspaces in time polynomial in $t$ (where $t$ is the number of halfspaces
forming an optimal polytope). This is an exponential improvement over the state
of the art [Arriaga and Vempala, 2006]. We also improve over the
super-polynomial-in-$t$ algorithm of Klivans and Servedio [2008], while
achieving a better sample complexity. Finally, we provide the first nearly
matching hardness-of-approximation lower bound, whence our claim of near
optimality.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gottlieb_L/0/1/0/all/0/1&quot;&gt;Lee-Ad Gottlieb&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaufman_E/0/1/0/all/0/1&quot;&gt;Eran Kaufman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kontorovich_A/0/1/0/all/0/1&quot;&gt;Aryeh Kontorovich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nivasch_G/0/1/0/all/0/1&quot;&gt;Gabriel Nivasch&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09757">
<title>Geographical Hidden Markov Tree for Flood Extent Mapping (With Proof Appendix). (arXiv:1805.09757v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.09757</link>
<description rdf:parseType="Literal">&lt;p&gt;Flood extent mapping plays a crucial role in disaster management and national
water forecasting. Unfortunately, traditional classification methods are often
hampered by the existence of noise, obstacles and heterogeneity in spectral
features as well as implicit anisotropic spatial dependency across class
labels. In this paper, we propose geographical hidden Markov tree, a
probabilistic graphical model that generalizes the common hidden Markov model
from a one dimensional sequence to a two dimensional map. Anisotropic spatial
dependency is incorporated in the hidden class layer with a reverse tree
structure. We also investigate computational algorithms for reverse tree
construction, model parameter learning and class inference. Extensive
evaluations on both synthetic and real world datasets show that proposed model
outperforms multiple baselines in flood mapping, and our algorithms are
scalable on large data sizes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_M/0/1/0/all/0/1&quot;&gt;Miao Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1&quot;&gt;Zhe Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sainju_A/0/1/0/all/0/1&quot;&gt;Arpan Man Sainju&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09772">
<title>Auto-Detection of Safety Issues in Baby Products. (arXiv:1805.09772v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.09772</link>
<description rdf:parseType="Literal">&lt;p&gt;Every year, thousands of people receive consumer product related injuries.
Research indicates that online customer reviews can be processed to
autonomously identify product safety issues. Early identification of safety
issues can lead to earlier recalls, and thus fewer injuries and deaths. A
dataset of product reviews from Amazon.com was compiled, along with
\emph{SaferProducts.gov} complaints and recall descriptions from the Consumer
Product Safety Commission (CPSC) and European Commission Rapid Alert system. A
system was built to clean the collected text and to extract relevant features.
Dimensionality reduction was performed by computing feature relevance through a
Random Forest and discarding features with low information gain. Various
classifiers were analyzed, including Logistic Regression, SVMs,
Na{\&quot;i}ve-Bayes, Random Forests, and an Ensemble classifier. Experimentation
with various features and classifier combinations resulted in a logistic
regression model with 70.2\% precision in the top 50 reviews surfaced. This
classifier outperforms all benchmarks set by related literature and consumer
product safety professionals.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bleaney_G/0/1/0/all/0/1&quot;&gt;Graham Bleaney&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuzyk_M/0/1/0/all/0/1&quot;&gt;Matthew Kuzyk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Man_J/0/1/0/all/0/1&quot;&gt;Julian Man&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mayanloo_H/0/1/0/all/0/1&quot;&gt;Hossein Mayanloo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tizhoosh_H/0/1/0/all/0/1&quot;&gt;H.R.Tizhoosh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09781">
<title>Log Gaussian Cox Process Networks. (arXiv:1805.09781v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.09781</link>
<description rdf:parseType="Literal">&lt;p&gt;We generalize the log Gaussian Cox process (LGCP) framework to model multiple
correlated point data jointly. The resulting log Gaussian Cox process network
(LGCPN) considers the observations as realizations of multiple LGCPs, whose log
intensities are given by linear combinations of latent functions drawn from
Gaussian process priors. The coefficients of these linear combinations are also
drawn from Gaussian processes and can incorporate additional dependencies a
priori. We derive closed-form expressions for the moments of the intensity
functions in our model and use them to develop an efficient variational
inference algorithm that is orders of magnitude faster than competing
deterministic and stochastic approximations of multivariate LGCP and
coregionalization models. Our approach outperforms the state of the art in
jointly estimating multiple bovine tuberculosis incidents in Cornwall, UK, and
multiple crime type intensities across New York city.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Aglietti_V/0/1/0/all/0/1&quot;&gt;Virginia Aglietti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Damoulas_T/0/1/0/all/0/1&quot;&gt;Theo Damoulas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bonilla_E/0/1/0/all/0/1&quot;&gt;Edwin Bonilla&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09793">
<title>New Insights into Bootstrapping for Bandits. (arXiv:1805.09793v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.09793</link>
<description rdf:parseType="Literal">&lt;p&gt;We investigate the use of bootstrapping in the bandit setting. We first show
that the commonly used non-parametric bootstrapping (NPB) procedure can be
provably inefficient and establish a near-linear lower bound on the regret
incurred by it under the bandit model with Bernoulli rewards. We show that NPB
with an appropriate amount of forced exploration can result in sub-linear
albeit sub-optimal regret. As an alternative to NPB, we propose a weighted
bootstrapping (WB) procedure. For Bernoulli rewards, WB with multiplicative
exponential weights is mathematically equivalent to Thompson sampling (TS) and
results in near-optimal regret bounds. Similarly, in the bandit setting with
Gaussian rewards, we show that WB with additive Gaussian weights achieves
near-optimal regret. Beyond these special cases, we show that WB leads to
better empirical performance than TS for several reward distributions bounded
on $[0,1]$. For the contextual bandit setting, we give practical guidelines
that make bootstrapping simple and efficient to implement and result in good
empirical performance on real-world datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vaswani_S/0/1/0/all/0/1&quot;&gt;Sharan Vaswani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kveton_B/0/1/0/all/0/1&quot;&gt;Branislav Kveton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_Z/0/1/0/all/0/1&quot;&gt;Zheng Wen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rao_A/0/1/0/all/0/1&quot;&gt;Anup Rao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmidt_M/0/1/0/all/0/1&quot;&gt;Mark Schmidt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbasi_Yadkori_Y/0/1/0/all/0/1&quot;&gt;Yasin Abbasi-Yadkori&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09804">
<title>Implicit Autoencoders. (arXiv:1805.09804v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.09804</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we describe the &quot;implicit autoencoder&quot; (IAE), a generative
autoencoder in which both the generative path and the recognition path are
parametrized by implicit distributions. We use two generative adversarial
networks to define the reconstruction and the regularization cost functions of
the implicit autoencoder, and derive the learning rules based on
maximum-likelihood learning. Using implicit distributions allows us to learn
more expressive posterior and conditional likelihood distributions for the
autoencoder. Learning an expressive conditional likelihood distribution enables
the latent code to only capture the abstract and high-level information of the
data, while the remaining information is captured by the implicit conditional
likelihood distribution. For example, we show that implicit autoencoders can
disentangle the global and local information, and perform deterministic or
stochastic reconstructions of the images. We further show that implicit
autoencoders can disentangle discrete underlying factors of variation from the
continuous factors in an unsupervised fashion, and perform clustering and
semi-supervised learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Makhzani_A/0/1/0/all/0/1&quot;&gt;Alireza Makhzani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.03439">
<title>Frequentist Consistency of Variational Bayes. (arXiv:1705.03439v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1705.03439</link>
<description rdf:parseType="Literal">&lt;p&gt;A key challenge for modern Bayesian statistics is how to perform scalable
inference of posterior distributions. To address this challenge, variational
Bayes (VB) methods have emerged as a popular alternative to the classical
Markov chain Monte Carlo (MCMC) methods. VB methods tend to be faster while
achieving comparable predictive performance. However, there are few theoretical
results around VB. In this paper, we establish frequentist consistency and
asymptotic normality of VB methods. Specifically, we connect VB methods to
point estimates based on variational approximations, called frequentist
variational approximations, and we use the connection to prove a variational
Bernstein-von Mises theorem. The theorem leverages the theoretical
characterizations of frequentist variational approximations to understand
asymptotic properties of VB. In summary, we prove that (1) the VB posterior
converges to the Kullback-Leibler (KL) minimizer of a normal distribution,
centered at the truth and (2) the corresponding variational expectation of the
parameter is consistent and asymptotically normal. As applications of the
theorem, we derive asymptotic properties of VB posteriors in Bayesian mixture
models, Bayesian generalized linear mixed models, and Bayesian stochastic block
models. We conduct a simulation study to illustrate these theoretical results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yixin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Blei_D/0/1/0/all/0/1&quot;&gt;David M. Blei&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.08415">
<title>Supervised Community Detection with Hierarchical Graph Neural Networks. (arXiv:1705.08415v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1705.08415</link>
<description rdf:parseType="Literal">&lt;p&gt;We study methods for supervised community detection on graphs. This
estimation problem is typically formulated in terms of the spectrum of certain
operators, as well as with posterior inference under certain probabilistic
graphical models. Focusing on random graph families such as the Stochastic
Block Model, recent research has unified both approaches, and identified both
statistical and computational signal-to-noise detection thresholds.
&lt;/p&gt;
&lt;p&gt;We identify the resulting class of algorithms with a family of Graph Neural
Networks and show that they can reach those detection thresholds in a purely
data-driven manner, without access to the underlying generative models and with
no parameter assumptions. For that purpose, we propose to augment GNNs with the
non-Backtracking operator, defined on the line graph of edge adjacencies. We
also perform the first analysis of optimization landscape on a simplified GNN
family, revealing an interesting transition from rugged to simple as the graph
size increases. Finally, the resulting model is also tested on real datasets,
performing significantly better than rigid parametric models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhengdao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bruna_J/0/1/0/all/0/1&quot;&gt;Joan Bruna&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.04072">
<title>A convergence frame for inexact nonconvex and nonsmooth algorithms and its applications to several iterations. (arXiv:1709.04072v4 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/1709.04072</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we consider the convergence of an abstract inexact nonconvex
and nonsmooth algorithm. We promise a pseudo sufficient descent condition and a
pseudo relative error condition, which both are related to an auxiliary
sequence, for the algorithm; and a continuity condition is assumed to hold. In
fact, a wide of classical inexact nonconvex and nonsmooth algorithms allow
these three conditions. Under the finite energy assumption on the auxiliary
sequence, we prove the sequence generated by the general algorithm converges to
a critical point of the objective function if being assumed Kurdyka-
Lojasiewicz property. The core of the proofs lies on building a new Lyapunov
function, whose successive difference provides a bound for the successive
difference of the points generated by the algorithm. And then, we apply our
findings to several classical nonconvex iterative algorithms and derive
corresponding convergence results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Sun_T/0/1/0/all/0/1&quot;&gt;Tao Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Jiang_H/0/1/0/all/0/1&quot;&gt;Hao Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Cheng_L/0/1/0/all/0/1&quot;&gt;Lizhi Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zhu_W/0/1/0/all/0/1&quot;&gt;Wei Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05283">
<title>Designing Random Graph Models Using Variational Autoencoders With Applications to Chemical Design. (arXiv:1802.05283v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.05283</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep generative models have been praised for their ability to learn smooth
latent representation of images, text, and audio, which can then be used to
generate new, plausible data. However, current generative models are unable to
work with graphs due to their unique characteristics--their underlying
structure is not Euclidean or grid-like, they remain isomorphic under
permutation of the nodes labels, and they come with a different number of nodes
and edges. In this paper, we propose NeVAE, a novel variational autoencoder for
graphs, whose encoder and decoder are specially designed to account for the
above properties by means of several technical innovations. In addition, by
using masking, the decoder is able to guarantee a set of local structural and
functional properties in the generated graphs. Experiments reveal that our
model is able to learn and mimic the generative process of several well-known
random graph models and can be used to discover new molecules more effectively
than several state of the art methods. Moreover, by utilizing Bayesian
optimization over the continuous latent representation of molecules our model
finds, we can also identify molecules that maximize certain desirable
properties more effectively than alternatives.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Samanta_B/0/1/0/all/0/1&quot;&gt;Bidisha Samanta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+De_A/0/1/0/all/0/1&quot;&gt;Abir De&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ganguly_N/0/1/0/all/0/1&quot;&gt;Niloy Ganguly&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gomez_Rodriguez_M/0/1/0/all/0/1&quot;&gt;Manuel Gomez-Rodriguez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08334">
<title>Learning Without Mixing: Towards A Sharp Analysis of Linear System Identification. (arXiv:1802.08334v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.08334</link>
<description rdf:parseType="Literal">&lt;p&gt;We prove that the ordinary least-squares (OLS) estimator attains nearly
minimax optimal performance for the identification of linear dynamical systems
from a single observed trajectory. Our upper bound relies on a generalization
of Mendelson&apos;s small-ball method to dependent data, eschewing the use of
standard mixing-time arguments. Our lower bounds reveal that these upper bounds
match up to logarithmic factors. In particular, we capture the correct
signal-to-noise behavior of the problem, showing that more unstable linear
systems are easier to estimate. This behavior is qualitatively different from
arguments which rely on mixing-time calculations that suggest that unstable
systems are more difficult to estimate. We generalize our technique to provide
bounds for a more general class of linear response time-series.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simchowitz_M/0/1/0/all/0/1&quot;&gt;Max Simchowitz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mania_H/0/1/0/all/0/1&quot;&gt;Horia Mania&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tu_S/0/1/0/all/0/1&quot;&gt;Stephen Tu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1&quot;&gt;Michael I. Jordan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Recht_B/0/1/0/all/0/1&quot;&gt;Benjamin Recht&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.01682">
<title>Beyond Greedy Ranking: Slate Optimization via List-CVAE. (arXiv:1803.01682v5 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.01682</link>
<description rdf:parseType="Literal">&lt;p&gt;The conventional approach to solving the recommendation problem is through
greedy ranking by prediction scores for individual document candidates. However
these methods fail to optimize the slate as a whole, and often struggle at
capturing biases caused by the page layout and interdependencies between
documents. The slate recommendation problem aims to find the optimal, ordered
subset of documents, a.k.a. slate, given the page layout to serve users
recommendations. Solving this problem is hard due to combinatorial explosion of
document candidates and their display positions on the page. In this paper, we
introduce List Conditional Variational Auto-Encoders (List-CVAE) to learn the
joint distribution of documents on the slate conditional on user responses, and
directly generate slates. Experiments on simulated and real-world data show
that List-CVAE outperforms greedy ranking methods consistently on various
scales of documents corpora.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jiang_R/0/1/0/all/0/1&quot;&gt;Ray Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gowal_S/0/1/0/all/0/1&quot;&gt;Sven Gowal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mann_T/0/1/0/all/0/1&quot;&gt;Timothy A. Mann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rezende_D/0/1/0/all/0/1&quot;&gt;Danilo J. Rezende&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.03666">
<title>Standing Wave Decomposition Gaussian Process. (arXiv:1803.03666v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.03666</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a Standing Wave Decomposition (SWD) approximation to Gaussian
Process regression (GP). GP involves a costly matrix inversion operation, which
limits applicability to large data analysis. For an input space that can be
approximated by a grid and when correlations among data are short-ranged, the
kernel matrix inversion can be replaced by analytic diagonalization using the
SWD. We show that this approach applies to uni- and multi-dimensional input
data, extends to include longer-range correlations, and the grid can be in a
latent space and used as inducing points. Through simulations, we show that our
approximate method outperforms existing methods in predictive accuracy per unit
time in the regime where data are plentiful. Our SWD-GP is recommended for
regression analyses where there is a relatively large amount of data and/or
there are constraints on computation time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lu_C/0/1/0/all/0/1&quot;&gt;Chi-Ken Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yang_S/0/1/0/all/0/1&quot;&gt;Scott Cheng-Hsin Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shafto_P/0/1/0/all/0/1&quot;&gt;Patrick Shafto&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07179">
<title>Markov Chain Importance Sampling - a highly efficient estimator for MCMC. (arXiv:1805.07179v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.07179</link>
<description rdf:parseType="Literal">&lt;p&gt;Markov chain algorithms are ubiquitous in machine learning and statistics and
many other disciplines. In this work we present a novel estimator applicable to
several classes of Markov chains, dubbed Markov chain importance sampling
(MCIS). For a broad class of Metropolis-Hastings algorithms, MCIS efficiently
makes use of rejected proposals. For discretized Langevin diffusions, it
provides a novel way of correcting the discretization error. Our estimator
satisfies a central limit theorem and improves on error per CPU cycle, often to
a large extent. As a by-product it enables estimating the normalizing constant,
an important quantity in Bayesian machine learning and statistics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schuster_I/0/1/0/all/0/1&quot;&gt;Ingmar Schuster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Klebanov_I/0/1/0/all/0/1&quot;&gt;Ilja Klebanov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07914">
<title>Imitating Latent Policies from Observation. (arXiv:1805.07914v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.07914</link>
<description rdf:parseType="Literal">&lt;p&gt;We describe a novel approach to imitation learning that infers latent
policies directly from state observations. We introduce a method that
characterizes the causal effects of unknown actions on observations while
simultaneously predicting their likelihood. We then outline an action alignment
procedure that leverages a small amount of environment interactions to
determine a mapping between latent and real-world actions. We show that this
corrected labeling can be used for imitating the observed behavior, even though
no expert actions are given. We evaluate our approach within classic control
and photo-realistic visual environments and demonstrate that it performs well
when compared to standard approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Edwards_A/0/1/0/all/0/1&quot;&gt;Ashley D. Edwards&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sahni_H/0/1/0/all/0/1&quot;&gt;Himanshu Sahni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schroecker_Y/0/1/0/all/0/1&quot;&gt;Yannick Schroecker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Isbell_C/0/1/0/all/0/1&quot;&gt;Charles L. Isbell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08527">
<title>Safe Element Screening for Submodular Function Minimization. (arXiv:1805.08527v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.08527</link>
<description rdf:parseType="Literal">&lt;p&gt;Submodular functions are discrete analogs of convex functions, which have
applications in various fields, including machine learning, computer vision and
signal processing. However, in large-scale applications, solving Submodular
Function Minimization (SFM) problems remains challenging. In this paper, we
make the first attempt to extend the emerging technique named screening in
large-scale sparse learning to SFM for accelerating its optimization process.
Specifically, we propose a novel safe element screening method---based on a
careful studying of the relationships between SFM and the corresponding convex
proximal problems, as well as the accurate estimation of the optimum of the
proximal problem---to quickly identify the elements that are guaranteed to be
included (we refer to them as active) or excluded (inactive) in the final
optimal solution of SFM during the optimization process. By removing the
inactive elements and fixing the active ones, the problem size can be
dramatically reduced, leading to great savings in the computational cost
without sacrificing accuracy. To the best of our knowledge, the proposed method
is the first screening method in the fields of SFM and even combinatorial
optimization, and thus points out a new direction for accelerating SFM
algorithms. Experiment results on both synthetic and real datasets demonstrate
the significant speedups gained by our screening method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Weizhong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hong_B/0/1/0/all/0/1&quot;&gt;Bin Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ma_L/0/1/0/all/0/1&quot;&gt;Lin Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_W/0/1/0/all/0/1&quot;&gt;Wei Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Tong Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09108">
<title>Deep Learning Estimation of Absorbed Dose for Nuclear Medicine Diagnostics. (arXiv:1805.09108v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.09108</link>
<description rdf:parseType="Literal">&lt;p&gt;The distribution of energy dose from Lu$^{177}$ radiotherapy can be estimated
by convolving an image of a time-integrated activity distribution with a dose
voxel kernel (dvk) consisting of different types of tissues. This fast and
inacurate approximation is inappropriate for personalized dosimetry as it
neglects tissue heterogenity. The latter can be calculated using different
imaging techniques such as CT and SPECT combined with a time consuming
monte-carlo simulation. The aim of this study is, for the first time, an
estimation of DVKs from CT-derived density kernels (dk) via deep learning in
convolutional neural networks (cnns). The proposed cnn achieved, on the test
set, a mean intersection over union (iou) of $= 0.86$ after $308$ epochs and a
corresponding mean squared error (mse) $= 1.24 \cdot 10^{-4}$. This
generalization ability shows that the trained cnn can indeed learn the complex
transfer function from dk to dvk. Future work will evaluate dvks estimated by
cnns with full monte-carlo simulations of a whole body CT to predict patient
specific voxel dose maps.
&lt;/p&gt;
&lt;p&gt;Keywords: Deep Learning, Nuclear Medicine, Diagnostics, Machine Learning,
Statistics
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Melodia_L/0/1/0/all/0/1&quot;&gt;Luciano Melodia&lt;/a&gt;</dc:creator>
</item></rdf:RDF>