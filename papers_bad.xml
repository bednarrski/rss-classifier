<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-07-24T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09174"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09177"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09203"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09217"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09703"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08856"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08894"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08920"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08934"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08941"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09205"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09232"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09244"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.05426"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.08534"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.08092"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.06957"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.07665"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08820"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08844"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08855"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08900"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08904"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08959"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09010"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09011"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09120"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09151"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09202"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09236"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.04454"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.05630"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.02550"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08061"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10586"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.02684"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.07543"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08409"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1807.09174">
<title>On the computational analysis of the genetic algorithm for attitude control of a carrier system. (arXiv:1807.09174v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1807.09174</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper intends to cover three main topics. First, a fuzzy-PID controller
is designed to control the thrust vector of a launch vehicle, accommodating a
CanSat. Then, the genetic algorithm (GA) is employed to optimize the controller
performance. Finally, through adjusting the algorithm parameters, their impact
on the optimization process is examined. In this regard, the motion vector
control is programmed based on the governing dynamic equations of motion for
payload delivery in the desired altitude and flight-path angle. This utilizes
one single input and one preferential fuzzy inference engine, where the latter
acts to avoid the system instability in large angles for the thrust vector. The
optimization objective functions include the deviations of the thrust vector
and the system from the equilibrium state, which must be met simultaneously.
Sensitivity analysis of the parameters of the genetic algorithm involves
examining nine different cases and discussing their impact on the optimization
results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jahanshahi_H/0/1/0/all/0/1&quot;&gt;Hadi Jahanshahi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sari_N/0/1/0/all/0/1&quot;&gt;Naeimeh Najafizadeh Sari&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09177">
<title>Robot Imitation through Vision, Kinesthetic and Force Features with Online Adaptation to Changing Environments. (arXiv:1807.09177v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1807.09177</link>
<description rdf:parseType="Literal">&lt;p&gt;Continuous Goal-Directed Actions (CGDA) is a robot imitation framework that
encodes actions as the changes they produce on the environment. While it
presents numerous advantages with respect to other robot imitation frameworks
in terms of generalization and portability, final robot joint trajectories for
the execution of actions are not necessarily encoded within the model. This is
studied as an optimization problem, and the solution is computed through
evolutionary algorithms in simulated environments. Evolutionary algorithms
require a large number of evaluations, which had made the use of these
algorithms in real world applications very challenging. This paper presents
online evolutionary strategies, as a change of paradigm within CGDA execution.
Online evolutionary strategies shift and merge motor execution into the
planning loop. A concrete online evolutionary strategy, Online Evolved
Trajectories (OET), is presented. OET drastically reduces computational times
between motor executions, and enables working in real world dynamic
environments and/or with human collaboration. Its performance has been measured
against Full Trajectory Evolution (FTE) and Incrementally Evolved Trajectories
(IET), obtaining the best overall results. Experimental evaluations are
performed on the TEO full-sized humanoid robot with &quot;paint&quot; and &quot;iron&quot; actions
that together involve vision, kinesthetic and force features.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fernandez_Fernandez_R/0/1/0/all/0/1&quot;&gt;Raul Fernandez-Fernandez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Victores_J/0/1/0/all/0/1&quot;&gt;Juan G. Victores&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Estevez_D/0/1/0/all/0/1&quot;&gt;David Estevez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balaguer_C/0/1/0/all/0/1&quot;&gt;Carlos Balaguer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09203">
<title>Theoretical Perspective of Convergence Complexity of Evolutionary Algorithms Adopting Optimal Mixing. (arXiv:1807.09203v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1807.09203</link>
<description rdf:parseType="Literal">&lt;p&gt;The optimal mixing evolutionary algorithms (OMEAs) have recently drawn much
attention for their robustness, small size of required population, and
efficiency in terms of number of function evaluations (NFE). In this paper, the
performances and behaviors of OMEAs are studied by investigating the mechanism
of optimal mixing (OM), the variation operator in OMEAs, under two scenarios --
one-layer and two-layer masks. For the case of one-layer masks, the required
population size is derived from the viewpoint of initial supply, while the
convergence time is derived by analyzing the progress of sub-solution growth.
NFE is then asymptotically bounded with rational probability by estimating the
probability of performing evaluations. For the case of two-layer masks,
empirical results indicate that the required population size is proportional to
both the degree of cross competition and the results from the one-layer-mask
case. The derived models also indicate that population sizing is decided by
initial supply when disjoint masks are adopted, that the high selection
pressure imposed by OM makes the composition of sub-problems impact little on
NFE, and that the population size requirement for two-layer masks increases
with the reverse-growth probability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tung_Y/0/1/0/all/0/1&quot;&gt;Yu-Fan Tung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1&quot;&gt;Tian-Li Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09217">
<title>Parallel Whale Optimization Algorithm for Solving Constrained and Unconstrained Optimization Problems. (arXiv:1807.09217v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1807.09217</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently the engineering optimization problems require large computational
demands and long solution time even on high multi-processors computational
devices. In this paper, an OpenMP inspired parallel version of the whale
optimization algorithm (PWOA) to obtain enhanced computational throughput and
global search capability is presented. It automatically detects the number of
available processors and divides the workload among them to accomplish the
effective utilization of the available resources. PWOA is applied on twenty
unconstrained optimization functions on multiple dimensions and five
constrained optimization engineering functions. The proposed parallelism PWOA
algorithms performance is evaluated using parallel metrics such as speedup,
efficiency. The comparison illustrates that the proposed PWOA algorithm has
obtained the same results while exceeding the sequential version in
performance. Furthermore, PWOA algorithm in the term of computational time and
speed of parallel metric was achieved better results over the sequential
processing compared to the standard WOA.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sauber_A/0/1/0/all/0/1&quot;&gt;Amr M. Sauber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nasef_M/0/1/0/all/0/1&quot;&gt;Mohammed M. Nasef&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Houssein_E/0/1/0/all/0/1&quot;&gt;Essam H. Houssein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hassanien_A/0/1/0/all/0/1&quot;&gt;Aboul Ella Hassanien&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09703">
<title>Boosting Cooperative Coevolution for Large Scale Optimization with a Fine-Grained Computation Resource Allocation Strategy. (arXiv:1802.09703v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1802.09703</link>
<description rdf:parseType="Literal">&lt;p&gt;Cooperative coevolution (CC) has shown great potential in solving large scale
optimization problems (LSOPs). However, traditional CC algorithms often waste
part of computation resource (CR) as they equally allocate CR among all the
subproblems. The recently developed contribution-based CC (CBCC) algorithms
improve the traditional ones to a certain extent by adaptively allocating CR
according to some heuristic rules. Different from existing works, this study
explicitly constructs a mathematical model for the CR allocation (CRA) problem
in CC and proposes a novel fine-grained CRA (FCRA) strategy by fully
considering both the theoretically optimal solution of the CRA model and the
evolution characteristics of CC. FCRA takes a single iteration as a basic CRA
unit and always selects the subproblem which is most likely to make the largest
contribution to the total fitness improvement to undergo a new iteration, where
the contribution of a subproblem at a new iteration is estimated according to
its current contribution, current evolution status as well as the estimation
for its current contribution. We verified the efficiency of FCRA by combining
it with SHADE which is an excellent differential evolution variant but has
never been employed in the CC framework. Experimental results on two benchmark
suites for LSOPs demonstrate that FCRA significantly outperforms existing CRA
strategies and the resultant CC algorithm is highly competitive in solving
LSOPs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_Z/0/1/0/all/0/1&quot;&gt;Zhigang Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1&quot;&gt;Yongsheng Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1&quot;&gt;Aimin Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yang Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1&quot;&gt;Zuren Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Lin Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08856">
<title>Toward a language-theoretic foundation for planning and filtering. (arXiv:1807.08856v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1807.08856</link>
<description rdf:parseType="Literal">&lt;p&gt;We address problems underlying the algorithmic question of automating the
co-design of robot hardware in tandem with its apposite software. Specifically,
we consider the impact that degradations of a robot&apos;s sensor and actuation
suites may have on the ability of that robot to complete its tasks. We
introduce a new formal structure that generalizes and consolidates a variety of
well-known structures including many forms of plans, planning problems, and
filters, into a single data structure called a procrustean graph, and give
these graph structures semantics in terms of ideas based in formal language
theory. We describe a collection of operations on procrustean graphs (both
semantics-preserving and semantics-mutating), and show how a family of
questions about the destructiveness of a change to the robot hardware can be
answered by applying these operations. We also highlight the connections
between this new approach and existing threads of research, including
combinatorial filtering, Erdmann&apos;s strategy complexes, and hybrid automata.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saberifar_F/0/1/0/all/0/1&quot;&gt;Fatemeh Zahra Saberifar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghasemlou_S/0/1/0/all/0/1&quot;&gt;Shervin Ghasemlou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shell_D/0/1/0/all/0/1&quot;&gt;Dylan A. Shell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+OKane_J/0/1/0/all/0/1&quot;&gt;Jason M. O&amp;#x27;Kane&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08894">
<title>ClusterNet: Instance Segmentation in RGB-D Images. (arXiv:1807.08894v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1807.08894</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a method for instance-level segmentation that uses RGB-D data as
input and provides detailed information about the location, geometry and number
of individual objects in the scene. This level of understanding is fundamental
for autonomous robots. It enables safe and robust decision-making under the
large uncertainty of the real-world. In our model, we propose to use the first
and second order moments of the object occupancy function to represent an
object instance. This enables us to transform the problem of instance-level
segmentation into a one-stage regression problem. We train an hourglass Deep
Neural Network (DNN) where each pixel in the output votes for the position of
the corresponding object center and for the object&apos;s size and pose. The final
instance segmentation is achieved through clustering in the space of moments.
The object-centric training loss is defined on the output of the clustering.
Our method outperforms the state-of-the-art instance segmentation method on our
synthesized dataset. We show that our method generalizes well on real-world
data achieving visually better segmentation results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shao_L/0/1/0/all/0/1&quot;&gt;Lin Shao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1&quot;&gt;Ye Tian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bohg_J/0/1/0/all/0/1&quot;&gt;Jeannette Bohg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08920">
<title>Competitive Inner-Imaging Squeeze and Excitation for Residual Network. (arXiv:1807.08920v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1807.08920</link>
<description rdf:parseType="Literal">&lt;p&gt;Residual Network make the very deep convolutional architecture works well,
which use the residual unit to supplement the identity mappings. On the other
hand, Squeeze-Excitation (SE) network propose a adaptively recalibrates
channel-wise attention approach to model the relationship of feature maps from
different convolutional channel. In this work, we propose the competitive SE
mechanism for residual network, rescaling value for each channel in this
structure will be determined by residual and identity mappings jointly, this
design enables us to expand the meaning of channel relationship modeling in
residual blocks: the modeling of competition between residual and identity
mappings make identity flow can controll the complement of residual feature
maps for itself. Further, we design a novel pair-view competitive SE block to
shrink the consumption and re-image the global characterizations of
intermediate convolutional channels. We carried out experiments on datasets:
CIFAR, SVHN, ImageNet, the proposed method can be compare with the
state-of-the-art results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1&quot;&gt;Yang Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_G/0/1/0/all/0/1&quot;&gt;Guihua Wen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_M/0/1/0/all/0/1&quot;&gt;Mingnan Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_D/0/1/0/all/0/1&quot;&gt;Dan Dai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08934">
<title>SAAGs: Biased Stochastic Variance Reduction Methods. (arXiv:1807.08934v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.08934</link>
<description rdf:parseType="Literal">&lt;p&gt;Stochastic optimization is one of the effective approach to deal with the
large-scale machine learning problems and the recent research has focused on
reduction of variance, caused by the noisy approximations of the gradients, and
momentum acceleration. In this paper, we have proposed simple variants of
SAAG-I and II (Stochastic Average Adjusted Gradient) \cite{Chauhan2017Saag},
called SAAG-III and IV, respectively. Unlike SAAG-I, starting point is set to
average of previous epoch in SAAG-III, and unlike SAAG-II, the snap point and
starting point are set to average and last iterate of previous epoch,
respectively. To determine the step size, we introduce Stochastic
Backtracking-Armijo line Search (SBAS) which performs line search only on
selected mini-batch of data points. Since backtracking line search is not
suitable for large-scale problems and the constants used to find the step size,
like Lipschitz constant, are not always available so SBAS could be very
effective in such cases. We also extend SAAGs (I, II, III, IV), to solve
non-smooth problems and design two update rules for smooth and non-smooth
problems. Moreover, our theoretical results prove linear convergence of SAAG-IV
for all the four combinations of smoothness and strong-convexity, in
expectation. Finally, our experimental studies prove the efficacy of proposed
methods against the state-of-art techniques, like, SVRG and VR-SGD.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chauhan_V/0/1/0/all/0/1&quot;&gt;Vinod Kumar Chauhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1&quot;&gt;Anuj Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dahiya_K/0/1/0/all/0/1&quot;&gt;Kalpana Dahiya&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08941">
<title>A Temporal Difference Reinforcement Learning Theory of Emotion: unifying emotion, cognition and adaptive behavior. (arXiv:1807.08941v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1807.08941</link>
<description rdf:parseType="Literal">&lt;p&gt;Emotions are intimately tied to motivation and the adaptation of behavior,
and many animal species show evidence of emotions in their behavior. Therefore,
emotions must be related to powerful mechanisms that aid survival, and,
emotions must be evolutionary continuous phenomena. How and why did emotions
evolve in nature, how do events get emotionally appraised, how do emotions
relate to cognitive complexity, and, how do they impact behavior and learning?
In this article I propose that all emotions are manifestations of reward
processing, in particular Temporal Difference (TD) error assessment.
Reinforcement Learning (RL) is a powerful computational model for the learning
of goal oriented tasks by exploration and feedback. Evidence indicates that
RL-like processes exist in many animal species. Key in the processing of
feedback in RL is the notion of TD error, the assessment of how much better or
worse a situation just became, compared to what was previously expected (or,
the estimated gain or loss of utility - or well-being - resulting from new
evidence). I propose a TDRL Theory of Emotion and discuss its ramifications for
our understanding of emotions in humans, animals and machines, and present
psychological, neurobiological and computational evidence in its support.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Broekens_J/0/1/0/all/0/1&quot;&gt;Joost Broekens&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09205">
<title>End-to-End Deep Imitation Learning: Robot Soccer Case Study. (arXiv:1807.09205v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1807.09205</link>
<description rdf:parseType="Literal">&lt;p&gt;In imitation learning, behavior learning is generally done using the features
extracted from the demonstration data. Recent deep learning algorithms enable
the development of machine learning methods that can get high dimensional data
as an input. In this work, we use imitation learning to teach the robot to
dribble the ball to the goal. We use B-Human robot software to collect
demonstration data and a deep convolutional network to represent the policies.
We use top and bottom camera images of the robot as input and speed commands as
outputs. The CNN policy learns the mapping between the series of images and
speed commands. In 3D realistic robotics simulator experiments, we show that
the robot is able to learn to search the ball and dribble the ball, but it
struggles to align to the goal. The best-proposed policy model learns to score
4 goals out of 20 test episodes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Asik_O/0/1/0/all/0/1&quot;&gt;Okan A&amp;#x15f;&amp;#x131;k&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gorer_B/0/1/0/all/0/1&quot;&gt;Binnur G&amp;#xf6;rer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Akin_H/0/1/0/all/0/1&quot;&gt;H. Levent Ak&amp;#x131;n&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09232">
<title>Deep Learning on Retina Images as Screening Tool for Diagnostic Decision Support. (arXiv:1807.09232v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1807.09232</link>
<description rdf:parseType="Literal">&lt;p&gt;In this project, we developed a deep learning system applied to human retina
images for medical diagnostic decision support. The retina images were provided
by EyePACS. These images were used in the framework of a Kaggle contest, whose
purpose to identify diabetic retinopathy signs through an automatic detection
system. Using as inspiration one of the solutions proposed in the contest, we
implemented a model that successfully detects diabetic retinopathy from retina
images. After a carefully designed preprocessing, the images were used as input
to a deep convolutional neural network (CNN). The CNN performed a feature
extraction process followed by a classification stage, which allowed the system
to differentiate between healthy and ill patients using five categories. Our
model was able to identify diabetic retinopathy in the patients with an
agreement rate of 76.73% with respect to the medical expert&apos;s labels for the
test data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Trivino_M/0/1/0/all/0/1&quot;&gt;Maria Camila Alvarez Trivino&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Despraz_J/0/1/0/all/0/1&quot;&gt;Jeremie Despraz&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sotelo_J/0/1/0/all/0/1&quot;&gt;Jesus Alfonso Lopez Sotelo&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pena_C/0/1/0/all/0/1&quot;&gt;Carlos Andres Pena&lt;/a&gt; (2) ((1) Universidad Autonoma de Occidente, (2) School of Business and Engineering Vaud (HEIG-VD))</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09244">
<title>Unsupervised Learning of Latent Physical Properties Using Perception-Prediction Networks. (arXiv:1807.09244v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.09244</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a framework for the completely unsupervised learning of latent
object properties from their interactions: the perception-prediction network
(PPN). Consisting of a perception module that extracts representations of
latent object properties and a prediction module that uses those extracted
properties to simulate system dynamics, the PPN can be trained in an end-to-end
fashion purely from samples of object dynamics. The representations of latent
object properties learned by PPNs not only are sufficient to accurately
simulate the dynamics of systems comprised of previously unseen objects, but
also can be translated directly into human-interpretable properties (e.g.,
mass, coefficient of restitution) in an entirely unsupervised manner.
Crucially, PPNs also generalize to novel scenarios: their gradient-based
training can be applied to many dynamical systems and their graph-based
structure functions over systems comprised of different numbers of objects. Our
results demonstrate the efficacy of graph-based neural architectures in
object-centric inference and prediction tasks, and our model has the potential
to discover relevant object properties in systems that are not yet well
understood.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_D/0/1/0/all/0/1&quot;&gt;David Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_V/0/1/0/all/0/1&quot;&gt;Vinson Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1&quot;&gt;Jiajun Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1&quot;&gt;Joshua B. Tenenbaum&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.05426">
<title>Causal Rule Sets for Identifying Subgroups with Enhanced Treatment Effect. (arXiv:1710.05426v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1710.05426</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a novel generative model for interpretable subgroup analysis for
causal inference applications, Causal Rule Sets (CRS). A CRS model uses a small
set of short rules to capture a subgroup where the average treatment effect is
elevated compared to the entire population. We present a Bayesian framework for
learning a causal rule set. The Bayesian framework consists of a prior that
favors simpler models and a Bayesian logistic regression that characterizes the
relation between outcomes, attributes and subgroup membership. We find maximum
a posteriori models using discrete Monte Carlo steps in the joint solution
space of rules sets and parameters. We provide theoretically grounded
heuristics and bounding strategies to improve search efficiency. Experiments
show that the search algorithm can efficiently recover a true underlying
subgroup and CRS shows consistently competitive performance compared to other
state-of-the-art baseline methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1&quot;&gt;Tong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rudin_C/0/1/0/all/0/1&quot;&gt;Cynthia Rudin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.08534">
<title>Safer Classification by Synthesis. (arXiv:1711.08534v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1711.08534</link>
<description rdf:parseType="Literal">&lt;p&gt;The discriminative approach to classification using deep neural networks has
become the de-facto standard in various fields. Complementing recent
reservations about safety against adversarial examples, we show that
conventional discriminative methods can easily be fooled to provide incorrect
labels with very high confidence to out of distribution examples. We posit that
a generative approach is the natural remedy for this problem, and propose a
method for classification using generative models. At training time, we learn a
generative model for each class, while at test time, given an example to
classify, we query each generator for its most similar generation, and select
the class corresponding to the most similar one. Our approach is general and
can be used with expressive models such as GANs and VAEs. At test time, our
method accurately &quot;knows when it does not know,&quot; and provides resilience to out
of distribution examples while maintaining competitive performance for standard
examples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;William Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_A/0/1/0/all/0/1&quot;&gt;Angelina Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tamar_A/0/1/0/all/0/1&quot;&gt;Aviv Tamar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1&quot;&gt;Pieter Abbeel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.08092">
<title>Generalizable Data-free Objective for Crafting Universal Adversarial Perturbations. (arXiv:1801.08092v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1801.08092</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning models are susceptible to adversarial perturbations: small
changes to input that can cause large changes in output. It is also
demonstrated that there exist input-agnostic perturbations, called universal
adversarial perturbations, which can change the inference of target model on
most of the data samples. However, existing methods to craft universal
perturbations are (i) task specific, (ii) require samples from the training
data distribution, and (iii) perform complex optimizations. Additionally,
because of the data dependence, fooling ability of the crafted perturbations is
proportional to the available training data. In this paper, we present a novel,
generalizable and data-free approaches for crafting universal adversarial
perturbations. Independent of the underlying task, our objective achieves
fooling via corrupting the extracted features at multiple layers. Therefore,
the proposed objective is generalizable to craft image-agnostic perturbations
across multiple vision tasks such as object recognition, semantic segmentation,
and depth estimation. In the practical setting of black-box attack scenario
(when the attacker does not have access to the target model and it&apos;s training
data), we show that our objective outperforms the data dependent objectives to
fool the learned models. Further, via exploiting simple priors related to the
data distribution, our objective remarkably boosts the fooling ability of the
crafted perturbations. Significant fooling rates achieved by our objective
emphasize that the current deep learning models are now at an increased risk,
since our objective generalizes across multiple tasks without the requirement
of training data for crafting the perturbations. To encourage reproducible
research, we have released the codes for our proposed algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mopuri_K/0/1/0/all/0/1&quot;&gt;Konda Reddy Mopuri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ganeshan_A/0/1/0/all/0/1&quot;&gt;Aditya Ganeshan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Babu_R/0/1/0/all/0/1&quot;&gt;R. Venkatesh Babu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.06957">
<title>Discrete linear-complexity reinforcement learning in continuous action spaces for Q-learning algorithms. (arXiv:1807.06957v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1807.06957</link>
<description rdf:parseType="Literal">&lt;p&gt;In this article, we sketch an algorithm that extends the Q-learning
algorithms to the continuous action space domain. Our method is based on the
discretization of the action space. Despite the commonly used discretization
methods, our method does not increase the discretized problem dimensionality
exponentially. We will show that our proposed method is linear in complexity
when the discretization is employed. The variant of the Q-learning algorithm
presented in this work, labeled as Finite Step Q-Learning (FSQ), can be
deployed to both shallow and deep neural network architectures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tavallali_P/0/1/0/all/0/1&quot;&gt;Peyman Tavallali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doran_G/0/1/0/all/0/1&quot;&gt;Gary B. Doran Jr.&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mandrake_L/0/1/0/all/0/1&quot;&gt;Lukas Mandrake&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.07665">
<title>Multitask Reinforcement Learning for Zero-shot Generalization with Subtask Dependencies. (arXiv:1807.07665v1 [cs.LG] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1807.07665</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a new RL problem where the agent is required to execute a given
subtask graph which describes a set of subtasks and their dependency. Unlike
existing multitask RL approaches that explicitly describe what the agent should
do, a subtask graph in our problem only describes properties of subtasks and
relationships among them, which requires the agent to perform complex reasoning
to find the optimal sequence of subtasks to execute. To tackle this problem, we
propose a neural subtask graph solver (NSS) which encodes the subtask graph
using a recursive neural network. To overcome the difficulty of training, we
propose a novel non-parametric gradient-based policy to pre-train our NSS
agent. % and further finetune it through actor-critic method. The experimental
results on two 2D visual domains show that our agent can perform complex
reasoning to find a near-optimal way of executing the subtask graph and
generalize well to the unseen subtask graphs. In addition, we compare our agent
with a Monte-Carlo tree search (MCTS) method showing that (1) our method is
much more efficient than MCTS and (2) combining MCTS with NSS dramatically
improves the search performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sohn_S/0/1/0/all/0/1&quot;&gt;Sungryull Sohn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oh_J/0/1/0/all/0/1&quot;&gt;Junhyuk Oh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1&quot;&gt;Honglak Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08820">
<title>RAIM: Recurrent Attentive and Intensive Model of Multimodal Patient Monitoring Data. (arXiv:1807.08820v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.08820</link>
<description rdf:parseType="Literal">&lt;p&gt;With the improvement of medical data capturing, vast amount of continuous
patient monitoring data, e.g., electrocardiogram (ECG), real-time vital signs
and medications, become available for clinical decision support at intensive
care units (ICUs). However, it becomes increasingly challenging to model such
data, due to high density of the monitoring data, heterogeneous data types and
the requirement for interpretable models. Integration of these high-density
monitoring data with the discrete clinical events (including diagnosis,
medications, labs) is challenging but potentially rewarding since richness and
granularity in such multimodal data increase the possibilities for accurate
detection of complex problems and predicting outcomes (e.g., length of stay and
mortality). We propose Recurrent Attentive and Intensive Model (RAIM) for
jointly analyzing continuous monitoring data and discrete clinical events. RAIM
introduces an efficient attention mechanism for continuous monitoring data
(e.g., ECG), which is guided by discrete clinical events (e.g, medication
usage). We apply RAIM in predicting physiological decompensation and length of
stay in those critically ill patients at ICU. With evaluations on MIMIC- III
Waveform Database Matched Subset, we obtain an AUC-ROC score of 90.18% for
predicting decompensation and an accuracy of 86.82% for forecasting length of
stay with our final model, which outperforms our six baseline models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yanbo Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Biswal_S/0/1/0/all/0/1&quot;&gt;Siddharth Biswal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deshpande_S/0/1/0/all/0/1&quot;&gt;Shriprasad R Deshpande&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maher_K/0/1/0/all/0/1&quot;&gt;Kevin O Maher&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1&quot;&gt;Jimeng Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08844">
<title>Lesion segmentation using U-Net network. (arXiv:1807.08844v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1807.08844</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper explains the method used in the segmentation challenge (Task 1) in
the International Skin Imaging Collaboration&apos;s (ISIC) Skin Lesion Analysis
Towards Melanoma Detection challenge held in 2018. We have trained a U-Net
network to perform the segmentation. The key elements for the training were
first to adjust the loss function to incorporate unbalanced proportion of
background and second to perform post-processing operation to adjust the
contour of the prediction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Motsch_A/0/1/0/all/0/1&quot;&gt;Adrien Motsch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Motsch_S/0/1/0/all/0/1&quot;&gt;Sebastien Motsch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saguet_T/0/1/0/all/0/1&quot;&gt;Thibaut Saguet&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08855">
<title>Weak in the NEES?: Auto-tuning Kalman Filters with Bayesian Optimization. (arXiv:1807.08855v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1807.08855</link>
<description rdf:parseType="Literal">&lt;p&gt;Kalman filters are routinely used for many data fusion applications including
navigation, tracking, and simultaneous localization and mapping problems.
However, significant time and effort is frequently required to tune various
Kalman filter model parameters, e.g. process noise covariance, pre-whitening
filter models for non-white noise, etc. Conventional optimization techniques
for tuning can get stuck in poor local minima and can be expensive to implement
with real sensor data. To address these issues, a new &quot;black box&quot; Bayesian
optimization strategy is developed for automatically tuning Kalman filters. In
this approach, performance is characterized by one of two stochastic objective
functions: normalized estimation error squared (NEES) when ground truth state
models are available, or the normalized innovation error squared (NIS) when
only sensor data is available. By intelligently sampling the parameter space to
both learn and exploit a nonparametric Gaussian process surrogate function for
the NEES/NIS costs, Bayesian optimization can efficiently identify multiple
local minima and provide uncertainty quantification on its results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhaozhong Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Heckman_C/0/1/0/all/0/1&quot;&gt;Christoffer Heckman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Julier_S/0/1/0/all/0/1&quot;&gt;Simon Julier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ahmed_N/0/1/0/all/0/1&quot;&gt;Nisar Ahmed&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08900">
<title>State-space analysis of an Ising model reveals contributions of pairwise interactions to sparseness, fluctuation, and stimulus coding of monkey V1 neurons. (arXiv:1807.08900v1 [q-bio.NC])</title>
<link>http://arxiv.org/abs/1807.08900</link>
<description rdf:parseType="Literal">&lt;p&gt;In this study, we analyzed the activity of monkey V1 neurons responding to
grating stimuli of different orientations using inference methods for a
time-dependent Ising model. The method provides optimal estimation of
time-dependent neural interactions with credible intervals according to the
sequential Bayes estimation algorithm. Furthermore, it allows us to trace
dynamics of macroscopic network properties such as entropy, sparseness, and
fluctuation. Here we report that, in all examined stimulus conditions, pairwise
interactions contribute to increasing sparseness and fluctuation. We then
demonstrate that the orientation of the grating stimulus is in part encoded in
the pairwise interactions of the neural populations. These results demonstrate
the utility of the state-space Ising model in assessing contributions of neural
interactions during stimulus processing.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Gaudreault_J/0/1/0/all/0/1&quot;&gt;Jimmy Gaudreault&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Shimazaki_H/0/1/0/all/0/1&quot;&gt;Hideaki Shimazaki&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08904">
<title>A Structured Perspective of Volumes on Active Learning. (arXiv:1807.08904v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.08904</link>
<description rdf:parseType="Literal">&lt;p&gt;Active Learning (AL) is a learning task that requires learners interactively
query the labels of the sampled unlabeled instances to minimize the training
outputs with human supervisions. In theoretical study, learners approximate the
version space which covers all possible classification hypothesis into a
bounded convex body and try to shrink the volume of it into a half-space by a
given cut size. However, only the hypersphere with finite VC dimensions has
obtained formal approximation guarantees that hold when the classes of
Euclidean space are separable with a margin. In this paper, we approximate the
version space to a structured {hypersphere} that covers most of the hypotheses,
and then divide the available AL sampling approaches into two kinds of
strategies: Outer Volume Sampling and Inner Volume Sampling. After providing
provable guarantees for the performance of AL in version space, we aggregate
the two kinds of volumes to eliminate their sampling biases via finding the
optimal inscribed hyperspheres in the enclosing space of outer volume. To touch
the version space from Euclidean space, we propose a theoretical bridge called
Volume-based Model that increases the `sampling target-independent&apos;. In
non-linear feature space, spanned by kernel, we use sequential optimization to
globally optimize the original space to a sparse space by halving the size of
the kernel space. Then, the EM (Expectation Maximization) model which returns
the local center helps us to find a local representation. To describe this
process, we propose an easy-to-implement algorithm called Volume-based AL
(VAL).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_X/0/1/0/all/0/1&quot;&gt;Xiaofeng Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsang_I/0/1/0/all/0/1&quot;&gt;Ivor W. Tsang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_G/0/1/0/all/0/1&quot;&gt;Guandong Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08959">
<title>Space-Time Extension of the MEM Approach for Electromagnetic Neuroimaging. (arXiv:1807.08959v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1807.08959</link>
<description rdf:parseType="Literal">&lt;p&gt;The wavelet Maximum Entropy on the Mean (wMEM) approach to the MEG inverse
problem is revisited and extended to infer brain activity from full space-time
data. The resulting dimensionality increase is tackled using a collection of
techniques , that includes time and space dimension reduction (using
respectively wavelet and spatial filter based reductions), Kronecker product
modeling for covariance matrices, and numerical manipulation of the free energy
directly in matrix form. This leads to a smooth numerical optimization problem
of reasonable dimension, solved using standard approaches. The method is
applied to the MEG inverse problem. Results of a simulation study in the
context of slow wave localization from sleep MEG data are presented and
discussed.
&lt;/p&gt;
&lt;p&gt;Index Terms: MEG inverse problem, maximum entropy on the mean, wavelet
decomposition, spatial filters, Kronecker covariance factorization, sleep slow
waves.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Roubaud_M/0/1/0/all/0/1&quot;&gt;Marie-Christine Roubaud&lt;/a&gt; (I2M), &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lina_J/0/1/0/all/0/1&quot;&gt;Jean-Marc Lina&lt;/a&gt; (ETS), &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Carrier_J/0/1/0/all/0/1&quot;&gt;Julie Carrier&lt;/a&gt; (CEAMS), &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Torresani_B/0/1/0/all/0/1&quot;&gt;B Torr&amp;#xe9;sani&lt;/a&gt; (I2M)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09010">
<title>Collective Matrix Completion. (arXiv:1807.09010v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1807.09010</link>
<description rdf:parseType="Literal">&lt;p&gt;Matrix completion aims to reconstruct a data matrix based on observations of
a small number of its entries. Usually in matrix completion a single matrix is
considered, which can be, for example, a rating matrix in recommendation
system. However, in practical situations, data is often obtained from multiple
sources which results in a collection of matrices rather than a single one. In
this work, we consider the problem of collective matrix completion with
multiple and heterogeneous matrices, which can be count, binary, continuous,
etc. We first investigate the setting where, for each source, the matrix
entries are sampled from an exponential family distribution. Then, we relax the
assumption of exponential family distribution for the noise and we investigate
the distribution-free case. In this setting, we do not assume any specific
model for the observations. The estimation procedures are based on minimizing
the sum of a goodness-of-fit term and the nuclear norm penalization of the
whole collective matrix. We prove that the proposed estimators achieve fast
rates of convergence under the two considered settings and we corroborate our
results with numerical experiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Alaya_M/0/1/0/all/0/1&quot;&gt;Mokhtar Z. Alaya&lt;/a&gt; (MODAL&amp;#x27;X), &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Klopp_O/0/1/0/all/0/1&quot;&gt;Olga Klopp&lt;/a&gt; (CREST)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09011">
<title>Uncertainty Modelling in Deep Networks: Forecasting Short and Noisy Series. (arXiv:1807.09011v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.09011</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep Learning is a consolidated, state-of-the-art Machine Learning tool to
fit a function when provided with large data sets of examples. However, in
regression tasks, the straightforward application of Deep Learning models
provides a point estimate of the target. In addition, the model does not take
into account the uncertainty of a prediction. This represents a great
limitation for tasks where communicating an erroneous prediction carries a
risk. In this paper we tackle a real-world problem of forecasting impending
financial expenses and incomings of customers, while displaying predictable
monetary amounts on a mobile app. In this context, we investigate if we would
obtain an advantage by applying Deep Learning models with a Heteroscedastic
model of the variance of a network&apos;s output. Experimentally, we achieve a
higher accuracy than non-trivial baselines. More importantly, we introduce a
mechanism to discard low-confidence predictions, which means that they will not
be visible to users. This should help enhance the user experience of our
product.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brando_A/0/1/0/all/0/1&quot;&gt;Axel Brando&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rodriguez_Serrano_J/0/1/0/all/0/1&quot;&gt;Jose A. Rodr&amp;#xed;guez-Serrano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ciprian_M/0/1/0/all/0/1&quot;&gt;Mauricio Ciprian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maestre_R/0/1/0/all/0/1&quot;&gt;Roberto Maestre&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vitria_J/0/1/0/all/0/1&quot;&gt;Jordi Vitri&amp;#xe0;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09120">
<title>Finite Time Adaptive Stabilization of LQ Systems. (arXiv:1807.09120v1 [cs.SY])</title>
<link>http://arxiv.org/abs/1807.09120</link>
<description rdf:parseType="Literal">&lt;p&gt;Stabilization of linear systems with unknown dynamics is a canonical problem
in adaptive control. Since the lack of knowledge of system parameters can cause
it to become destabilized, an adaptive stabilization procedure is needed prior
to regulation. Therefore, the adaptive stabilization needs to be completed in
finite time. In order to achieve this goal, asymptotic approaches are not very
helpful. There are only a few existing non-asymptotic results and a full
treatment of the problem is not currently available.
&lt;/p&gt;
&lt;p&gt;In this work, leveraging the novel method of random linear feedbacks, we
establish high probability guarantees for finite time stabilization. Our
results hold for remarkably general settings because we carefully choose a
minimal set of assumptions. These include stabilizability of the underlying
system and restricting the degree of heaviness of the noise distribution. To
derive our results, we also introduce a number of new concepts and technical
tools to address regularity and instability of the closed-loop matrix.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Faradonbeh_M/0/1/0/all/0/1&quot;&gt;Mohamad Kazem Shirani Faradonbeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tewari_A/0/1/0/all/0/1&quot;&gt;Ambuj Tewari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Michailidis_G/0/1/0/all/0/1&quot;&gt;George Michailidis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09151">
<title>Clearing noisy annotations for computed tomography imaging. (arXiv:1807.09151v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1807.09151</link>
<description rdf:parseType="Literal">&lt;p&gt;One of the problems on the way to successful implementation of neural
networks is the quality of annotation. For instance, different annotators can
annotate images in a different way and very often their decisions do not match
exactly and in extreme cases are even mutually exclusive which results in noisy
annotations and, consequently, inaccurate predictions.
&lt;/p&gt;
&lt;p&gt;To avoid that problem in the task of computed tomography (CT) imaging
segmentation we propose a clearing algorithm for annotations. It consists of 3
stages:
&lt;/p&gt;
&lt;p&gt;- annotators scoring, which assigns a higher confidence level to better
annotators;
&lt;/p&gt;
&lt;p&gt;- nodules scoring, which assigns a higher confidence level to nodules
confirmed by good annotators;
&lt;/p&gt;
&lt;p&gt;- nodules merging, which aggregates annotations according to nodules
confidence.
&lt;/p&gt;
&lt;p&gt;In general, the algorithm can be applied to many different tasks (namely,
binary and multi-class semantic segmentation, and also with trivial adjustments
to classification and regression) where there are several annotators labeling
each image.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khudorozhkov_R/0/1/0/all/0/1&quot;&gt;Roman Khudorozhkov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koryagin_A/0/1/0/all/0/1&quot;&gt;Alexander Koryagin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kozhevin_A/0/1/0/all/0/1&quot;&gt;Alexey Kozhevin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09202">
<title>Constraint-Based Visual Generation. (arXiv:1807.09202v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.09202</link>
<description rdf:parseType="Literal">&lt;p&gt;In the last few years the systematic adoption of deep learning to visual
generation has produced impressive results that, amongst others, definitely
benefit from the massive exploration of convolutional architectures. In this
paper, we propose a general approach to visual generation that combines
learning capabilities with logic descriptions of the target to be generated.
The process of generation is regarded as a constrained satisfaction problem,
where the constraints describe a set of properties that characterize the
target. Interestingly, the constraints can also involve logic variables, while
all of them are converted into real-valued functions by means of the t-norm
theory. We use deep architectures to model the involved variables, and propose
a computational scheme where the learning process carries out a satisfaction of
the constraints. We propose some examples in which the theory can naturally be
used, including the modeling of GAN and auto-encoders, and report promising
results in problems with the generation of handwritten characters and face
transformations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marra_G/0/1/0/all/0/1&quot;&gt;Giuseppe Marra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Giannini_F/0/1/0/all/0/1&quot;&gt;Francesco Giannini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diligenti_M/0/1/0/all/0/1&quot;&gt;Michelangelo Diligenti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gori_M/0/1/0/all/0/1&quot;&gt;Marco Gori&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09236">
<title>Improving pairwise comparison models using Empirical Bayes shrinkage. (arXiv:1807.09236v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1807.09236</link>
<description rdf:parseType="Literal">&lt;p&gt;Comparison data arises in many important contexts, e.g. shopping, web clicks,
or sports competitions. Typically we are given a dataset of comparisons and
wish to train a model to make predictions about the outcome of unseen
comparisons. In many cases available datasets have relatively few comparisons
(e.g. there are only so many NFL games per year) or efficiency is important
(e.g. we want to quickly estimate the relative appeal of a product). In such
settings it is well known that shrinkage estimators outperform maximum
likelihood estimators. A complicating matter is that standard comparison models
such as the conditional multinomial logit model are only models of conditional
outcomes (who wins) and not of comparisons themselves (who competes). As such,
different models of the comparison process lead to different shrinkage
estimators. In this work we derive a collection of methods for estimating the
pairwise uncertainty of pairwise predictions based on different assumptions
about the comparison process. These uncertainty estimates allow us both to
examine model uncertainty as well as perform Empirical Bayes shrinkage
estimation of the model parameters. We demonstrate that our shrunk estimators
outperform standard maximum likelihood methods on real comparison data from
online comparison surveys as well as from several sports contexts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ragain_S/0/1/0/all/0/1&quot;&gt;Stephen Ragain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Peysakhovich_A/0/1/0/all/0/1&quot;&gt;Alexander Peysakhovich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ugander_J/0/1/0/all/0/1&quot;&gt;Johan Ugander&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.04454">
<title>Thresholding Bandit for Dose-ranging: The Impact of Monotonicity. (arXiv:1711.04454v2 [math.ST] UPDATED)</title>
<link>http://arxiv.org/abs/1711.04454</link>
<description rdf:parseType="Literal">&lt;p&gt;We analyze the sample complexity of the thresholding bandit problem, with and
without the assumption that the mean values of the arms are increasing. In each
case, we provide a lower bound valid for any risk $\delta$ and any
$\delta$-correct algorithm; in addition, we propose an algorithm whose sample
complexity is of the same order of magnitude for small risks. This work is
motivated by phase 1 clinical trials, a practically important setting where the
arm means are increasing by nature, and where no satisfactory solution is
available so far.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Garivier_A/0/1/0/all/0/1&quot;&gt;Aur&amp;#xe9;lien Garivier&lt;/a&gt; (IMT), &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Menard_P/0/1/0/all/0/1&quot;&gt;Pierre M&amp;#xe9;nard&lt;/a&gt; (IMT), &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Rossi_L/0/1/0/all/0/1&quot;&gt;Laurent Rossi&lt;/a&gt; (IMT), &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Menard_P/0/1/0/all/0/1&quot;&gt;Pierre Menard&lt;/a&gt; (IMT)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.05630">
<title>Sparse principal component analysis via random projections. (arXiv:1712.05630v3 [stat.ME] UPDATED)</title>
<link>http://arxiv.org/abs/1712.05630</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a new method for sparse principal component analysis, based on
the aggregation of eigenvector information from carefully-selected random
projections of the sample covariance matrix. Unlike most alternative
approaches, our algorithm is non-iterative, so is not vulnerable to a bad
choice of initialisation. Our theory provides great detail on the statistical
and computational trade-off in our procedure, revealing a subtle interplay
between the effective sample size and the number of random projections that are
required to achieve the minimax optimal rate. Numerical studies provide further
insight into the procedure and confirm its highly competitive finite-sample
performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gataric_M/0/1/0/all/0/1&quot;&gt;Milana Gataric&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_T/0/1/0/all/0/1&quot;&gt;Tengyao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Samworth_R/0/1/0/all/0/1&quot;&gt;Richard J. Samworth&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.02550">
<title>Semi-Amortized Variational Autoencoders. (arXiv:1802.02550v7 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.02550</link>
<description rdf:parseType="Literal">&lt;p&gt;Amortized variational inference (AVI) replaces instance-specific local
inference with a global inference network. While AVI has enabled efficient
training of deep generative models such as variational autoencoders (VAE),
recent empirical work suggests that inference networks can produce suboptimal
variational parameters. We propose a hybrid approach, to use AVI to initialize
the variational parameters and run stochastic variational inference (SVI) to
refine them. Crucially, the local SVI procedure is itself differentiable, so
the inference network and generative model can be trained end-to-end with
gradient-based optimization. This semi-amortized approach enables the use of
rich generative models without experiencing the posterior-collapse phenomenon
common in training VAEs for problems like text generation. Experiments show
this approach outperforms strong autoregressive and variational baselines on
standard text and image datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kim_Y/0/1/0/all/0/1&quot;&gt;Yoon Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wiseman_S/0/1/0/all/0/1&quot;&gt;Sam Wiseman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Miller_A/0/1/0/all/0/1&quot;&gt;Andrew C. Miller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sontag_D/0/1/0/all/0/1&quot;&gt;David Sontag&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rush_A/0/1/0/all/0/1&quot;&gt;Alexander M. Rush&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08061">
<title>NEWMA: a new method for scalable model-free online change-point detection. (arXiv:1805.08061v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.08061</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of detecting abrupt changes in the distribution of a
multi-dimensional time series, with limited computing power and memory. In this
paper, we propose a new method for model-free online change-point detection
that relies only on fast and light recursive statistics, inspired by the
classical Exponential Weighted Moving Average algorithm (EWMA). The proposed
idea is to compute two EWMA statistics on the stream of data with different
forgetting factors, and to compare them. By doing so, we show that we
implicitly compare recent samples with older ones, without the need to
explicitly store them. Additionally, we leverage Random Features to efficiently
use the Maximum Mean Discrepancy as a distance between distributions. We show
that our method is orders of magnitude faster than usual non-parametric methods
for a given accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keriven_N/0/1/0/all/0/1&quot;&gt;Nicolas Keriven&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garreau_D/0/1/0/all/0/1&quot;&gt;Damien Garreau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poli_I/0/1/0/all/0/1&quot;&gt;Iacopo Poli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10586">
<title>Approximability of Discriminators Implies Diversity in GANs. (arXiv:1806.10586v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1806.10586</link>
<description rdf:parseType="Literal">&lt;p&gt;While Generative Adversarial Networks (GANs) have empirically produced
impressive results on learning complex real-world distributions, recent work
has shown that they suffer from lack of diversity or mode collapse. The
theoretical work of Arora et al. suggests a dilemma about GANs&apos; statistical
properties: powerful discriminators cause overfitting, whereas weak
discriminators cannot detect mode collapse.
&lt;/p&gt;
&lt;p&gt;In contrast, we show in this paper that GANs can in principle learn
distributions in Wasserstein distance (or KL-divergence in many cases) with
polynomial sample complexity, if the discriminator class has strong
distinguishing power against the particular generator class (instead of against
all possible generators). For various generator classes such as mixture of
Gaussians, exponential families, and invertible neural networks generators, we
design corresponding discriminators (which are often neural nets of specific
architectures) such that the Integral Probability Metric (IPM) induced by the
discriminators can provably approximate the Wasserstein distance and/or
KL-divergence. This implies that if the training is successful, then the
learned distribution is close to the true distribution in Wasserstein distance
or KL divergence, and thus cannot drop modes. Our preliminary experiments show
that on synthetic datasets the test IPM is well correlated with KL divergence,
indicating that the lack of diversity may be caused by the sub-optimality in
optimization instead of statistical inefficiency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1&quot;&gt;Yu Bai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1&quot;&gt;Tengyu Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Risteski_A/0/1/0/all/0/1&quot;&gt;Andrej Risteski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.02684">
<title>VFPred: A Fusion of Signal Processing and Machine Learning techniques in Detecting Ventricular Fibrillation from ECG Signals. (arXiv:1807.02684v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1807.02684</link>
<description rdf:parseType="Literal">&lt;p&gt;Ventricular Fibrillation (VF), one of the most dangerous arrhythmias, is
responsible for sudden cardiac arrests. Thus, various algorithms have been
developed to predict VF from Electrocardiogram (ECG), which is a binary
classification problem. In the literature, we find a number of algorithms based
on signal processing, where, after some robust mathematical operations the
decision is given based on a predefined threshold over a single value. On the
other hand, some machine learning based algorithms are also reported in the
literature; however, these algorithms merely combine some parameters and make a
prediction using those as features. Both the approaches have their perks and
pitfalls; thus our motivation was to coalesce them to get the best out of the
both worlds. Hence we have developed, VFPred that, in addition to employing a
signal processing pipeline, namely, Empirical Mode Decomposition and Discrete
Time Fourier Transform for useful feature extraction, uses a Support Vector
Machine for efficient classification. VFPred turns out to be a robust algorithm
as it is able to successfully segregate the two classes with equal confidence
(Sensitivity = 99.99%, Specificity = 98.40%) even from a short signal of 5
seconds long, whereas existing works though requires longer signals, flourishes
in one but fails in the other.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ibtehaz_N/0/1/0/all/0/1&quot;&gt;Nabil Ibtehaz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1&quot;&gt;M. Saifur Rahman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1&quot;&gt;M. Sohel Rahman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.07543">
<title>Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer. (arXiv:1807.07543v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1807.07543</link>
<description rdf:parseType="Literal">&lt;p&gt;Autoencoders provide a powerful framework for learning compressed
representations by encoding all of the information needed to reconstruct a data
point in a latent code. In some cases, autoencoders can &quot;interpolate&quot;: By
decoding the convex combination of the latent codes for two datapoints, the
autoencoder can produce an output which semantically mixes characteristics from
the datapoints. In this paper, we propose a regularization procedure which
encourages interpolated outputs to appear more realistic by fooling a critic
network which has been trained to recover the mixing coefficient from
interpolated data. We then develop a simple benchmark task where we can
quantitatively measure the extent to which various autoencoders can interpolate
and show that our regularizer dramatically improves interpolation in this
setting. We also demonstrate empirically that our regularizer produces latent
codes which are more effective on downstream tasks, suggesting a possible link
between interpolation abilities and learning useful representations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berthelot_D/0/1/0/all/0/1&quot;&gt;David Berthelot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raffel_C/0/1/0/all/0/1&quot;&gt;Colin Raffel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roy_A/0/1/0/all/0/1&quot;&gt;Aurko Roy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goodfellow_I/0/1/0/all/0/1&quot;&gt;Ian Goodfellow&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08409">
<title>Subsampling MCMC - A review for the survey statistician. (arXiv:1807.08409v2 [stat.ME] UPDATED)</title>
<link>http://arxiv.org/abs/1807.08409</link>
<description rdf:parseType="Literal">&lt;p&gt;The rapid development of computing power and efficient Markov Chain Monte
Carlo (MCMC) simulation algorithms have revolutionized Bayesian statistics,
making it a highly practical inference method in applied work. However, MCMC
algorithms tend to be computationally demanding, and are particularly slow for
large datasets. Data subsampling has recently been suggested as a way to make
MCMC methods scalable on massively large data, utilizing efficient sampling
schemes and estimators from the survey sampling literature. These developments
tend to be unknown by many survey statisticians who traditionally work with
non-Bayesian methods, and rarely use MCMC. Our article reviews Subsampling
MCMC, a so called pseudo-marginal MCMC approach to speeding up MCMC through
data subsampling. The review is written for a survey statistician without
previous knowledge of MCMC methods since our aim is to motivate survey sampling
experts to contribute to the growing Subsampling MCMC literature.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Quiroz_M/0/1/0/all/0/1&quot;&gt;Matias Quiroz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Villani_M/0/1/0/all/0/1&quot;&gt;Mattias Villani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kohn_R/0/1/0/all/0/1&quot;&gt;Robert Kohn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tran_M/0/1/0/all/0/1&quot;&gt;Minh-Ngoc Tran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dang_K/0/1/0/all/0/1&quot;&gt;Khue-Dung Dang&lt;/a&gt;</dc:creator>
</item></rdf:RDF>