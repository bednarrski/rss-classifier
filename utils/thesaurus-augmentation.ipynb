{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import re\n",
    "import codecs\n",
    "\n",
    "poliMorfPath = '../datasets/polish_dictionaries/PoliMorf-0.6.7.tab'\n",
    "thesaurusPath = '../datasets/polish_dictionaries/thesaurus.txt-latest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read all the poliMorf data\n",
    "poliMorf = codecs.open(poliMorfPath,'r', encoding='UTF-8')\n",
    "\n",
    "flexed2root = dict()\n",
    "root2flexed = dict()\n",
    "\n",
    "for line in poliMorf.readlines():\n",
    "    splitted = line.split('\\t')\n",
    "    if (splitted[0] in flexed2root):\n",
    "        temp = flexed2root[splitted[0]]\n",
    "        temp.append((splitted[1], splitted[2]))\n",
    "        splitted[0] = temp\n",
    "    else:\n",
    "        flexed2root[splitted[0]] = [(splitted[1], splitted[2])]\n",
    "        \n",
    "    root2flexed[splitted[1], splitted[2]] = [splitted[0]]\n",
    "    \n",
    "poliMorf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read all the thesaurus data\n",
    "thesaurus = codecs.open(thesaurusPath,'r', encoding='UTF-8')\n",
    "\n",
    "thesaurus_dict = dict()\n",
    "\n",
    "i = 0\n",
    "for line in thesaurus.readlines():\n",
    "    i = i + 1\n",
    "    if i < 9:\n",
    "        continue\n",
    "    splitted = line.lower().split(';')\n",
    "    synonyms = splitted[1:]\n",
    "    \n",
    "    synonyms_cleaned = []\n",
    "    for item in synonyms:\n",
    "        #item = re.sub('\\(.*\\)', '', item)\n",
    "        #item = item.strip()\n",
    "        if item.find('(') == -1:\n",
    "            item = item.strip()\n",
    "            synonyms_cleaned.append(item)\n",
    "    \n",
    "    thesaurus_dict[splitted[0]] = synonyms_cleaned\n",
    "    i = i + 1\n",
    "    \n",
    "thesaurus.close()\n",
    "\n",
    "black_list = ['do', 'na', 'nad']\n",
    "\n",
    "for item in black_list:\n",
    "    thesaurus_dict[item] = [item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_synonyms_and_form(word):\n",
    "    if not word in flexed2root:\n",
    "        return []\n",
    "        \n",
    "    root_list = flexed2root[word]\n",
    "    synonyms_forms_list = []\n",
    "    for root, form in root_list:\n",
    "        if root in thesaurus_dict:\n",
    "            synonyms_forms_list.append((thesaurus_dict[root], form))\n",
    "    return synonyms_forms_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['lilak'], ['lilak'], ['lilak']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test = find_synonyms_and_form('bez')\n",
    "test = [x[0] for x in test]\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import random\n",
    "\n",
    "def generate_sentences(sentence, max_sentences_num = 10):\n",
    "    words = sentence.lower().split(' ')\n",
    "    words = [[x] for x in words]\n",
    "    \n",
    "    for i in range(len(words)):\n",
    "        synonyms = find_synonyms_and_form(words[i][0])\n",
    "        \n",
    "        unique_synonyms = []\n",
    "        for syn_form in synonyms:\n",
    "            for item in syn_form[0]:\n",
    "                unique_synonyms.append(item)\n",
    "        unique_synonyms = list(set(unique_synonyms))\n",
    "        words[i] = words[i] + unique_synonyms\n",
    "        \n",
    "    \n",
    "    new_sentences = []\n",
    "    for i in range(max_sentences_num):\n",
    "        txt = ''\n",
    "        for j in range(len(words)):\n",
    "            txt = txt + ' ' + random.sample(words[j],1)[0]\n",
    "        txt = txt.strip()\n",
    "        new_sentences.append(txt)\n",
    "\n",
    "    \n",
    "    return new_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['idę do znachor', 'powodzić się, wieść się do doktor', 'idę do doktor']\n"
     ]
    }
   ],
   "source": [
    "#print(generate_sentences('Idę do lekarza', 10))\n",
    "words = generate_sentences('Idę do lekarza', 3)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loadig ING queries.\n",
      "Found 248 queries.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'blablalablablba blablabla przelewu ekspresowego blablabla\\tPrzelew złotówkowy\\tPrzelew\\tzłotówkowy\\r\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASETS_DIR = '../datasets/'\n",
    "ING_DIR = DATASETS_DIR+'ING-queries/'\n",
    "\n",
    "ing_queries_file = 'queries_2017_06_29.tsv'\n",
    "\n",
    "print('Loadig ING queries.')\n",
    "\n",
    "import codecs\n",
    "file = codecs.open(ING_DIR+ing_queries_file,'r', encoding='UTF-8')\n",
    "queries= file.readlines()\n",
    "\n",
    "print('Found %s queries.' % len(queries))\n",
    "\n",
    "queries[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filter_out = '[.!]'\n",
    "\n",
    "output = codecs.open(ING_DIR+'test_remove.tsv','w', encoding='UTF-8')\n",
    "\n",
    "for query in queries:\n",
    "    domain = query.split('\\t')[1]\n",
    "    intent = query.split('\\t')[2]\n",
    "    something = query.split('\\t')[3]\n",
    "    query = query.split('\\t')[0]\n",
    "    query = re.sub(filter_out, '', query)\n",
    "    \n",
    "    augmented = generate_sentences(query, 3)\n",
    "    first = query+'\\t'+domain+'\\t'+intent+'\\t'+something.strip()+'\\tN'\n",
    "    #print(first.strip())\n",
    "    output.write(first.strip()+'\\n')\n",
    "    for item in augmented:\n",
    "        additional = item+'\\t'+domain+'\\t'+intent+'\\t'+something.strip()+'\\tA'\n",
    "        #print(additional.strip())\n",
    "        output.write(additional.strip()+'\\n')\n",
    "        \n",
    "        \n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ja mam pytanie. Chciałabym przelać kwotę do koleżanki na konto walutowe.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ja bałamucić pytanie. chciałabym przelać kwotę do koleżanki na rachunek rozliczeniowy walutowe.',\n",
       " 'ja zwodzić pytanie. chciałabym przelać liczba do partnerka na rachunek rozliczeniowy walutowe.',\n",
       " 'ja bałamucić pytanie. chciałabym przelać kwotę do towarzyszka na konto walutowe.',\n",
       " 'ja przechodzić pytanie. chciałabym przelać kwotę do partnerka na rachunek rozliczeniowy walutowe.',\n",
       " 'ja łudzić pytanie. chciałabym przelać kwotę do towarzyszka na konto walutowe.',\n",
       " 'ja hipnotyzować pytanie. chciałabym przelać ilość do koleżanki na rachunek rozliczeniowy walutowe.',\n",
       " 'ja bałamucić pytanie. chciałabym przelać liczba do znajoma na rachunek rozliczeniowy walutowe.',\n",
       " 'ja łudzić pytanie. chciałabym przelać ilość do koleżanki na konto walutowe.',\n",
       " 'ja cierpieć pytanie. chciałabym przelać wolumen do koleżanki na rachunek rozliczeniowy walutowe.',\n",
       " 'ja zwodzić pytanie. chciałabym przelać liczba do koleżanki na rachunek rozliczeniowy walutowe.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(queries[50].split('\\t')[0])\n",
    "generate_sentences(queries[50].split('\\t')[0], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
